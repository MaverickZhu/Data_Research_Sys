#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åœ°å€åŒ¹é…é˜ˆå€¼å‚æ•°ç²¾ç»†è°ƒä¼˜
åŸºäºåŸºå‡†æµ‹è¯•ç»“æœï¼Œä¼˜åŒ–å„çº§åœ°å€ç»„ä»¶çš„ç›¸ä¼¼åº¦é˜ˆå€¼
"""

import os
import sys
import logging
import json
import time
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import copy

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.database.connection import DatabaseManager
from src.utils.config import ConfigManager
from src.matching.similarity_scorer import SimilarityCalculator
from src.matching.address_normalizer import normalize_address_for_matching

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ThresholdOptimizer:
    """åœ°å€åŒ¹é…é˜ˆå€¼ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ä¼˜åŒ–å™¨"""
        self.config_manager = ConfigManager()
        self.db_manager = DatabaseManager(config=self.config_manager.get_database_config())
        
        # å½“å‰é˜ˆå€¼é…ç½®ï¼ˆä»åŸºå‡†æµ‹è¯•åˆ†æå¾—å‡ºï¼‰
        self.current_thresholds = {
            'similarity_threshold': 0.7,  # æ€»ä½“åŒ¹é…é˜ˆå€¼
            'high_precision_threshold': 0.9,  # é«˜ç²¾åº¦é˜ˆå€¼
            'medium_precision_threshold': 0.7,  # ä¸­ç²¾åº¦é˜ˆå€¼
            
            # å±‚çº§éªŒè¯é˜ˆå€¼ï¼ˆä»similarity_scorer.pyåˆ†æå¾—å‡ºï¼‰
            'province_threshold': 0.85,  # çœçº§é˜ˆå€¼
            'city_threshold': 0.85,      # å¸‚çº§é˜ˆå€¼
            'district_threshold': 0.80,  # åŒºå¿çº§é˜ˆå€¼ï¼ˆå…³é”®é—®é¢˜æ‰€åœ¨ï¼‰
            'town_threshold': 0.75,      # é•‡è¡—çº§é˜ˆå€¼
            'community_threshold': 0.70, # å°åŒºçº§é˜ˆå€¼
            'street_threshold': 0.70,    # è·¯çº§é˜ˆå€¼
            'lane_threshold': 0.65,      # å¼„çº§é˜ˆå€¼
            'number_threshold': 0.60     # é—¨ç‰Œçº§é˜ˆå€¼
        }
        
        # ä¼˜åŒ–å€™é€‰é˜ˆå€¼é…ç½®
        self.optimization_candidates = [
            {
                'name': 'å®½æ¾é…ç½®',
                'description': 'é™ä½åŒºå¿çº§é˜ˆå€¼ï¼Œæé«˜åŒ¹é…ç‡',
                'thresholds': {
                    'similarity_threshold': 0.6,   # é™ä½æ€»ä½“é˜ˆå€¼
                    'high_precision_threshold': 0.85,  # é™ä½é«˜ç²¾åº¦é˜ˆå€¼
                    'medium_precision_threshold': 0.6,  # é™ä½ä¸­ç²¾åº¦é˜ˆå€¼
                    'province_threshold': 0.80,
                    'city_threshold': 0.80,
                    'district_threshold': 0.65,    # å…³é”®ï¼šå¤§å¹…é™ä½åŒºå¿çº§é˜ˆå€¼
                    'town_threshold': 0.60,        # é™ä½é•‡è¡—çº§é˜ˆå€¼
                    'community_threshold': 0.55,
                    'street_threshold': 0.55,
                    'lane_threshold': 0.50,
                    'number_threshold': 0.45
                }
            },
            {
                'name': 'å¹³è¡¡é…ç½®',
                'description': 'é€‚åº¦é™ä½é˜ˆå€¼ï¼Œå¹³è¡¡ç²¾å‡†åº¦å’Œå¬å›ç‡',
                'thresholds': {
                    'similarity_threshold': 0.65,
                    'high_precision_threshold': 0.88,
                    'medium_precision_threshold': 0.65,
                    'province_threshold': 0.82,
                    'city_threshold': 0.82,
                    'district_threshold': 0.72,    # é€‚åº¦é™ä½åŒºå¿çº§é˜ˆå€¼
                    'town_threshold': 0.68,
                    'community_threshold': 0.62,
                    'street_threshold': 0.62,
                    'lane_threshold': 0.58,
                    'number_threshold': 0.52
                }
            },
            {
                'name': 'æ¸è¿›é…ç½®',
                'description': 'å°å¹…è°ƒæ•´é˜ˆå€¼ï¼Œä¿æŒè¾ƒé«˜ç²¾å‡†åº¦',
                'thresholds': {
                    'similarity_threshold': 0.68,
                    'high_precision_threshold': 0.90,
                    'medium_precision_threshold': 0.68,
                    'province_threshold': 0.83,
                    'city_threshold': 0.83,
                    'district_threshold': 0.75,    # å°å¹…é™ä½åŒºå¿çº§é˜ˆå€¼
                    'town_threshold': 0.72,
                    'community_threshold': 0.68,
                    'street_threshold': 0.68,
                    'lane_threshold': 0.62,
                    'number_threshold': 0.55
                }
            }
        ]
        
    def run_threshold_optimization(self) -> Dict:
        """è¿è¡Œé˜ˆå€¼ä¼˜åŒ–æµ‹è¯•"""
        logger.info("ğŸ”§ å¼€å§‹åœ°å€åŒ¹é…é˜ˆå€¼ä¼˜åŒ–æµ‹è¯•")
        
        optimization_results = {
            'test_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'baseline_performance': None,
            'optimization_results': [],
            'best_configuration': None,
            'recommendations': []
        }
        
        # 1. è·å–æµ‹è¯•æ•°æ®
        test_data = self._prepare_test_data()
        if not test_data:
            return {'error': 'æ— æ³•è·å–æµ‹è¯•æ•°æ®'}
        
        logger.info(f"å‡†å¤‡äº† {len(test_data['source_samples'])} æ¡æºæ•°æ®å’Œ {len(test_data['target_samples'])} æ¡ç›®æ ‡æ•°æ®")
        
        # 2. åŸºå‡†æµ‹è¯•ï¼ˆå½“å‰é…ç½®ï¼‰
        logger.info("ğŸ“Š æ‰§è¡ŒåŸºå‡†æµ‹è¯•ï¼ˆå½“å‰é…ç½®ï¼‰...")
        baseline_result = self._test_threshold_configuration(
            "å½“å‰é…ç½®", 
            self.current_thresholds, 
            test_data
        )
        optimization_results['baseline_performance'] = baseline_result
        
        # 3. æµ‹è¯•ä¼˜åŒ–å€™é€‰é…ç½®
        for candidate in self.optimization_candidates:
            logger.info(f"ğŸ§ª æµ‹è¯• {candidate['name']} - {candidate['description']}")
            
            result = self._test_threshold_configuration(
                candidate['name'],
                candidate['thresholds'],
                test_data
            )
            
            # è®¡ç®—ç›¸å¯¹äºåŸºå‡†çš„æ”¹è¿›
            result['improvement'] = self._calculate_improvement(baseline_result, result)
            optimization_results['optimization_results'].append(result)
        
        # 4. é€‰æ‹©æœ€ä½³é…ç½®
        best_config = self._select_best_configuration(optimization_results['optimization_results'])
        optimization_results['best_configuration'] = best_config
        
        # 5. ç”Ÿæˆä¼˜åŒ–å»ºè®®
        optimization_results['recommendations'] = self._generate_optimization_recommendations(
            baseline_result, optimization_results['optimization_results']
        )
        
        return optimization_results
    
    def _prepare_test_data(self) -> Dict:
        """å‡†å¤‡æµ‹è¯•æ•°æ®"""
        try:
            # è·å–æºè¡¨æ•°æ®\n            source_collection = self.db_manager.get_collection('hztj_hzxx')\n            source_sample = source_collection.find_one()\n            if not source_sample:\n                return {}\n            \n            # æŸ¥æ‰¾æºè¡¨åœ°å€å­—æ®µ\n            source_address_field = None\n            for field, value in source_sample.items():\n                if isinstance(value, str) and len(value) > 5:\n                    if any(keyword in value for keyword in ['è·¯', 'è¡—', 'åŒº', 'å¸‚', 'å·', 'å¼„', 'æ‘']):\n                        source_address_field = field\n                        break\n            \n            if not source_address_field:\n                return {}\n            \n            # è·å–ç›®æ ‡è¡¨æ•°æ®\n            target_collection = self.db_manager.get_collection('dwd_yljgxx')\n            target_sample = target_collection.find_one()\n            if not target_sample:\n                return {}\n            \n            # æŸ¥æ‰¾ç›®æ ‡è¡¨åœ°å€å­—æ®µ\n            target_address_field = None\n            for field, value in target_sample.items():\n                if isinstance(value, str) and len(value) > 5:\n                    if any(keyword in value for keyword in ['è·¯', 'è¡—', 'åŒº', 'å¸‚', 'å·', 'å¼„', 'æ‘']):\n                        target_address_field = field\n                        break\n            \n            if not target_address_field:\n                return {}\n            \n            # è·å–æµ‹è¯•æ ·æœ¬ï¼ˆå‡å°‘æ•°é‡ä»¥æé«˜æµ‹è¯•é€Ÿåº¦ï¼‰\n            source_samples = list(source_collection.find(\n                {source_address_field: {'$exists': True, '$ne': '', '$ne': None}}\n            ).limit(30))  # å‡å°‘åˆ°30æ¡\n            \n            target_samples = list(target_collection.find(\n                {target_address_field: {'$exists': True, '$ne': '', '$ne': None}}\n            ).limit(50))  # å‡å°‘åˆ°50æ¡\n            \n            # æ ‡å‡†åŒ–åœ°å€å­—æ®µå\n            for sample in source_samples:\n                sample['address'] = sample.get(source_address_field, '')\n            \n            for sample in target_samples:\n                sample['address'] = sample.get(target_address_field, '')\n            \n            return {\n                'source_samples': source_samples,\n                'target_samples': target_samples,\n                'source_field': source_address_field,\n                'target_field': target_address_field\n            }\n            \n        except Exception as e:\n            logger.error(f\"å‡†å¤‡æµ‹è¯•æ•°æ®å¤±è´¥: {str(e)}\")\n            return {}\n    \n    def _test_threshold_configuration(self, config_name: str, thresholds: Dict, test_data: Dict) -> Dict:\n        \"\"\"æµ‹è¯•ç‰¹å®šé˜ˆå€¼é…ç½®\"\"\"\n        start_time = time.time()\n        \n        # åˆ›å»ºä¸´æ—¶çš„ç›¸ä¼¼åº¦è®¡ç®—å™¨ï¼Œä½¿ç”¨æ–°çš„é˜ˆå€¼é…ç½®\n        temp_config = self.config_manager.get_matching_config().copy()\n        temp_config.update(thresholds)\n        \n        similarity_calculator = SimilarityCalculator(temp_config)\n        \n        # ä¸´æ—¶ä¿®æ”¹å±‚çº§éªŒè¯é˜ˆå€¼ï¼ˆé€šè¿‡monkey patchï¼‰\n        original_method = similarity_calculator._hierarchical_termination_verification\n        \n        def patched_verification(comp1, comp2):\n            # ä½¿ç”¨æ–°çš„é˜ˆå€¼é…ç½®\n            hierarchy_levels = [\n                ('province', 'çœçº§', thresholds.get('province_threshold', 0.85)),\n                ('city', 'å¸‚çº§', thresholds.get('city_threshold', 0.85)),\n                ('district', 'åŒºå¿çº§', thresholds.get('district_threshold', 0.80)),\n                ('town', 'é•‡è¡—çº§', thresholds.get('town_threshold', 0.75)),\n                ('community', 'å°åŒºçº§', thresholds.get('community_threshold', 0.70)),\n                ('street', 'è·¯çº§', thresholds.get('street_threshold', 0.70)),\n                ('lane', 'å¼„çº§', thresholds.get('lane_threshold', 0.65)),\n                ('number', 'é—¨ç‰Œçº§', thresholds.get('number_threshold', 0.60))\n            ]\n            \n            for level_idx, (level, level_name, threshold) in enumerate(hierarchy_levels):\n                val1 = comp1.get(level, '').strip()\n                val2 = comp2.get(level, '').strip()\n                \n                if val1 and val2:\n                    level_similarity = similarity_calculator._calculate_component_similarity(val1, val2, level)\n                    if level_similarity < threshold:\n                        return 0.0\n                elif not val1 or not val2:\n                    continue\n            \n            return 1.0  # é€šè¿‡å±‚çº§éªŒè¯\n        \n        # åº”ç”¨è¡¥ä¸\n        similarity_calculator._hierarchical_termination_verification = patched_verification\n        \n        # æ‰§è¡Œæµ‹è¯•\n        results = {\n            'config_name': config_name,\n            'thresholds': thresholds,\n            'total_tests': len(test_data['source_samples']),\n            'matches_found': 0,\n            'high_precision_matches': 0,\n            'medium_precision_matches': 0,\n            'low_precision_matches': 0,\n            'no_matches': 0,\n            'match_details': [],\n            'performance': {\n                'total_time': 0,\n                'avg_time_per_test': 0,\n                'tests_per_second': 0\n            }\n        }\n        \n        for i, source_record in enumerate(test_data['source_samples']):\n            source_address = source_record.get('address', '')\n            if not source_address:\n                continue\n            \n            # æ ‡å‡†åŒ–æºåœ°å€\n            normalized_source = normalize_address_for_matching(source_address)\n            \n            # å¯»æ‰¾æœ€ä½³åŒ¹é…\n            best_similarity = 0.0\n            best_match = None\n            \n            for target_record in test_data['target_samples']:\n                target_address = target_record.get('address', '')\n                if not target_address:\n                    continue\n                \n                # æ ‡å‡†åŒ–ç›®æ ‡åœ°å€\n                normalized_target = normalize_address_for_matching(target_address)\n                \n                # è®¡ç®—ç›¸ä¼¼åº¦\n                similarity = similarity_calculator.calculate_address_similarity(\n                    normalized_source, normalized_target\n                )\n                \n                if similarity > best_similarity:\n                    best_similarity = similarity\n                    best_match = {\n                        'target_address': target_address,\n                        'normalized_target': normalized_target,\n                        'similarity': similarity\n                    }\n            \n            # åˆ†ç±»åŒ¹é…ç»“æœ\n            match_category = self._categorize_match_with_thresholds(best_similarity, thresholds)\n            \n            if best_similarity >= thresholds.get('similarity_threshold', 0.7):\n                results['matches_found'] += 1\n                \n                if match_category == 'high_precision':\n                    results['high_precision_matches'] += 1\n                elif match_category == 'medium_precision':\n                    results['medium_precision_matches'] += 1\n                else:\n                    results['low_precision_matches'] += 1\n            else:\n                results['no_matches'] += 1\n            \n            # è®°å½•è¯¦ç»†ç»“æœï¼ˆåªä¿ç•™å‰5æ¡ï¼‰\n            if len(results['match_details']) < 5:\n                results['match_details'].append({\n                    'test_id': i + 1,\n                    'source_address': source_address,\n                    'normalized_source': normalized_source,\n                    'best_match_address': best_match['target_address'] if best_match else '',\n                    'best_match_normalized': best_match['normalized_target'] if best_match else '',\n                    'similarity_score': best_similarity,\n                    'match_category': match_category,\n                    'has_match': best_similarity >= thresholds.get('similarity_threshold', 0.7)\n                })\n        \n        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡\n        total_time = time.time() - start_time\n        results['performance']['total_time'] = total_time\n        results['performance']['avg_time_per_test'] = total_time / len(test_data['source_samples']) if test_data['source_samples'] else 0\n        results['performance']['tests_per_second'] = len(test_data['source_samples']) / total_time if total_time > 0 else 0\n        \n        return results\n    \n    def _categorize_match_with_thresholds(self, similarity: float, thresholds: Dict) -> str:\n        \"\"\"ä½¿ç”¨æŒ‡å®šé˜ˆå€¼åˆ†ç±»åŒ¹é…ç»“æœ\"\"\"\n        if similarity >= thresholds.get('high_precision_threshold', 0.9):\n            return 'high_precision'\n        elif similarity >= thresholds.get('medium_precision_threshold', 0.7):\n            return 'medium_precision'\n        elif similarity >= thresholds.get('similarity_threshold', 0.7):\n            return 'low_precision'\n        else:\n            return 'no_match'\n    \n    def _calculate_improvement(self, baseline: Dict, candidate: Dict) -> Dict:\n        \"\"\"è®¡ç®—ç›¸å¯¹äºåŸºå‡†çš„æ”¹è¿›\"\"\"\n        baseline_match_rate = baseline['matches_found'] / baseline['total_tests'] if baseline['total_tests'] > 0 else 0\n        candidate_match_rate = candidate['matches_found'] / candidate['total_tests'] if candidate['total_tests'] > 0 else 0\n        \n        baseline_high_rate = baseline['high_precision_matches'] / baseline['total_tests'] if baseline['total_tests'] > 0 else 0\n        candidate_high_rate = candidate['high_precision_matches'] / candidate['total_tests'] if candidate['total_tests'] > 0 else 0\n        \n        return {\n            'match_rate_improvement': candidate_match_rate - baseline_match_rate,\n            'high_precision_improvement': candidate_high_rate - baseline_high_rate,\n            'speed_improvement': candidate['performance']['tests_per_second'] - baseline['performance']['tests_per_second'],\n            'match_rate_change_percent': ((candidate_match_rate - baseline_match_rate) / baseline_match_rate * 100) if baseline_match_rate > 0 else 0,\n            'high_precision_change_percent': ((candidate_high_rate - baseline_high_rate) / baseline_high_rate * 100) if baseline_high_rate > 0 else float('inf') if candidate_high_rate > 0 else 0\n        }\n    \n    def _select_best_configuration(self, results: List[Dict]) -> Dict:\n        \"\"\"é€‰æ‹©æœ€ä½³é…ç½®\"\"\"\n        if not results:\n            return None\n        \n        # ç»¼åˆè¯„åˆ†ï¼šåŒ¹é…ç‡ * 0.6 + é«˜ç²¾åº¦ç‡ * 0.4\n        best_config = None\n        best_score = -1\n        \n        for result in results:\n            match_rate = result['matches_found'] / result['total_tests'] if result['total_tests'] > 0 else 0\n            high_precision_rate = result['high_precision_matches'] / result['total_tests'] if result['total_tests'] > 0 else 0\n            \n            composite_score = match_rate * 0.6 + high_precision_rate * 0.4\n            \n            if composite_score > best_score:\n                best_score = composite_score\n                best_config = result\n        \n        if best_config:\n            best_config['composite_score'] = best_score\n        \n        return best_config\n    \n    def _generate_optimization_recommendations(self, baseline: Dict, results: List[Dict]) -> List[str]:\n        \"\"\"ç”Ÿæˆä¼˜åŒ–å»ºè®®\"\"\"\n        recommendations = []\n        \n        # åˆ†ææœ€ä½³æ”¹è¿›\n        best_match_improvement = max(results, key=lambda x: x['improvement']['match_rate_improvement'])\n        best_precision_improvement = max(results, key=lambda x: x['improvement']['high_precision_improvement'])\n        \n        if best_match_improvement['improvement']['match_rate_improvement'] > 0:\n            recommendations.append(\n                f\"é‡‡ç”¨'{best_match_improvement['config_name']}'å¯å°†åŒ¹é…ç‡æå‡ \"\n                f\"{best_match_improvement['improvement']['match_rate_change_percent']:.1f}%\"\n            )\n        \n        if best_precision_improvement['improvement']['high_precision_improvement'] > 0:\n            recommendations.append(\n                f\"é‡‡ç”¨'{best_precision_improvement['config_name']}'å¯æå‡é«˜ç²¾åº¦åŒ¹é…ç‡\"\n            )\n        \n        # åˆ†æé˜ˆå€¼è°ƒæ•´å»ºè®®\n        baseline_match_rate = baseline['matches_found'] / baseline['total_tests'] if baseline['total_tests'] > 0 else 0\n        if baseline_match_rate < 0.3:\n            recommendations.append(\"å½“å‰åŒ¹é…ç‡è¿‡ä½ï¼Œå»ºè®®é‡‡ç”¨'å®½æ¾é…ç½®'å¤§å¹…é™ä½åŒºå¿çº§é˜ˆå€¼\")\n        elif baseline_match_rate < 0.5:\n            recommendations.append(\"åŒ¹é…ç‡åä½ï¼Œå»ºè®®é‡‡ç”¨'å¹³è¡¡é…ç½®'é€‚åº¦è°ƒæ•´é˜ˆå€¼\")\n        else:\n            recommendations.append(\"åŒ¹é…ç‡å°šå¯ï¼Œå»ºè®®é‡‡ç”¨'æ¸è¿›é…ç½®'è¿›è¡Œå¾®è°ƒ\")\n        \n        return recommendations\n\ndef main():\n    \"\"\"ä¸»å‡½æ•°\"\"\"\n    print(\"ğŸ”§ åœ°å€åŒ¹é…é˜ˆå€¼ä¼˜åŒ–æµ‹è¯•\")\n    print(\"=\" * 50)\n    \n    try:\n        optimizer = ThresholdOptimizer()\n        results = optimizer.run_threshold_optimization()\n        \n        if 'error' in results:\n            print(f\"âŒ ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {results['error']}\")\n            return\n        \n        # æ˜¾ç¤ºåŸºå‡†æµ‹è¯•ç»“æœ\n        baseline = results['baseline_performance']\n        print(f\"\\nğŸ“Š åŸºå‡†æµ‹è¯•ç»“æœï¼ˆå½“å‰é…ç½®ï¼‰:\")\n        print(f\"  æ€»æµ‹è¯•æ•°: {baseline['total_tests']}\")\n        print(f\"  æ‰¾åˆ°åŒ¹é…: {baseline['matches_found']} ({baseline['matches_found']/baseline['total_tests']*100:.1f}%)\")\n        print(f\"  é«˜ç²¾åº¦åŒ¹é…: {baseline['high_precision_matches']} ({baseline['high_precision_matches']/baseline['total_tests']*100:.1f}%)\")\n        print(f\"  å¤„ç†é€Ÿåº¦: {baseline['performance']['tests_per_second']:.1f} æ¡/ç§’\")\n        \n        # æ˜¾ç¤ºä¼˜åŒ–ç»“æœ\n        print(f\"\\nğŸ§ª ä¼˜åŒ–é…ç½®æµ‹è¯•ç»“æœ:\")\n        for result in results['optimization_results']:\n            match_rate = result['matches_found'] / result['total_tests'] * 100\n            high_precision_rate = result['high_precision_matches'] / result['total_tests'] * 100\n            improvement = result['improvement']\n            \n            print(f\"\\n  {result['config_name']}:\")\n            print(f\"    åŒ¹é…ç‡: {match_rate:.1f}% (æ”¹è¿›: {improvement['match_rate_change_percent']:+.1f}%)\")\n            print(f\"    é«˜ç²¾åº¦ç‡: {high_precision_rate:.1f}% (æ”¹è¿›: {improvement['high_precision_change_percent']:+.1f}%)\")\n            print(f\"    å¤„ç†é€Ÿåº¦: {result['performance']['tests_per_second']:.1f} æ¡/ç§’\")\n        \n        # æ˜¾ç¤ºæœ€ä½³é…ç½®\n        best_config = results['best_configuration']\n        if best_config:\n            print(f\"\\nğŸ† æ¨èæœ€ä½³é…ç½®: {best_config['config_name']}\")\n            print(f\"  ç»¼åˆè¯„åˆ†: {best_config['composite_score']:.3f}\")\n            print(f\"  åŒ¹é…ç‡: {best_config['matches_found']/best_config['total_tests']*100:.1f}%\")\n            print(f\"  é«˜ç²¾åº¦ç‡: {best_config['high_precision_matches']/best_config['total_tests']*100:.1f}%\")\n        \n        # æ˜¾ç¤ºä¼˜åŒ–å»ºè®®\n        print(f\"\\nğŸ’¡ ä¼˜åŒ–å»ºè®®:\")\n        for i, rec in enumerate(results['recommendations'], 1):\n            print(f\"  {i}. {rec}\")\n        \n        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š\n        report_file = f\"threshold_optimization_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n        with open(report_file, 'w', encoding='utf-8') as f:\n            json.dump(results, f, ensure_ascii=False, indent=2)\n        \n        print(f\"\\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file}\")\n        \n    except Exception as e:\n        print(f\"âŒ ä¼˜åŒ–æµ‹è¯•æ‰§è¡Œå¤±è´¥: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n\nif __name__ == \"__main__\":\n    main()
