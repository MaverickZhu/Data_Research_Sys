#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åœ°å€åŒ¹é…ç²¾å‡†åº¦åŸºå‡†æµ‹è¯•
åŸºäºæ˜¨æ—¥çš„æŠ€æœ¯çªç ´ï¼Œå»ºç«‹å½“å‰ç³»ç»Ÿçš„ç²¾å‡†åº¦åŸºå‡†çº¿
"""

import os
import sys
import logging
import json
import time
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.database.connection import DatabaseManager
from src.matching.user_data_matcher import UserDataMatcher
from src.matching.similarity_scorer import SimilarityCalculator
from src.matching.address_normalizer import normalize_address_for_matching
from src.utils.config import ConfigManager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/address_precision_benchmark.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class AddressPrecisionBenchmark:
    """åœ°å€åŒ¹é…ç²¾å‡†åº¦åŸºå‡†æµ‹è¯•å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åŸºå‡†æµ‹è¯•å™¨"""
        # åŠ è½½é…ç½®
        self.config_manager = ConfigManager()
        self.db_manager = DatabaseManager(config=self.config_manager.get_database_config())
        self.similarity_calculator = SimilarityCalculator(self.config_manager.get_matching_config())
        
        # æµ‹è¯•é…ç½®
        self.test_config = {
            'sample_size': 500,  # æµ‹è¯•æ ·æœ¬æ•°é‡
            'precision_threshold': 0.8,  # ç²¾å‡†åŒ¹é…é˜ˆå€¼
            'similarity_threshold': 0.6,  # ç›¸ä¼¼åº¦é˜ˆå€¼
            'max_candidates': 10  # æœ€å¤§å€™é€‰æ•°é‡
        }
        
        # æµ‹è¯•ç»“æœç»Ÿè®¡
        self.results = {
            'total_tests': 0,
            'successful_matches': 0,
            'false_positives': 0,
            'false_negatives': 0,
            'precision': 0.0,
            'recall': 0.0,
            'f1_score': 0.0,
            'detailed_results': []
        }
        
        logger.info("ğŸš€ åœ°å€åŒ¹é…ç²¾å‡†åº¦åŸºå‡†æµ‹è¯•å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def prepare_test_dataset(self) -> List[Dict]:
        """
        å‡†å¤‡æµ‹è¯•æ•°æ®é›†
        é€‰æ‹©500æ¡å…·æœ‰ä»£è¡¨æ€§çš„åœ°å€æ•°æ®
        """
        logger.info("ğŸ“Š å‡†å¤‡æµ‹è¯•æ•°æ®é›†...")
        
        try:
            # ä»å®é™…çš„ç”¨æˆ·æ•°æ®è¡¨è·å–åœ°å€æ ·æœ¬
            # ä½¿ç”¨hztj_hzxxè¡¨ä½œä¸ºæºæ•°æ®
            source_collection = self.db_manager.get_collection('hztj_hzxx')
            
            # å…ˆæ£€æŸ¥è¡¨ä¸­çš„å­—æ®µç»“æ„
            sample_record = source_collection.find_one()
            if not sample_record:
                logger.error("hztj_hzxxè¡¨ä¸­æ²¡æœ‰æ•°æ®")
                return []
            
            logger.info(f"hztj_hzxxè¡¨æ ·æœ¬è®°å½•å­—æ®µ: {list(sample_record.keys())}")
            
            # æŸ¥æ‰¾åŒ…å«åœ°å€ä¿¡æ¯çš„å­—æ®µ
            address_fields = []
            for field in sample_record.keys():
                if any(keyword in field.lower() for keyword in ['address', 'addr', 'dz', 'åœ°å€', 'ä½å€']):
                    address_fields.append(field)
            
            if not address_fields:
                # å¦‚æœæ²¡æœ‰æ˜æ˜¾çš„åœ°å€å­—æ®µï¼ŒæŸ¥çœ‹æ‰€æœ‰å­—æ®µçš„å€¼
                logger.info("æœªæ‰¾åˆ°æ˜æ˜¾çš„åœ°å€å­—æ®µï¼Œæ£€æŸ¥æ‰€æœ‰å­—æ®µ...")
                for field, value in sample_record.items():
                    if isinstance(value, str) and len(value) > 10:
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«åœ°å€å…³é”®è¯
                        if any(keyword in value for keyword in ['è·¯', 'è¡—', 'åŒº', 'å¸‚', 'å·', 'å¼„', 'æ‘']):
                            address_fields.append(field)
                            logger.info(f"å‘ç°å¯èƒ½çš„åœ°å€å­—æ®µ: {field} = {value[:50]}...")
            
            if not address_fields:
                logger.error("æœªæ‰¾åˆ°åŒ…å«åœ°å€ä¿¡æ¯çš„å­—æ®µ")
                return []
            
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªåœ°å€å­—æ®µè·å–æµ‹è¯•æ ·æœ¬
            primary_address_field = address_fields[0]
            logger.info(f"ä½¿ç”¨åœ°å€å­—æ®µ: {primary_address_field}")
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶ï¼Œè·å–æœ‰åœ°å€æ•°æ®çš„è®°å½•
            query = {primary_address_field: {'$exists': True, '$ne': '', '$ne': None}}
            
            # è·å–æµ‹è¯•æ ·æœ¬
            test_samples = list(source_collection.find(query).limit(self.test_config['sample_size']))
            
            # æ ‡å‡†åŒ–æ ·æœ¬æ ¼å¼ï¼Œç»Ÿä¸€åœ°å€å­—æ®µå
            for sample in test_samples:
                sample['address'] = sample.get(primary_address_field, '')
                sample['source_table'] = 'hztj_hzxx'
            
            logger.info(f"âœ… æµ‹è¯•æ•°æ®é›†å‡†å¤‡å®Œæˆï¼Œå…± {len(test_samples)} æ¡æ ·æœ¬")
            return test_samples
            
        except Exception as e:
            logger.error(f"âŒ å‡†å¤‡æµ‹è¯•æ•°æ®é›†å¤±è´¥: {str(e)}")
            return []
    
    def create_ground_truth_pairs(self, test_samples: List[Dict]) -> List[Dict]:
        """
        åˆ›å»ºåœ°å€åŒ¹é…çš„æ ‡å‡†ç­”æ¡ˆå¯¹
        åŸºäºåœ°å€ç›¸ä¼¼åº¦å’Œäººå·¥è§„åˆ™ç”Ÿæˆ
        """
        logger.info("ğŸ¯ åˆ›å»ºæ ‡å‡†ç­”æ¡ˆå¯¹...")
        
        ground_truth_pairs = []
        
        try:
            # è·å–ç›®æ ‡æ•°æ®é›†ï¼ˆç”¨äºåŒ¹é…çš„æ•°æ®ï¼‰- ä½¿ç”¨dwd_yljgxxè¡¨
            target_collection = self.db_manager.get_collection('dwd_yljgxx')
            
            # å…ˆæ£€æŸ¥ç›®æ ‡è¡¨çš„å­—æ®µç»“æ„
            target_sample = target_collection.find_one()
            if not target_sample:
                logger.error("dwd_yljgxxè¡¨ä¸­æ²¡æœ‰æ•°æ®")
                return []
            
            # æŸ¥æ‰¾ç›®æ ‡è¡¨ä¸­çš„åœ°å€å­—æ®µ
            target_address_field = None
            for field in target_sample.keys():
                if any(keyword in field.lower() for keyword in ['address', 'addr', 'dz', 'åœ°å€', 'ä½å€']):
                    target_address_field = field
                    break
            
            if not target_address_field:
                # æ£€æŸ¥æ‰€æœ‰å­—æ®µçš„å€¼
                for field, value in target_sample.items():
                    if isinstance(value, str) and len(value) > 10:
                        if any(keyword in value for keyword in ['è·¯', 'è¡—', 'åŒº', 'å¸‚', 'å·', 'å¼„', 'æ‘']):
                            target_address_field = field
                            break
            
            if not target_address_field:
                logger.error("ç›®æ ‡è¡¨ä¸­æœªæ‰¾åˆ°åœ°å€å­—æ®µ")
                return []
            
            logger.info(f"ç›®æ ‡è¡¨ä½¿ç”¨åœ°å€å­—æ®µ: {target_address_field}")
            
            target_samples = list(target_collection.find(
                {target_address_field: {'$exists': True, '$ne': ''}},
                {'_id': 1, target_address_field: 1}
            ).limit(2000))  # é™åˆ¶ç›®æ ‡æ•°æ®é‡ä»¥æé«˜æ•ˆç‡
            
            # ç»Ÿä¸€åœ°å€å­—æ®µå
            for sample in target_samples:
                sample['address'] = sample.get(target_address_field, '')
            
            logger.info(f"è·å–åˆ° {len(target_samples)} æ¡ç›®æ ‡æ•°æ®ç”¨äºåŒ¹é…")
            
            for i, source_record in enumerate(test_samples[:100]):  # é™åˆ¶åˆ°100æ¡ä»¥æé«˜æ•ˆç‡
                source_address = source_record.get('address', '')
                if not source_address:
                    continue
                
                logger.info(f"å¤„ç†ç¬¬ {i+1}/100 æ¡æºåœ°å€: {source_address[:50]}...")
                
                # æ ‡å‡†åŒ–æºåœ°å€
                normalized_source = normalize_address_for_matching(source_address)
                
                # å¯»æ‰¾æœ€ä½³åŒ¹é…
                best_matches = []
                
                for target_record in target_samples:
                    target_address = target_record.get('address', '')
                    if not target_address:
                        continue
                    
                    # æ ‡å‡†åŒ–ç›®æ ‡åœ°å€
                    normalized_target = normalize_address_for_matching(target_address)
                    
                    # è®¡ç®—åœ°å€ç›¸ä¼¼åº¦
                    similarity = self.similarity_calculator.calculate_address_similarity(
                        normalized_source, normalized_target
                    )
                    
                    if similarity >= 0.3:  # åªè€ƒè™‘æœ‰ä¸€å®šç›¸ä¼¼åº¦çš„å€™é€‰
                        best_matches.append({
                            'target_record': target_record,
                            'similarity': similarity,
                            'source_address': source_address,
                            'target_address': target_address,
                            'normalized_source': normalized_source,
                            'normalized_target': normalized_target
                        })
                
                # æŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œå–å‰5ä¸ª
                best_matches.sort(key=lambda x: x['similarity'], reverse=True)
                best_matches = best_matches[:5]
                
                # åˆ›å»ºæ ‡å‡†ç­”æ¡ˆå¯¹
                for match in best_matches:
                    # åŸºäºç›¸ä¼¼åº¦å’Œè§„åˆ™åˆ¤æ–­æ˜¯å¦ä¸ºæ­£ç¡®åŒ¹é…
                    is_correct_match = self._evaluate_match_correctness(
                        source_record, match['target_record'], match['similarity']
                    )
                    
                    ground_truth_pairs.append({
                        'source_record': source_record,
                        'target_record': match['target_record'],
                        'similarity_score': match['similarity'],
                        'is_correct_match': is_correct_match,
                        'source_address': match['source_address'],
                        'target_address': match['target_address'],
                        'normalized_source': match['normalized_source'],
                        'normalized_target': match['normalized_target'],
                        'match_type': self._classify_match_type(match['similarity'])
                    })
            
            logger.info(f"âœ… åˆ›å»ºäº† {len(ground_truth_pairs)} ä¸ªæ ‡å‡†ç­”æ¡ˆå¯¹")
            return ground_truth_pairs
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºæ ‡å‡†ç­”æ¡ˆå¯¹å¤±è´¥: {str(e)}")
            return []
    
    def _evaluate_match_correctness(self, source_record: Dict, target_record: Dict, similarity: float) -> bool:
        """
        è¯„ä¼°åŒ¹é…çš„æ­£ç¡®æ€§
        åŸºäºç›¸ä¼¼åº¦é˜ˆå€¼å’Œä¸šåŠ¡è§„åˆ™
        """
        # é«˜ç›¸ä¼¼åº¦ç›´æ¥è®¤ä¸ºæ­£ç¡®
        if similarity >= 0.9:
            return True
        
        # ä¸­ç­‰ç›¸ä¼¼åº¦éœ€è¦è¿›ä¸€æ­¥éªŒè¯
        if similarity >= 0.7:
            # æ£€æŸ¥å•ä½åç§°æ˜¯å¦ä¹Ÿç›¸ä¼¼
            source_name = source_record.get('unit_name', '')
            target_name = target_record.get('unit_name', '')
            
            if source_name and target_name:
                name_similarity = self.similarity_calculator.calculate_string_similarity(
                    source_name, target_name
                )
                # åœ°å€å’Œå•ä½åç§°éƒ½æœ‰ä¸€å®šç›¸ä¼¼åº¦ï¼Œè®¤ä¸ºæ­£ç¡®
                return name_similarity >= 0.6
            
            # åªæœ‰åœ°å€ç›¸ä¼¼åº¦ï¼Œéœ€è¦æ›´é«˜çš„é˜ˆå€¼
            return similarity >= 0.8
        
        # ä½ç›¸ä¼¼åº¦è®¤ä¸ºä¸æ­£ç¡®
        return False
    
    def _classify_match_type(self, similarity: float) -> str:
        """åˆ†ç±»åŒ¹é…ç±»å‹"""
        if similarity >= 0.9:
            return "high_precision"
        elif similarity >= 0.7:
            return "medium_precision"
        elif similarity >= 0.5:
            return "low_precision"
        else:
            return "poor_match"
    
    def run_baseline_test(self, ground_truth_pairs: List[Dict]) -> Dict:
        """
        è¿è¡ŒåŸºå‡†æµ‹è¯•
        ä½¿ç”¨å½“å‰ç³»ç»Ÿå¯¹æ ‡å‡†ç­”æ¡ˆå¯¹è¿›è¡ŒåŒ¹é…æµ‹è¯•
        """
        logger.info("ğŸ§ª å¼€å§‹è¿è¡ŒåŸºå‡†æµ‹è¯•...")
        
        test_results = {
            'total_pairs': len(ground_truth_pairs),
            'correct_predictions': 0,
            'false_positives': 0,
            'false_negatives': 0,
            'true_positives': 0,
            'true_negatives': 0,
            'detailed_results': [],
            'performance_metrics': {}
        }
        
        start_time = time.time()
        
        try:
            for i, pair in enumerate(ground_truth_pairs):
                logger.info(f"æµ‹è¯•ç¬¬ {i+1}/{len(ground_truth_pairs)} å¯¹...")
                
                source_record = pair['source_record']
                target_record = pair['target_record']
                expected_match = pair['is_correct_match']
                
                # ä½¿ç”¨å½“å‰ç³»ç»Ÿè®¡ç®—ç›¸ä¼¼åº¦
                predicted_similarity = self.similarity_calculator.calculate_address_similarity(
                    pair['source_address'], pair['target_address']
                )
                
                # åŸºäºé˜ˆå€¼åˆ¤æ–­ç³»ç»Ÿé¢„æµ‹ç»“æœ
                predicted_match = predicted_similarity >= self.test_config['similarity_threshold']
                
                # ç»Ÿè®¡ç»“æœ
                if expected_match and predicted_match:
                    test_results['true_positives'] += 1
                    test_results['correct_predictions'] += 1
                elif not expected_match and not predicted_match:
                    test_results['true_negatives'] += 1
                    test_results['correct_predictions'] += 1
                elif not expected_match and predicted_match:
                    test_results['false_positives'] += 1
                elif expected_match and not predicted_match:
                    test_results['false_negatives'] += 1
                
                # è®°å½•è¯¦ç»†ç»“æœ
                test_results['detailed_results'].append({
                    'pair_index': i,
                    'source_address': pair['source_address'],
                    'target_address': pair['target_address'],
                    'expected_match': expected_match,
                    'predicted_match': predicted_match,
                    'predicted_similarity': predicted_similarity,
                    'ground_truth_similarity': pair['similarity_score'],
                    'match_type': pair['match_type'],
                    'is_correct': expected_match == predicted_match
                })
        
        except Exception as e:
            logger.error(f"âŒ åŸºå‡†æµ‹è¯•æ‰§è¡Œå¤±è´¥: {str(e)}")
            return test_results
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        end_time = time.time()
        test_duration = end_time - start_time
        
        tp = test_results['true_positives']
        tn = test_results['true_negatives']
        fp = test_results['false_positives']
        fn = test_results['false_negatives']
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0
        accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0.0
        
        test_results['performance_metrics'] = {
            'precision': precision,
            'recall': recall,
            'f1_score': f1_score,
            'accuracy': accuracy,
            'test_duration': test_duration,
            'pairs_per_second': len(ground_truth_pairs) / test_duration if test_duration > 0 else 0
        }
        
        logger.info(f"âœ… åŸºå‡†æµ‹è¯•å®Œæˆ")
        logger.info(f"ğŸ“Š å‡†ç¡®ç‡: {accuracy:.3f}, ç²¾ç¡®ç‡: {precision:.3f}, å¬å›ç‡: {recall:.3f}, F1åˆ†æ•°: {f1_score:.3f}")
        
        return test_results
    
    def analyze_results(self, test_results: Dict) -> Dict:
        """
        åˆ†ææµ‹è¯•ç»“æœ
        è¯†åˆ«è¯¯åŒ¹é…æ¡ˆä¾‹å’Œä¼˜åŒ–æ–¹å‘
        """
        logger.info("ğŸ“ˆ åˆ†ææµ‹è¯•ç»“æœ...")
        
        analysis = {
            'summary': {},
            'error_analysis': {},
            'optimization_recommendations': []
        }
        
        try:
            # åŸºç¡€ç»Ÿè®¡
            metrics = test_results['performance_metrics']
            analysis['summary'] = {
                'total_pairs_tested': test_results['total_pairs'],
                'accuracy': metrics['accuracy'],
                'precision': metrics['precision'],
                'recall': metrics['recall'],
                'f1_score': metrics['f1_score'],
                'test_duration': metrics['test_duration'],
                'processing_speed': metrics['pairs_per_second']
            }
            
            # é”™è¯¯åˆ†æ
            false_positives = []
            false_negatives = []
            
            for result in test_results['detailed_results']:
                if not result['is_correct']:
                    if result['predicted_match'] and not result['expected_match']:
                        false_positives.append(result)
                    elif not result['predicted_match'] and result['expected_match']:
                        false_negatives.append(result)
            
            analysis['error_analysis'] = {
                'false_positives_count': len(false_positives),
                'false_negatives_count': len(false_negatives),
                'false_positive_examples': false_positives[:5],  # å‰5ä¸ªç¤ºä¾‹
                'false_negative_examples': false_negatives[:5]   # å‰5ä¸ªç¤ºä¾‹
            }
            
            # ç”Ÿæˆä¼˜åŒ–å»ºè®®
            recommendations = []
            
            if metrics['precision'] < 0.8:
                recommendations.append({
                    'issue': 'precision_low',
                    'description': f'ç²¾ç¡®ç‡åä½ ({metrics["precision"]:.3f})',
                    'suggestion': 'æé«˜ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œå‡å°‘è¯¯åŒ¹é…',
                    'priority': 'high'
                })
            
            if metrics['recall'] < 0.7:
                recommendations.append({
                    'issue': 'recall_low', 
                    'description': f'å¬å›ç‡åä½ ({metrics["recall"]:.3f})',
                    'suggestion': 'é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼æˆ–ä¼˜åŒ–åœ°å€æ ‡å‡†åŒ–',
                    'priority': 'high'
                })
            
            if len(false_positives) > len(false_negatives) * 2:
                recommendations.append({
                    'issue': 'too_many_false_positives',
                    'description': 'è¯¯åŒ¹é…è¿‡å¤š',
                    'suggestion': 'åŠ å¼ºåœ°å€å±‚çº§éªŒè¯ï¼Œæé«˜åŒ¹é…ä¸¥æ ¼æ€§',
                    'priority': 'medium'
                })
            
            analysis['optimization_recommendations'] = recommendations
            
            logger.info(f"âœ… ç»“æœåˆ†æå®Œæˆï¼Œç”Ÿæˆäº† {len(recommendations)} æ¡ä¼˜åŒ–å»ºè®®")
            
        except Exception as e:
            logger.error(f"âŒ ç»“æœåˆ†æå¤±è´¥: {str(e)}")
        
        return analysis
    
    def save_benchmark_report(self, test_results: Dict, analysis: Dict) -> str:
        """
        ä¿å­˜åŸºå‡†æµ‹è¯•æŠ¥å‘Š
        """
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_filename = f'address_precision_benchmark_report_{timestamp}.json'
        
        report = {
            'test_info': {
                'timestamp': timestamp,
                'test_config': self.test_config,
                'system_version': '2.0.8'
            },
            'test_results': test_results,
            'analysis': analysis
        }
        
        try:
            with open(report_filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ“„ åŸºå‡†æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_filename}")
            return report_filename
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {str(e)}")
            return ""
    
    def run_complete_benchmark(self) -> Dict:
        """
        è¿è¡Œå®Œæ•´çš„åŸºå‡†æµ‹è¯•æµç¨‹
        """
        logger.info("ğŸš€ å¼€å§‹å®Œæ•´åŸºå‡†æµ‹è¯•æµç¨‹...")
        
        try:
            # 1. å‡†å¤‡æµ‹è¯•æ•°æ®é›†
            test_samples = self.prepare_test_dataset()
            if not test_samples:
                raise Exception("æ— æ³•å‡†å¤‡æµ‹è¯•æ•°æ®é›†")
            
            # 2. åˆ›å»ºæ ‡å‡†ç­”æ¡ˆå¯¹
            ground_truth_pairs = self.create_ground_truth_pairs(test_samples)
            if not ground_truth_pairs:
                raise Exception("æ— æ³•åˆ›å»ºæ ‡å‡†ç­”æ¡ˆå¯¹")
            
            # 3. è¿è¡ŒåŸºå‡†æµ‹è¯•
            test_results = self.run_baseline_test(ground_truth_pairs)
            
            # 4. åˆ†æç»“æœ
            analysis = self.analyze_results(test_results)
            
            # 5. ä¿å­˜æŠ¥å‘Š
            report_file = self.save_benchmark_report(test_results, analysis)
            
            logger.info("ğŸ‰ å®Œæ•´åŸºå‡†æµ‹è¯•æµç¨‹å®Œæˆï¼")
            
            return {
                'success': True,
                'test_results': test_results,
                'analysis': analysis,
                'report_file': report_file
            }
            
        except Exception as e:
            logger.error(f"âŒ åŸºå‡†æµ‹è¯•æµç¨‹å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ¯ åœ°å€åŒ¹é…ç²¾å‡†åº¦åŸºå‡†æµ‹è¯•å¼€å§‹")
    
    try:
        # åˆ›å»ºåŸºå‡†æµ‹è¯•å™¨
        benchmark = AddressPrecisionBenchmark()
        
        # è¿è¡Œå®Œæ•´æµ‹è¯•
        result = benchmark.run_complete_benchmark()
        
        if result['success']:
            # è¾“å‡ºå…³é”®æŒ‡æ ‡
            metrics = result['test_results']['performance_metrics']
            print("\n" + "="*60)
            print("ğŸ“Š åœ°å€åŒ¹é…ç²¾å‡†åº¦åŸºå‡†æµ‹è¯•ç»“æœ")
            print("="*60)
            print(f"å‡†ç¡®ç‡ (Accuracy): {metrics['accuracy']:.3f}")
            print(f"ç²¾ç¡®ç‡ (Precision): {metrics['precision']:.3f}")
            print(f"å¬å›ç‡ (Recall): {metrics['recall']:.3f}")
            print(f"F1åˆ†æ•°: {metrics['f1_score']:.3f}")
            print(f"å¤„ç†é€Ÿåº¦: {metrics['pairs_per_second']:.1f} å¯¹/ç§’")
            print(f"æµ‹è¯•ç”¨æ—¶: {metrics['test_duration']:.1f} ç§’")
            print("="*60)
            
            # è¾“å‡ºä¼˜åŒ–å»ºè®®
            recommendations = result['analysis']['optimization_recommendations']
            if recommendations:
                print("\nğŸ¯ ä¼˜åŒ–å»ºè®®:")
                for i, rec in enumerate(recommendations, 1):
                    print(f"{i}. {rec['description']}")
                    print(f"   å»ºè®®: {rec['suggestion']}")
                    print(f"   ä¼˜å…ˆçº§: {rec['priority']}")
            
            print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {result['report_file']}")
        else:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {result['error']}")
    
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")


if __name__ == "__main__":
    main()
