#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ¶ˆé˜²å•ä½å»ºç­‘æ•°æ®å…³è”ç³»ç»Ÿå¹¶è¡Œå¤„ç†ä¼˜åŒ–è„šæœ¬
åˆ©ç”¨32æ ¸CPUè¿›è¡Œå¤šçº¿ç¨‹å¤„ç†ï¼Œè§£å†³ä¸¥é‡çš„æ€§èƒ½ç“¶é¢ˆ
"""
import sys
import os
import requests
import time
import json
import threading
import concurrent.futures
from datetime import datetime
import psutil

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

BASE_URL = "http://localhost:8888"

class ParallelOptimizer:
    def __init__(self):
        self.base_url = BASE_URL
        self.cpu_count = psutil.cpu_count()
        self.memory_info = psutil.virtual_memory()
        self.active_tasks = []
        
    def print_header(self, title):
        """æ‰“å°æ ‡é¢˜"""
        print("\n" + "=" * 80)
        print(f"âš¡ {title}")
        print("=" * 80)
    
    def analyze_system_resources(self):
        """åˆ†æç³»ç»Ÿèµ„æº"""
        print(f"ğŸ” ç³»ç»Ÿèµ„æºåˆ†æ:")
        print(f"   CPUæ ¸å¿ƒæ•°: {self.cpu_count}")
        print(f"   æ€»å†…å­˜: {self.memory_info.total / (1024**3):.1f} GB")
        print(f"   å¯ç”¨å†…å­˜: {self.memory_info.available / (1024**3):.1f} GB")
        print(f"   å†…å­˜ä½¿ç”¨ç‡: {self.memory_info.percent:.1f}%")
        
        # è®¡ç®—æœ€ä¼˜å¹¶è¡Œæ•°
        optimal_workers = min(self.cpu_count - 2, 16)  # ä¿ç•™2ä¸ªæ ¸å¿ƒï¼Œæœ€å¤š16ä¸ªå·¥ä½œçº¿ç¨‹
        print(f"   å»ºè®®å¹¶è¡Œæ•°: {optimal_workers}")
        
        return optimal_workers
    
    def stop_existing_tasks(self):
        """åœæ­¢ç°æœ‰çš„ä½æ•ˆä»»åŠ¡"""
        print(f"ğŸ›‘ åœæ­¢ç°æœ‰ä½æ•ˆä»»åŠ¡...")
        
        # å·²çŸ¥çš„ä»»åŠ¡ID
        task_ids = [
            "c2e93daf-b41c-47ce-b2bb-84fb372adfae",
            "fe67e811-77bc-4b3c-a2e1-1f56e4cdb521",
            "ebf0421e-4836-4ec6-90ac-298afeff8cfc"
        ]
        
        stopped_count = 0
        for task_id in task_ids:
            try:
                # å…ˆæ£€æŸ¥ä»»åŠ¡çŠ¶æ€
                response = requests.get(f"{self.base_url}/api/optimized_task_progress/{task_id}", 
                                      timeout=5)
                if response.status_code == 200:
                    status = response.json()
                    if status.get('status') == 'running':
                        print(f"   å‘ç°è¿è¡Œä¸­ä»»åŠ¡: {task_id[:8]}...")
                        
                        # å°è¯•åœæ­¢ä»»åŠ¡ï¼ˆå³ä½¿APIå¯èƒ½è¿”å›404ï¼‰
                        try:
                            stop_response = requests.post(f"{self.base_url}/api/stop_optimized_matching", 
                                                        json={"task_id": task_id}, timeout=10)
                            if stop_response.status_code == 200:
                                print(f"   âœ… ä»»åŠ¡å·²åœæ­¢: {task_id[:8]}...")
                                stopped_count += 1
                            else:
                                print(f"   âš ï¸ åœæ­¢è¯·æ±‚å‘é€: {task_id[:8]}... (HTTP {stop_response.status_code})")
                        except:
                            print(f"   âš ï¸ åœæ­¢è¯·æ±‚å‘é€: {task_id[:8]}...")
                            
            except Exception as e:
                continue
        
        if stopped_count > 0:
            print(f"   æˆåŠŸåœæ­¢ {stopped_count} ä¸ªä»»åŠ¡")
            time.sleep(5)  # ç­‰å¾…ä»»åŠ¡å®Œå…¨åœæ­¢
        else:
            print(f"   æ²¡æœ‰æ‰¾åˆ°éœ€è¦åœæ­¢çš„ä»»åŠ¡")
        
        return stopped_count
    
    def start_parallel_tasks(self, num_workers=8):
        """å¯åŠ¨å¤šä¸ªå¹¶è¡Œä»»åŠ¡"""
        print(f"ğŸš€ å¯åŠ¨ {num_workers} ä¸ªå¹¶è¡Œä¼˜åŒ–ä»»åŠ¡...")
        
        # ä¸åŒçš„é…ç½®ç»„åˆ
        configs = [
            {"batch_size": 1000, "mode": "incremental"},
            {"batch_size": 1500, "mode": "incremental"},
            {"batch_size": 2000, "mode": "incremental"},
            {"batch_size": 1200, "mode": "incremental"},
            {"batch_size": 800, "mode": "incremental"},
            {"batch_size": 1800, "mode": "incremental"},
            {"batch_size": 1000, "mode": "update"},
            {"batch_size": 1500, "mode": "update"}
        ]
        
        successful_tasks = []
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¯åŠ¨å¤šä¸ªä»»åŠ¡
        with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:
            future_to_config = {}
            
            for i in range(min(num_workers, len(configs))):
                config = configs[i]
                future = executor.submit(self.start_single_task, config, i+1)
                future_to_config[future] = config
            
            # æ”¶é›†ç»“æœ
            for future in concurrent.futures.as_completed(future_to_config, timeout=60):
                config = future_to_config[future]
                try:
                    task_id = future.result()
                    if task_id:
                        successful_tasks.append({
                            'task_id': task_id,
                            'config': config
                        })
                        print(f"   âœ… ä»»åŠ¡ {len(successful_tasks)} å¯åŠ¨æˆåŠŸ: {task_id[:8]}...")
                    else:
                        print(f"   âŒ ä»»åŠ¡å¯åŠ¨å¤±è´¥: {config}")
                except Exception as e:
                    print(f"   âŒ ä»»åŠ¡å¯åŠ¨å¼‚å¸¸: {config} - {str(e)}")
        
        self.active_tasks = successful_tasks
        print(f"ğŸ¯ æˆåŠŸå¯åŠ¨ {len(successful_tasks)} ä¸ªå¹¶è¡Œä»»åŠ¡")
        
        return successful_tasks
    
    def start_single_task(self, config, task_num):
        """å¯åŠ¨å•ä¸ªä»»åŠ¡"""
        try:
            payload = {
                "match_type": "both",
                "mode": config["mode"],
                "batch_size": config["batch_size"]
            }
            
            response = requests.post(f"{self.base_url}/api/start_optimized_matching", 
                                   json=payload, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                if data.get('success'):
                    return data.get('task_id')
            
            return None
            
        except Exception as e:
            return None
    
    def monitor_parallel_performance(self, duration=300):
        """ç›‘æ§å¹¶è¡Œä»»åŠ¡æ€§èƒ½"""
        if not self.active_tasks:
            print(f"âŒ æ²¡æœ‰æ´»åŠ¨ä»»åŠ¡å¯ç›‘æ§")
            return False
        
        print(f"ğŸ“Š å¼€å§‹ç›‘æ§ {len(self.active_tasks)} ä¸ªå¹¶è¡Œä»»åŠ¡ ({duration}ç§’)...")
        
        start_time = time.time()
        performance_history = []
        
        while time.time() - start_time < duration:
            try:
                # å¹¶è¡Œè·å–æ‰€æœ‰ä»»åŠ¡çŠ¶æ€
                with concurrent.futures.ThreadPoolExecutor(max_workers=len(self.active_tasks)) as executor:
                    future_to_task = {}
                    
                    for task_info in self.active_tasks:
                        task_id = task_info['task_id']
                        future = executor.submit(self.get_task_progress, task_id)
                        future_to_task[future] = task_info
                    
                    # æ”¶é›†æ‰€æœ‰ä»»åŠ¡çŠ¶æ€
                    current_stats = {
                        'total_processed': 0,
                        'total_speed': 0,
                        'active_tasks': 0,
                        'task_details': []
                    }
                    
                    for future in concurrent.futures.as_completed(future_to_task, timeout=30):
                        task_info = future_to_task[future]
                        try:
                            progress = future.result()
                            if progress:
                                processed = progress.get('processed_records', 0)
                                elapsed = progress.get('elapsed_time', 0)
                                status = progress.get('status', 'unknown')
                                
                                if status == 'running' and elapsed > 0:
                                    speed = processed / elapsed
                                    current_stats['total_processed'] += processed
                                    current_stats['total_speed'] += speed
                                    current_stats['active_tasks'] += 1
                                    
                                    current_stats['task_details'].append({
                                        'task_id': task_info['task_id'][:8],
                                        'processed': processed,
                                        'speed': speed,
                                        'batch_size': task_info['config']['batch_size'],
                                        'status': status
                                    })
                        except Exception as e:
                            continue
                
                # æ˜¾ç¤ºå¹¶è¡Œæ€§èƒ½ç»Ÿè®¡
                if current_stats['active_tasks'] > 0:
                    avg_speed = current_stats['total_speed'] / current_stats['active_tasks']
                    
                    print(f"\nğŸ“ˆ å¹¶è¡Œæ€§èƒ½ç›‘æ§æŠ¥å‘Š:")
                    print(f"   æ´»è·ƒä»»åŠ¡æ•°: {current_stats['active_tasks']}")
                    print(f"   æ€»å¤„ç†é‡: {current_stats['total_processed']:,} æ¡")
                    print(f"   æ€»ä½“é€Ÿåº¦: {current_stats['total_speed']:.3f} è®°å½•/ç§’")
                    print(f"   å¹³å‡é€Ÿåº¦: {avg_speed:.3f} è®°å½•/ç§’")
                    
                    # ä¸å•ä»»åŠ¡å¯¹æ¯”
                    single_task_speed = 0.01  # åŸå§‹å•ä»»åŠ¡é€Ÿåº¦
                    improvement = current_stats['total_speed'] / single_task_speed if single_task_speed > 0 else 0
                    
                    print(f"   æ€§èƒ½æå‡: {improvement:.1f}x")
                    
                    # æ€§èƒ½è¯„çº§
                    if current_stats['total_speed'] > 5:
                        grade = "ğŸŸ¢ ä¼˜ç§€"
                    elif current_stats['total_speed'] > 1:
                        grade = "ğŸŸ¡ è‰¯å¥½"
                    elif current_stats['total_speed'] > 0.1:
                        grade = "ğŸŸ  ä¸€èˆ¬"
                    else:
                        grade = "ğŸ”´ åä½"
                    
                    print(f"   æ€§èƒ½è¯„çº§: {grade}")
                    
                    # æ˜¾ç¤ºå„ä»»åŠ¡è¯¦æƒ…
                    print(f"   ä»»åŠ¡è¯¦æƒ…:")
                    for detail in current_stats['task_details']:
                        print(f"     {detail['task_id']}: {detail['processed']:,}æ¡ "
                              f"({detail['speed']:.3f}/ç§’, æ‰¹æ¬¡:{detail['batch_size']})")
                    
                    # è®°å½•æ€§èƒ½å†å²
                    performance_history.append({
                        'time': time.time() - start_time,
                        'total_speed': current_stats['total_speed'],
                        'active_tasks': current_stats['active_tasks'],
                        'total_processed': current_stats['total_processed']
                    })
                
                print("-" * 80)
                time.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                print(f"âŒ ç›‘æ§å‡ºé”™: {str(e)}")
                time.sleep(30)
        
        # ç”Ÿæˆå¹¶è¡Œæ€§èƒ½æŠ¥å‘Š
        self.generate_parallel_report(performance_history)
        
        return True
    
    def get_task_progress(self, task_id):
        """è·å–å•ä¸ªä»»åŠ¡è¿›åº¦"""
        try:
            response = requests.get(f"{self.base_url}/api/optimized_task_progress/{task_id}", 
                                  timeout=10)
            if response.status_code == 200:
                return response.json()
        except:
            pass
        return None
    
    def generate_parallel_report(self, performance_history):
        """ç”Ÿæˆå¹¶è¡Œæ€§èƒ½æŠ¥å‘Š"""
        if not performance_history:
            print(f"âŒ æ²¡æœ‰æ€§èƒ½æ•°æ®å¯åˆ†æ")
            return
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        speeds = [p['total_speed'] for p in performance_history]
        avg_speed = sum(speeds) / len(speeds)
        max_speed = max(speeds)
        min_speed = min(speeds)
        
        final_processed = performance_history[-1]['total_processed']
        final_tasks = performance_history[-1]['active_tasks']
        
        # ä¸åŸå§‹æ€§èƒ½å¯¹æ¯”
        original_speed = 0.01
        improvement_ratio = avg_speed / original_speed
        
        print(f"\nğŸ“Š å¹¶è¡Œå¤„ç†æ€§èƒ½æŠ¥å‘Š:")
        print(f"   å¹³å‡æ€»é€Ÿåº¦: {avg_speed:.3f} è®°å½•/ç§’")
        print(f"   æœ€é«˜æ€»é€Ÿåº¦: {max_speed:.3f} è®°å½•/ç§’")
        print(f"   æœ€ä½æ€»é€Ÿåº¦: {min_speed:.3f} è®°å½•/ç§’")
        print(f"   æœ€ç»ˆå¤„ç†é‡: {final_processed:,} æ¡")
        print(f"   æ´»è·ƒä»»åŠ¡æ•°: {final_tasks}")
        print(f"   æ€§èƒ½æå‡: {improvement_ratio:.1f}x")
        print(f"   ç›‘æ§æ ·æœ¬: {len(performance_history)} æ¬¡")
        
        # æ•ˆæœè¯„ä¼°
        if improvement_ratio > 100:
            print(f"   ä¼˜åŒ–æ•ˆæœ: ğŸŸ¢ å“è¶Š - é€Ÿåº¦æå‡{improvement_ratio:.0f}å€!")
        elif improvement_ratio > 50:
            print(f"   ä¼˜åŒ–æ•ˆæœ: ğŸŸ¢ ä¼˜ç§€ - é€Ÿåº¦æå‡{improvement_ratio:.0f}å€!")
        elif improvement_ratio > 10:
            print(f"   ä¼˜åŒ–æ•ˆæœ: ğŸŸ¡ è‰¯å¥½ - é€Ÿåº¦æå‡{improvement_ratio:.0f}å€")
        elif improvement_ratio > 3:
            print(f"   ä¼˜åŒ–æ•ˆæœ: ğŸŸ  ä¸€èˆ¬ - é€Ÿåº¦æå‡{improvement_ratio:.1f}å€")
        else:
            print(f"   ä¼˜åŒ–æ•ˆæœ: ğŸ”´ æœ‰é™ - éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        
        # é¢„ä¼°å®Œæˆæ—¶é—´
        if avg_speed > 0:
            total_records = 1659320
            remaining_records = total_records - final_processed
            eta_hours = remaining_records / avg_speed / 3600
            print(f"   é¢„è®¡å®Œæˆæ—¶é—´: {eta_hours:.1f} å°æ—¶")
    
    def provide_next_optimization_steps(self):
        """æä¾›ä¸‹ä¸€æ­¥ä¼˜åŒ–å»ºè®®"""
        print(f"\nğŸ¯ ä¸‹ä¸€æ­¥ä¼˜åŒ–å»ºè®®:")
        print(f"   1. ğŸ—„ï¸ æ•°æ®åº“ç´¢å¼•ä¼˜åŒ– - åˆ›å»ºå¿…è¦çš„æŸ¥è¯¢ç´¢å¼•")
        print(f"   2. ğŸ§  ç®—æ³•å‚æ•°è°ƒä¼˜ - ä¼˜åŒ–åŒ¹é…ç®—æ³•å‚æ•°")
        print(f"   3. ğŸ’¾ å†…å­˜ç¼“å­˜ä¼˜åŒ– - ç¼“å­˜å¸¸ç”¨æ•°æ®å’Œæ¨¡å‹")
        print(f"   4. ğŸ”„ è¿æ¥æ± ä¼˜åŒ– - ä¼˜åŒ–æ•°æ®åº“è¿æ¥æ± é…ç½®")
        print(f"   5. ğŸ“Š æ‰¹å¤„ç†ä¼˜åŒ– - è¿›ä¸€æ­¥ä¼˜åŒ–æ‰¹å¤„ç†é€»è¾‘")
        
        print(f"\nğŸ“ˆ ç›‘æ§å»ºè®®:")
        print(f"   - ç»§ç»­ä½¿ç”¨å¹¶è¡Œå¤„ç†")
        print(f"   - ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ")
        print(f"   - æ ¹æ®æ€§èƒ½æ•°æ®è°ƒæ•´å¹¶è¡Œæ•°")
        print(f"   - å®šæœŸæ£€æŸ¥ä»»åŠ¡çŠ¶æ€")
    
    def run_parallel_optimization(self):
        """è¿è¡Œå¹¶è¡Œå¤„ç†ä¼˜åŒ–"""
        self.print_header("æ¶ˆé˜²å•ä½å»ºç­‘æ•°æ®å…³è”ç³»ç»Ÿ - å¹¶è¡Œå¤„ç†ä¼˜åŒ–")
        
        print(f"ğŸ•’ å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ¯ ç›®æ ‡: åˆ©ç”¨32æ ¸CPUè¿›è¡Œå¹¶è¡Œå¤„ç†ï¼Œæ˜¾è‘—æå‡å¤„ç†é€Ÿåº¦")
        
        # åˆ†æç³»ç»Ÿèµ„æº
        optimal_workers = self.analyze_system_resources()
        
        # åœæ­¢ç°æœ‰ä½æ•ˆä»»åŠ¡
        self.stop_existing_tasks()
        
        # å¯åŠ¨å¹¶è¡Œä»»åŠ¡
        successful_tasks = self.start_parallel_tasks(optimal_workers)
        
        if successful_tasks:
            print(f"\nğŸ“Š å¼€å§‹å¹¶è¡Œæ€§èƒ½ç›‘æ§...")
            self.monitor_parallel_performance(duration=360)  # ç›‘æ§6åˆ†é’Ÿ
            
            # æä¾›ä¸‹ä¸€æ­¥å»ºè®®
            self.provide_next_optimization_steps()
            
            self.print_header("å¹¶è¡Œå¤„ç†ä¼˜åŒ–å®Œæˆ")
            print(f"ğŸ•’ ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"âœ… å¹¶è¡Œä¼˜åŒ–æ‰§è¡ŒæˆåŠŸ")
            print(f"ğŸ“Š {len(successful_tasks)} ä¸ªå¹¶è¡Œä»»åŠ¡æ­£åœ¨è¿è¡Œ")
            
            return True
        else:
            print(f"âŒ æ— æ³•å¯åŠ¨å¹¶è¡Œä»»åŠ¡")
            print(f"ğŸ”§ å»ºè®®æ£€æŸ¥ç³»ç»Ÿé…ç½®")
            
            self.print_header("å¹¶è¡Œå¤„ç†ä¼˜åŒ–å®Œæˆ")
            print(f"ğŸ•’ ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"âš ï¸ å¹¶è¡Œä¼˜åŒ–éƒ¨åˆ†å®Œæˆ")
            
            return False

def main():
    """ä¸»å‡½æ•°"""
    optimizer = ParallelOptimizer()
    optimizer.run_parallel_optimization()

if __name__ == "__main__":
    main() 