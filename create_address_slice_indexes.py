#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åœ°å€å­—æ®µåˆ‡ç‰‡ç´¢å¼•åˆ›å»ºè„šæœ¬
ä¸ºhztj_hzxxå’Œdwd_yljgxxè¡¨çš„åœ°å€å­—æ®µåˆ›å»ºN-gramåˆ‡ç‰‡ç´¢å¼•ï¼Œå®ç°é«˜æ•ˆåœ°å€åŒ¹é…
"""

import pymongo
import re
import time
from datetime import datetime

class AddressSliceIndexer:
    def __init__(self):
        """åˆå§‹åŒ–åœ°å€ç´¢å¼•å™¨"""
        self.client = pymongo.MongoClient('mongodb://localhost:27017/')
        self.db = self.client['Unit_Info']
        self.stats = {
            'slice_indexes_created': 0,
            'keyword_indexes_created': 0,
            'processing_time': 0,
            'total_slices': 0
        }
        
        print("ğŸ”§ åœ°å€åˆ‡ç‰‡ç´¢å¼•å™¨åˆå§‹åŒ–å®Œæˆ")
        
    def extract_address_keywords(self, address: str) -> set:
        """æå–åœ°å€å…³é”®è¯"""
        if not address:
            return set()
        
        address_str = str(address).strip()
        keywords = set()
        
        # 1. æå–é—¨ç‰Œå·ï¼ˆæ•°å­—+å·ï¼‰
        door_numbers = re.findall(r'\d+å·', address_str)
        keywords.update(door_numbers)
        
        # 2. æå–è¡—é“è·¯å
        street_patterns = [
            r'[\u4e00-\u9fff]+è·¯\d*å·?',  # XXè·¯
            r'[\u4e00-\u9fff]+è¡—\d*å·?',  # XXè¡—  
            r'[\u4e00-\u9fff]+é“\d*å·?',  # XXé“
            r'[\u4e00-\u9fff]+å¤§é“\d*å·?', # XXå¤§é“
        ]
        for pattern in street_patterns:
            streets = re.findall(pattern, address_str)
            keywords.update(streets)
        
        # 3. æå–åŒºå¿
        district_pattern = r'[\u4e00-\u9fff]+åŒº'
        districts = re.findall(district_pattern, address_str)
        keywords.update(districts)
        
        # 4. æå–å»ºç­‘ç‰©åç§°ï¼ˆåŒ…å«ç‰¹å®šåç¼€çš„è¯ï¼‰
        building_patterns = [
            r'[\u4e00-\u9fff]+å¤§å¦',
            r'[\u4e00-\u9fff]+å¤§æ¥¼', 
            r'[\u4e00-\u9fff]+ä¸­å¿ƒ',
            r'[\u4e00-\u9fff]+å¹¿åœº',
            r'[\u4e00-\u9fff]+å…»è€é™¢',
            r'[\u4e00-\u9fff]+åŒ»é™¢',
            r'[\u4e00-\u9fff]+å­¦æ ¡',
        ]
        for pattern in building_patterns:
            buildings = re.findall(pattern, address_str)
            keywords.update(buildings)
        
        # 5. æå–è¿ç»­çš„åœ°å€ç‰‡æ®µï¼ˆ3-6ä¸ªå­—ç¬¦ï¼‰
        clean_address = re.sub(r'[^\u4e00-\u9fff\d]', '', address_str)
        for i in range(len(clean_address) - 2):
            for length in [3, 4, 5, 6]:
                if i + length <= len(clean_address):
                    segment = clean_address[i:i+length]
                    if len(segment) >= 3:
                        keywords.add(segment)
        
        # è¿‡æ»¤æ‰å¤ªçŸ­æˆ–å¤ªå¸¸è§çš„å…³é”®è¯
        filtered_keywords = set()
        common_words = {'ä¸Šæµ·å¸‚', 'å¸‚è¾–åŒº', 'ä¸­å›½', 'æœ‰é™å…¬å¸', 'è‚¡ä»½'}
        
        for keyword in keywords:
            if len(keyword) >= 3 and keyword not in common_words:
                filtered_keywords.add(keyword)
        
        return filtered_keywords
    
    def create_address_indexes_for_table(self, table_name: str, address_field: str):
        """ä¸ºæŒ‡å®šè¡¨çš„åœ°å€å­—æ®µåˆ›å»ºç´¢å¼•"""
        print(f"\nğŸ“ ä¸ºè¡¨ {table_name} çš„å­—æ®µ {address_field} åˆ›å»ºåœ°å€ç´¢å¼•...")
        
        start_time = time.time()
        
        # è·å–æºè¡¨
        collection = self.db[table_name]
        
        # åˆ›å»ºç´¢å¼•è¡¨å
        slice_collection_name = f"{table_name}_address_slices"
        keyword_collection_name = f"{table_name}_address_keywords"
        
        # æ¸…ç©ºè¯¥å­—æ®µçš„ç°æœ‰ç´¢å¼•ï¼ˆè€Œä¸æ˜¯æ•´ä¸ªè¡¨ï¼‰
        keyword_collection = self.db[keyword_collection_name]
        keyword_collection.delete_many({"table_name": table_name, "field_name": address_field})
        
        slice_collection = self.db[slice_collection_name]
        keyword_collection = self.db[keyword_collection_name]
        
        # æ‰¹é‡å¤„ç†æ•°æ®
        batch_size = 1000
        slice_data = []
        keyword_data = []
        total_processed = 0
        
        print(f"   æ­£åœ¨å¤„ç†åœ°å€æ•°æ®...")
        
        # æŸ¥è¯¢æœ‰åœ°å€çš„è®°å½•
        query = {address_field: {"$exists": True, "$ne": ""}}
        total_records = collection.count_documents(query)
        print(f"   è¡¨ä¸­ {address_field} å­—æ®µæœ‰æ•°æ®çš„è®°å½•æ•°: {total_records}")
        
        if total_records == 0:
            print(f"   âš ï¸  å­—æ®µ {address_field} æ²¡æœ‰æ•°æ®ï¼Œè·³è¿‡")
            return {'processed_records': 0, 'keywords_created': 0, 'processing_time': 0}
        
        cursor = collection.find(query, {address_field: 1})
        
        for doc in cursor:
            address = doc.get(address_field, '')
            if not address:
                continue
            
            doc_id = doc['_id']
            
            # æå–åœ°å€å…³é”®è¯
            keywords = self.extract_address_keywords(address)
            
            # å‡†å¤‡å…³é”®è¯æ•°æ®
            for keyword in keywords:
                keyword_data.append({
                    'keyword': keyword,
                    'doc_id': doc_id,
                    'address': str(address),
                    'table_name': table_name,
                    'field_name': address_field
                })
            
            total_processed += 1
            
            # æ‰¹é‡æ’å…¥
            if len(keyword_data) >= batch_size:
                if keyword_data:
                    keyword_collection.insert_many(keyword_data)
                keyword_data = []
            
            if total_processed % 1000 == 0:
                print(f"   å·²å¤„ç†: {total_processed:,} æ¡è®°å½•")
        
        # æ’å…¥å‰©ä½™æ•°æ®
        if keyword_data:
            keyword_collection.insert_many(keyword_data)
        
        # åˆ›å»ºç´¢å¼•
        print(f"   åˆ›å»ºå…³é”®è¯ç´¢å¼•...")
        keyword_collection.create_index([('keyword', 1)])
        keyword_collection.create_index([('doc_id', 1)])
        keyword_collection.create_index([('table_name', 1)])
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        # ç»Ÿè®¡ç»“æœ
        keyword_count = keyword_collection.count_documents({})
        
        print(f"   âœ… å®Œæˆï¼")
        print(f"   å¤„ç†è®°å½•æ•°: {total_processed:,}")
        print(f"   ç”Ÿæˆå…³é”®è¯: {keyword_count:,}")
        print(f"   å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
        
        self.stats['keyword_indexes_created'] += keyword_count
        self.stats['processing_time'] += processing_time
        
        return {
            'processed_records': total_processed,
            'keywords_created': keyword_count,
            'processing_time': processing_time
        }
    
    def create_all_address_indexes(self):
        """ä¸ºæ‰€æœ‰ç›¸å…³è¡¨åˆ›å»ºåœ°å€ç´¢å¼•"""
        print("ğŸš€ å¼€å§‹åˆ›å»ºåœ°å€åˆ‡ç‰‡ç´¢å¼•...")
        
        # å®šä¹‰è¦å¤„ç†çš„è¡¨å’Œå­—æ®µ
        address_tables = [
            ('hztj_hzxx', 'èµ·ç«åœ°ç‚¹'),  # æºè¡¨ï¼šç«ç¾ç»Ÿè®¡ä¿¡æ¯
            ('dwd_yljgxx', 'ZCDZ'),    # ç›®æ ‡è¡¨ï¼šå…»è€æœºæ„ä¿¡æ¯çš„æ³¨å†Œåœ°å€
            ('dwd_yljgxx', 'FWCS_DZ'), # ç›®æ ‡è¡¨ï¼šå…»è€æœºæ„ä¿¡æ¯çš„æœåŠ¡åœºæ‰€åœ°å€
            ('dwd_yljgxx', 'NSYLJGDZ'), # ç›®æ ‡è¡¨ï¼šå…»è€æœºæ„ä¿¡æ¯çš„å†…è®¾å…»è€æœºæ„åœ°å€
        ]
        
        total_start_time = time.time()
        
        for table_name, address_field in address_tables:
            try:
                result = self.create_address_indexes_for_table(table_name, address_field)
                print(f"   {table_name}.{address_field}: {result['keywords_created']} ä¸ªå…³é”®è¯")
            except Exception as e:
                print(f"   âŒ {table_name}.{address_field} å¤„ç†å¤±è´¥: {e}")
        
        total_end_time = time.time()
        total_time = total_end_time - total_start_time
        
        print(f"\nğŸ‰ åœ°å€ç´¢å¼•åˆ›å»ºå®Œæˆï¼")
        print(f"æ€»å¤„ç†æ—¶é—´: {total_time:.2f}ç§’")
        print(f"æ€»å…³é”®è¯æ•°: {self.stats['keyword_indexes_created']:,}")
        
    def close(self):
        """å…³é—­è¿æ¥"""
        self.client.close()

def main():
    """ä¸»å‡½æ•°"""
    indexer = AddressSliceIndexer()
    
    try:
        indexer.create_all_address_indexes()
    except Exception as e:
        print(f"âŒ åˆ›å»ºåœ°å€ç´¢å¼•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        indexer.close()

if __name__ == "__main__":
    main()
