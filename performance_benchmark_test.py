#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ÊÄßËÉΩÂü∫ÂáÜÊµãËØï
‰ΩøÁî®10,000Êù°Êï∞ÊçÆËøõË°åÂéãÂäõÊµãËØïÔºåÈ™åËØÅ‰ºòÂåñÂêéÁöÑÁ≥ªÁªüÊÄßËÉΩË°®Áé∞
"""

import os
import sys
import logging
import json
import time
import threading
import multiprocessing
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import psutil

# Ê∑ªÂä†È°πÁõÆÊ†πÁõÆÂΩïÂà∞Ë∑ØÂæÑ
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.database.connection import DatabaseManager
from src.utils.config import ConfigManager
from src.matching.similarity_scorer import SimilarityCalculator
from src.matching.address_normalizer import normalize_address_for_matching

# ÈÖçÁΩÆÊó•Âøó
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class PerformanceBenchmarkTest:
    """ÊÄßËÉΩÂü∫ÂáÜÊµãËØïÂô®"""
    
    def __init__(self):
        """ÂàùÂßãÂåñÊµãËØïÂô®"""
        self.config_manager = ConfigManager()
        self.db_manager = DatabaseManager(config=self.config_manager.get_database_config())
        self.similarity_calculator = SimilarityCalculator(self.config_manager.get_matching_config())
        
        # ÊÄßËÉΩÁªüËÆ°
        self.performance_stats = {
            'total_comparisons': 0,
            'successful_matches': 0,
            'processing_times': [],
            'memory_usage': [],
            'cpu_usage': [],
            'throughput_per_second': 0,
            'average_response_time': 0,
            'peak_memory_usage': 0,
            'peak_cpu_usage': 0
        }
        
        # ÊµãËØïÈÖçÁΩÆ
        self.test_config = {
            'total_test_records': 10000,
            'batch_size': 100,
            'thread_count': 4,
            'similarity_threshold': 0.6,
            'max_comparisons_per_record': 50
        }
        
    def run_performance_benchmark(self):
        """ËøêË°åÊÄßËÉΩÂü∫ÂáÜÊµãËØï"""
        print("üöÄ ÊÄßËÉΩÂü∫ÂáÜÊµãËØï")
        print("=" * 50)
        
        try:
            # 1. ÂáÜÂ§áÊµãËØïÊï∞ÊçÆ
            print("üìä ÂáÜÂ§áÊµãËØïÊï∞ÊçÆ...")
            test_data = self._prepare_large_test_dataset()
            
            if not test_data['source_addresses'] or not test_data['target_addresses']:
                print("‚ùå ÊµãËØïÊï∞ÊçÆÂáÜÂ§áÂ§±Ë¥•")
                return
            
            print(f"‚úÖ ÊµãËØïÊï∞ÊçÆÂáÜÂ§áÂÆåÊàêÔºö{len(test_data['source_addresses'])} Êù°Ê∫êÂú∞ÂùÄÔºå{len(test_data['target_addresses'])} Êù°ÁõÆÊ†áÂú∞ÂùÄ")
            
            # 2. ÂçïÁ∫øÁ®ãÊÄßËÉΩÊµãËØï
            print("\nüîÑ ÂçïÁ∫øÁ®ãÊÄßËÉΩÊµãËØï...")
            single_thread_results = self._run_single_thread_test(test_data)
            
            # 3. Â§öÁ∫øÁ®ãÊÄßËÉΩÊµãËØï
            print("\nüîÑ Â§öÁ∫øÁ®ãÊÄßËÉΩÊµãËØï...")
            multi_thread_results = self._run_multi_thread_test(test_data)
            
            # 4. ÊâπÂ§ÑÁêÜÊÄßËÉΩÊµãËØï
            print("\nüîÑ ÊâπÂ§ÑÁêÜÊÄßËÉΩÊµãËØï...")
            batch_processing_results = self._run_batch_processing_test(test_data)
            
            # 5. ÂÜÖÂ≠òÂíåCPUÁõëÊéßÊµãËØï
            print("\nüîÑ ËµÑÊ∫ê‰ΩøÁî®ÁõëÊéßÊµãËØï...")
            resource_monitoring_results = self._run_resource_monitoring_test(test_data)
            
            # 6. ÁîüÊàêÁªºÂêàÊÄßËÉΩÊä•Âëä
            performance_report = self._generate_performance_report({
                'single_thread': single_thread_results,
                'multi_thread': multi_thread_results,
                'batch_processing': batch_processing_results,
                'resource_monitoring': resource_monitoring_results,
                'test_config': self.test_config,
                'system_info': self._get_system_info()
            })
            
            # 7. ‰øùÂ≠òÊä•Âëä
            report_filename = f"performance_benchmark_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(report_filename, 'w', encoding='utf-8') as f:
                json.dump(performance_report, f, ensure_ascii=False, indent=2)
            
            # 8. ÊòæÁ§∫ÁªìÊûúÊëòË¶Å
            self._display_performance_summary(performance_report)
            
            print(f"\nüìã ËØ¶ÁªÜÊÄßËÉΩÊä•ÂëäÂ∑≤‰øùÂ≠òÂà∞: {report_filename}")
            print("‚úÖ ÊÄßËÉΩÂü∫ÂáÜÊµãËØïÂÆåÊàê")
            
        except Exception as e:
            logger.error(f"ÊÄßËÉΩÂü∫ÂáÜÊµãËØïÂ§±Ë¥•: {str(e)}")
            print("‚ùå ÊÄßËÉΩÂü∫ÂáÜÊµãËØïÂ§±Ë¥•")
    
    def _prepare_large_test_dataset(self) -> Dict:
        """ÂáÜÂ§áÂ§ßËßÑÊ®°ÊµãËØïÊï∞ÊçÆÈõÜ"""
        try:
            # Ëé∑ÂèñÊ∫êË°®Êï∞ÊçÆ
            source_collection = self.db_manager.get_collection('hztj_hzxx')
            source_addresses = list(source_collection.find(
                {'Ëµ∑ÁÅ´Âú∞ÁÇπ': {'$exists': True, '$ne': ''}},
                {'Ëµ∑ÁÅ´Âú∞ÁÇπ': 1}
            ).limit(self.test_config['total_test_records']))
            
            # Ëé∑ÂèñÁõÆÊ†áË°®Êï∞ÊçÆ
            target_collection = self.db_manager.get_collection('dwd_yljgxx')
            target_addresses = list(target_collection.find(
                {'ZCDZ': {'$exists': True, '$ne': ''}},
                {'ZCDZ': 1}
            ).limit(self.test_config['total_test_records']))
            
            return {
                'source_addresses': [addr['Ëµ∑ÁÅ´Âú∞ÁÇπ'] for addr in source_addresses],
                'target_addresses': [addr['ZCDZ'] for addr in target_addresses]
            }
            
        except Exception as e:
            logger.error(f"ÂáÜÂ§áÊµãËØïÊï∞ÊçÆÂ§±Ë¥•: {str(e)}")
            return {'source_addresses': [], 'target_addresses': []}
    
    def _run_single_thread_test(self, test_data: Dict) -> Dict:
        """ËøêË°åÂçïÁ∫øÁ®ãÊÄßËÉΩÊµãËØï"""
        start_time = time.time()
        successful_matches = 0
        total_comparisons = 0
        processing_times = []
        
        # ÈôêÂà∂ÊµãËØïÊï∞Èáè‰ª•ÈÅøÂÖçËøáÈïøÊó∂Èó¥
        test_limit = min(1000, len(test_data['source_addresses']))
        
        for i, source_addr in enumerate(test_data['source_addresses'][:test_limit]):
            if i % 100 == 0:
                print(f"  Â§ÑÁêÜËøõÂ∫¶: {i}/{test_limit}")
            
            record_start_time = time.time()
            
            # Ê†áÂáÜÂåñÊ∫êÂú∞ÂùÄ
            normalized_source = normalize_address_for_matching(source_addr)
            
            best_score = 0.0
            # ÈôêÂà∂ÊØîËæÉÊï∞Èáè
            comparison_limit = min(self.test_config['max_comparisons_per_record'], len(test_data['target_addresses']))
            
            for target_addr in test_data['target_addresses'][:comparison_limit]:
                normalized_target = normalize_address_for_matching(target_addr)
                
                # ËÆ°ÁÆóÁõ∏‰ººÂ∫¶
                similarity = self.similarity_calculator.calculate_string_similarity(
                    normalized_source, normalized_target
                )
                
                if similarity > best_score:
                    best_score = similarity
                
                total_comparisons += 1
            
            if best_score >= self.test_config['similarity_threshold']:
                successful_matches += 1
            
            record_time = time.time() - record_start_time
            processing_times.append(record_time)
        
        total_time = time.time() - start_time
        
        return {
            'total_time': total_time,
            'successful_matches': successful_matches,
            'total_comparisons': total_comparisons,
            'records_processed': test_limit,
            'throughput_per_second': test_limit / total_time if total_time > 0 else 0,
            'average_response_time': sum(processing_times) / len(processing_times) if processing_times else 0,
            'match_rate': successful_matches / test_limit if test_limit > 0 else 0
        }
    
    def _run_multi_thread_test(self, test_data: Dict) -> Dict:
        """ËøêË°åÂ§öÁ∫øÁ®ãÊÄßËÉΩÊµãËØï"""
        start_time = time.time()
        successful_matches = 0
        total_comparisons = 0
        
        # ÈôêÂà∂ÊµãËØïÊï∞Èáè
        test_limit = min(1000, len(test_data['source_addresses']))
        
        def process_batch(batch_data):
            batch_matches = 0
            batch_comparisons = 0
            
            for source_addr in batch_data:
                normalized_source = normalize_address_for_matching(source_addr)
                best_score = 0.0
                
                comparison_limit = min(self.test_config['max_comparisons_per_record'], len(test_data['target_addresses']))
                
                for target_addr in test_data['target_addresses'][:comparison_limit]:
                    normalized_target = normalize_address_for_matching(target_addr)
                    similarity = self.similarity_calculator.calculate_string_similarity(
                        normalized_source, normalized_target
                    )
                    
                    if similarity > best_score:
                        best_score = similarity
                    
                    batch_comparisons += 1
                
                if best_score >= self.test_config['similarity_threshold']:
                    batch_matches += 1
            
            return batch_matches, batch_comparisons
        
        # ÂàÜÊâπÂ§ÑÁêÜ
        batch_size = self.test_config['batch_size']
        batches = [test_data['source_addresses'][i:i+batch_size] for i in range(0, test_limit, batch_size)]
        
        with ThreadPoolExecutor(max_workers=self.test_config['thread_count']) as executor:
            results = list(executor.map(process_batch, batches))
        
        for matches, comparisons in results:
            successful_matches += matches
            total_comparisons += comparisons
        
        total_time = time.time() - start_time
        
        return {
            'total_time': total_time,
            'successful_matches': successful_matches,
            'total_comparisons': total_comparisons,
            'records_processed': test_limit,
            'throughput_per_second': test_limit / total_time if total_time > 0 else 0,
            'match_rate': successful_matches / test_limit if test_limit > 0 else 0,
            'thread_count': self.test_config['thread_count']
        }
    
    def _run_batch_processing_test(self, test_data: Dict) -> Dict:
        """ËøêË°åÊâπÂ§ÑÁêÜÊÄßËÉΩÊµãËØï"""
        start_time = time.time()
        
        # ÊâπÈáèÈ¢ÑÂ§ÑÁêÜÂú∞ÂùÄ
        print("  ÊâπÈáèÊ†áÂáÜÂåñÊ∫êÂú∞ÂùÄ...")
        normalized_sources = []
        for addr in test_data['source_addresses'][:1000]:
            normalized_sources.append(normalize_address_for_matching(addr))
        
        print("  ÊâπÈáèÊ†áÂáÜÂåñÁõÆÊ†áÂú∞ÂùÄ...")
        normalized_targets = []
        for addr in test_data['target_addresses'][:1000]:
            normalized_targets.append(normalize_address_for_matching(addr))
        
        preprocessing_time = time.time() - start_time
        
        # ÊâπÈáèÁõ∏‰ººÂ∫¶ËÆ°ÁÆó
        matching_start_time = time.time()
        successful_matches = 0
        total_comparisons = 0
        
        for i, source in enumerate(normalized_sources[:500]):  # ÈôêÂà∂Êï∞Èáè
            if i % 100 == 0:
                print(f"  ÊâπÂ§ÑÁêÜËøõÂ∫¶: {i}/500")
            
            best_score = 0.0
            for target in normalized_targets[:50]:  # ÈôêÂà∂ÊØîËæÉÊï∞Èáè
                similarity = self.similarity_calculator.calculate_string_similarity(source, target)
                if similarity > best_score:
                    best_score = similarity
                total_comparisons += 1
            
            if best_score >= self.test_config['similarity_threshold']:
                successful_matches += 1
        
        matching_time = time.time() - matching_start_time
        total_time = time.time() - start_time
        
        return {
            'total_time': total_time,
            'preprocessing_time': preprocessing_time,
            'matching_time': matching_time,
            'successful_matches': successful_matches,
            'total_comparisons': total_comparisons,
            'records_processed': 500,
            'throughput_per_second': 500 / total_time if total_time > 0 else 0,
            'match_rate': successful_matches / 500 if successful_matches > 0 else 0
        }
    
    def _run_resource_monitoring_test(self, test_data: Dict) -> Dict:
        """ËøêË°åËµÑÊ∫ê‰ΩøÁî®ÁõëÊéßÊµãËØï"""
        memory_usage = []
        cpu_usage = []
        
        def monitor_resources():
            while getattr(monitor_resources, 'running', True):
                memory_usage.append(psutil.virtual_memory().percent)
                cpu_usage.append(psutil.cpu_percent())
                time.sleep(0.5)
        
        # ÂêØÂä®ÁõëÊéßÁ∫øÁ®ã
        monitor_resources.running = True
        monitor_thread = threading.Thread(target=monitor_resources)
        monitor_thread.start()
        
        try:
            # ÊâßË°å‰∏Ä‰∏™‰∏≠Á≠âËßÑÊ®°ÁöÑÊµãËØï
            start_time = time.time()
            successful_matches = 0
            
            for i, source_addr in enumerate(test_data['source_addresses'][:500]):
                if i % 100 == 0:
                    print(f"  ËµÑÊ∫êÁõëÊéßÊµãËØïËøõÂ∫¶: {i}/500")
                
                normalized_source = normalize_address_for_matching(source_addr)
                best_score = 0.0
                
                for target_addr in test_data['target_addresses'][:30]:
                    normalized_target = normalize_address_for_matching(target_addr)
                    similarity = self.similarity_calculator.calculate_string_similarity(
                        normalized_source, normalized_target
                    )
                    
                    if similarity > best_score:
                        best_score = similarity
                
                if best_score >= self.test_config['similarity_threshold']:
                    successful_matches += 1
            
            total_time = time.time() - start_time
            
        finally:
            # ÂÅúÊ≠¢ÁõëÊéß
            monitor_resources.running = False
            monitor_thread.join()
        
        return {
            'total_time': total_time,
            'successful_matches': successful_matches,
            'records_processed': 500,
            'peak_memory_usage': max(memory_usage) if memory_usage else 0,
            'average_memory_usage': sum(memory_usage) / len(memory_usage) if memory_usage else 0,
            'peak_cpu_usage': max(cpu_usage) if cpu_usage else 0,
            'average_cpu_usage': sum(cpu_usage) / len(cpu_usage) if cpu_usage else 0,
            'memory_samples': len(memory_usage),
            'cpu_samples': len(cpu_usage)
        }
    
    def _get_system_info(self) -> Dict:
        """Ëé∑ÂèñÁ≥ªÁªü‰ø°ÊÅØ"""
        return {
            'cpu_count': multiprocessing.cpu_count(),
            'memory_total_gb': round(psutil.virtual_memory().total / (1024**3), 2),
            'python_version': sys.version,
            'platform': sys.platform
        }
    
    def _generate_performance_report(self, results: Dict) -> Dict:
        """ÁîüÊàêÊÄßËÉΩÊä•Âëä"""
        return {
            'test_timestamp': datetime.now().isoformat(),
            'test_configuration': results['test_config'],
            'system_information': results['system_info'],
            'performance_results': {
                'single_thread_performance': results['single_thread'],
                'multi_thread_performance': results['multi_thread'],
                'batch_processing_performance': results['batch_processing'],
                'resource_monitoring': results['resource_monitoring']
            },
            'performance_comparison': {
                'single_vs_multi_thread_speedup': (
                    results['multi_thread']['throughput_per_second'] / 
                    results['single_thread']['throughput_per_second']
                ) if results['single_thread']['throughput_per_second'] > 0 else 0,
                'batch_processing_efficiency': (
                    results['batch_processing']['throughput_per_second'] / 
                    results['single_thread']['throughput_per_second']
                ) if results['single_thread']['throughput_per_second'] > 0 else 0
            },
            'recommendations': self._generate_performance_recommendations(results)
        }
    
    def _generate_performance_recommendations(self, results: Dict) -> List[str]:
        """ÁîüÊàêÊÄßËÉΩ‰ºòÂåñÂª∫ËÆÆ"""
        recommendations = []
        
        # Âü∫‰∫éÊµãËØïÁªìÊûúÁîüÊàêÂª∫ËÆÆ
        single_thread = results['single_thread']
        multi_thread = results['multi_thread']
        batch_processing = results['batch_processing']
        resource_monitoring = results['resource_monitoring']
        
        if multi_thread['throughput_per_second'] > single_thread['throughput_per_second'] * 1.5:
            recommendations.append("Â§öÁ∫øÁ®ãÂ§ÑÁêÜÊòæËëóÊèêÂçáÊÄßËÉΩÔºåÂª∫ËÆÆÂú®Áîü‰∫ßÁéØÂ¢É‰∏≠‰ΩøÁî®Â§öÁ∫øÁ®ãÂ§ÑÁêÜ")
        
        if batch_processing['throughput_per_second'] > single_thread['throughput_per_second'] * 1.2:
            recommendations.append("ÊâπÂ§ÑÁêÜÊ®°ÂºèÊèêÂçáÊÄßËÉΩÔºåÂª∫ËÆÆÂØπÂú∞ÂùÄËøõË°åÊâπÈáèÈ¢ÑÂ§ÑÁêÜ")
        
        if resource_monitoring['peak_memory_usage'] > 80:
            recommendations.append("ÂÜÖÂ≠ò‰ΩøÁî®ÁéáËæÉÈ´òÔºåÂª∫ËÆÆ‰ºòÂåñÂÜÖÂ≠òÁÆ°ÁêÜÊàñÂ¢ûÂä†Á≥ªÁªüÂÜÖÂ≠ò")
        
        if resource_monitoring['peak_cpu_usage'] > 90:
            recommendations.append("CPU‰ΩøÁî®ÁéáËæÉÈ´òÔºåÂª∫ËÆÆ‰ºòÂåñÁÆóÊ≥ïÊàñ‰ΩøÁî®Êõ¥Âº∫ÁöÑCPU")
        
        if single_thread['match_rate'] < 0.3:
            recommendations.append("ÂåπÈÖçÁéáËæÉ‰ΩéÔºåÂª∫ËÆÆË∞ÉÊï¥Áõ∏‰ººÂ∫¶ÈòàÂÄºÊàñ‰ºòÂåñÂåπÈÖçÁÆóÊ≥ï")
        
        return recommendations
    
    def _display_performance_summary(self, report: Dict):
        """ÊòæÁ§∫ÊÄßËÉΩÊµãËØïÊëòË¶Å"""
        print("\nüéØ ÊÄßËÉΩÊµãËØïÁªìÊûúÊëòË¶Å:")
        print("=" * 50)
        
        results = report['performance_results']
        
        print(f"üìä ÂçïÁ∫øÁ®ãÊÄßËÉΩ:")
        print(f"  Â§ÑÁêÜÈÄüÂ∫¶: {results['single_thread_performance']['throughput_per_second']:.2f} Êù°/Áßí")
        print(f"  ÂåπÈÖçÁéá: {results['single_thread_performance']['match_rate']:.1%}")
        print(f"  Âπ≥ÂùáÂìçÂ∫îÊó∂Èó¥: {results['single_thread_performance']['average_response_time']:.3f} Áßí")
        
        print(f"\nüìä Â§öÁ∫øÁ®ãÊÄßËÉΩ:")
        print(f"  Â§ÑÁêÜÈÄüÂ∫¶: {results['multi_thread_performance']['throughput_per_second']:.2f} Êù°/Áßí")
        print(f"  ÂåπÈÖçÁéá: {results['multi_thread_performance']['match_rate']:.1%}")
        print(f"  Á∫øÁ®ãÊï∞: {results['multi_thread_performance']['thread_count']}")
        
        print(f"\nüìä ÊâπÂ§ÑÁêÜÊÄßËÉΩ:")
        print(f"  Â§ÑÁêÜÈÄüÂ∫¶: {results['batch_processing_performance']['throughput_per_second']:.2f} Êù°/Áßí")
        print(f"  ÂåπÈÖçÁéá: {results['batch_processing_performance']['match_rate']:.1%}")
        print(f"  È¢ÑÂ§ÑÁêÜÊó∂Èó¥: {results['batch_processing_performance']['preprocessing_time']:.2f} Áßí")
        
        print(f"\nüìä ËµÑÊ∫ê‰ΩøÁî®:")
        print(f"  Â≥∞ÂÄºÂÜÖÂ≠ò‰ΩøÁî®: {results['resource_monitoring']['peak_memory_usage']:.1f}%")
        print(f"  Â≥∞ÂÄºCPU‰ΩøÁî®: {results['resource_monitoring']['peak_cpu_usage']:.1f}%")
        print(f"  Âπ≥ÂùáÂÜÖÂ≠ò‰ΩøÁî®: {results['resource_monitoring']['average_memory_usage']:.1f}%")
        print(f"  Âπ≥ÂùáCPU‰ΩøÁî®: {results['resource_monitoring']['average_cpu_usage']:.1f}%")
        
        print(f"\nüöÄ ÊÄßËÉΩÂØπÊØî:")
        comparison = report['performance_comparison']
        print(f"  Â§öÁ∫øÁ®ãÂä†ÈÄüÊØî: {comparison['single_vs_multi_thread_speedup']:.2f}x")
        print(f"  ÊâπÂ§ÑÁêÜÊïàÁéáÊØî: {comparison['batch_processing_efficiency']:.2f}x")
        
        print(f"\nüí° ‰ºòÂåñÂª∫ËÆÆ:")
        for i, recommendation in enumerate(report['recommendations'], 1):
            print(f"  {i}. {recommendation}")

def main():
    """‰∏ªÂáΩÊï∞"""
    try:
        benchmark = PerformanceBenchmarkTest()
        benchmark.run_performance_benchmark()
    except Exception as e:
        logger.error(f"ÊÄßËÉΩÂü∫ÂáÜÊµãËØïÊâßË°åÂ§±Ë¥•: {str(e)}")
        print("‚ùå ÊÄßËÉΩÂü∫ÂáÜÊµãËØïÊâßË°åÂ§±Ë¥•")

if __name__ == "__main__":
    main()

