#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒé‡éªŒè¯åŒ¹é…å™¨
å®ç°ä¸»è¦å­—æ®µå…ˆéªŒè¯ï¼Œæ¬¡è¦å­—æ®µåéªŒè¯çš„ä¸¥æ ¼åŒ¹é…ç­–ç•¥
ç¡®ä¿æœ€ç»ˆä¿ç•™é˜ˆå€¼35%ä»¥ä¸Šï¼Œè¿‡æ»¤è„æ•°æ®
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import time
from loguru import logger

from src.matching.fuzzy_matcher import FuzzyMatcher
from src.matching.enhanced_fuzzy_matcher import EnhancedFuzzyMatcher
from src.matching.intelligent_unit_name_matcher import IntelligentUnitNameMatcher
from src.matching.content_field_analyzer import ContentFieldAnalyzer

@dataclass
class FieldValidationConfig:
    """å­—æ®µéªŒè¯é…ç½®"""
    field_name: str
    source_field: str
    target_field: str
    weight: float
    threshold: float
    is_primary: bool = False
    match_type: str = 'string'  # string, address, unit_name

@dataclass
class DualValidationResult:
    """åŒé‡éªŒè¯ç»“æœ"""
    is_valid: bool
    final_score: float
    primary_field_score: float
    secondary_field_score: float
    validation_details: Dict[str, Any]
    rejection_reason: Optional[str] = None
    passes_threshold: bool = False

class DualValidationMatcher:
    """
    åŒé‡éªŒè¯åŒ¹é…å™¨
    
    åŒ¹é…ç­–ç•¥ï¼š
    1. ä¸»è¦å­—æ®µå¿…é¡»å…ˆè¾¾åˆ°é˜ˆå€¼
    2. æ¬¡è¦å­—æ®µåªæœ‰åœ¨ä¸»è¦å­—æ®µè¾¾æ ‡åæ‰éªŒè¯
    3. ä¸¤ä¸ªå­—æ®µéƒ½è¾¾æ ‡æ‰è®¡ç®—æœ€ç»ˆå¾—åˆ†
    4. æœ€ç»ˆå¾—åˆ†ä½äº35%ç›´æ¥æ‹’ç»
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """
        åˆå§‹åŒ–åŒé‡éªŒè¯åŒ¹é…å™¨
        
        Args:
            config: é…ç½®å‚æ•°
        """
        self.config = config or {}
        
        # åˆå§‹åŒ–å„ç§åŒ¹é…å™¨
        try:
            from src.utils.config import ConfigManager
            config_manager = ConfigManager()
            self.fuzzy_matcher = FuzzyMatcher(config_manager)
            self.enhanced_fuzzy_matcher = EnhancedFuzzyMatcher(config_manager)
            self.unit_name_matcher = IntelligentUnitNameMatcher()
        except Exception as e:
            logger.warning(f"åˆå§‹åŒ–åŒ¹é…å™¨å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–é…ç½®: {str(e)}")
            # ä½¿ç”¨ç®€åŒ–é…ç½®
            simple_config = {'fuzzy_match': {'similarity_threshold': 0.6}}
            self.fuzzy_matcher = None
            self.enhanced_fuzzy_matcher = None
            self.unit_name_matcher = IntelligentUnitNameMatcher()
        
        # åˆå§‹åŒ–å†…å®¹åˆ†æå™¨
        self.content_analyzer = ContentFieldAnalyzer()
        
        # éªŒè¯é…ç½®
        self.validation_configs: List[FieldValidationConfig] = []
        
        # å…¨å±€é˜ˆå€¼è®¾ç½®
        self.final_threshold = 0.35  # æœ€ç»ˆä¿ç•™é˜ˆå€¼35%
        self.primary_field_threshold = 0.25  # ä¸»è¦å­—æ®µé˜ˆå€¼25%ï¼ˆè¿›ä¸€æ­¥é™ä½ï¼Œç¬¦åˆå®é™…æ•°æ®è´¨é‡ï¼‰
        self.secondary_field_threshold = 0.25  # æ¬¡è¦å­—æ®µé˜ˆå€¼25%ï¼ˆè¿›ä¸€æ­¥é™ä½ï¼Œç¬¦åˆå®é™…æ•°æ®è´¨é‡ï¼‰
        
        logger.info(f"ğŸ”§ åŒé‡éªŒè¯åŒ¹é…å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   - æœ€ç»ˆä¿ç•™é˜ˆå€¼: {self.final_threshold:.1%}")
        logger.info(f"   - ä¸»è¦å­—æ®µé˜ˆå€¼: {self.primary_field_threshold:.1%}")
        logger.info(f"   - æ¬¡è¦å­—æ®µé˜ˆå€¼: {self.secondary_field_threshold:.1%}")
    
    def configure_fields(self, mappings: List[Dict[str, Any]], 
                        source_data: List[Dict] = None, 
                        target_data: List[Dict] = None) -> None:
        """
        é…ç½®å­—æ®µéªŒè¯è§„åˆ™ï¼ˆåŸºäºå†…å®¹åˆ†æï¼‰
        
        Args:
            mappings: å­—æ®µæ˜ å°„é…ç½®åˆ—è¡¨
            source_data: æºæ•°æ®æ ·æœ¬ï¼ˆç”¨äºå†…å®¹åˆ†æï¼‰
            target_data: ç›®æ ‡æ•°æ®æ ·æœ¬ï¼ˆç”¨äºå†…å®¹åˆ†æï¼‰
        """
        self.validation_configs.clear()
        
        for mapping in mappings:
            source_field = mapping['source_field']
            target_field = mapping['target_field']
            weight = mapping.get('weight', 1.0)
            
            # ã€æ–°é€»è¾‘ã€‘åŸºäºå†…å®¹åˆ†æå­—æ®µç±»å‹
            is_primary = False
            match_type = 'string'
            threshold = self.secondary_field_threshold
            
            # å¦‚æœæœ‰æ ·æœ¬æ•°æ®ï¼Œè¿›è¡Œå†…å®¹åˆ†æ
            if source_data and target_data:
                # æå–å­—æ®µå€¼æ ·æœ¬
                source_values = [record.get(source_field, '') for record in source_data[:10] if record.get(source_field)]
                target_values = [record.get(target_field, '') for record in target_data[:10] if record.get(target_field)]
                
                # åˆ†ææºå­—æ®µç±»å‹
                source_analysis = self.content_analyzer.analyze_field_type(source_values)
                target_analysis = self.content_analyzer.analyze_field_type(target_values)
                
                source_type = source_analysis.get('field_type', 'unknown')
                target_type = target_analysis.get('field_type', 'unknown')
                source_confidence = source_analysis.get('confidence', 0.0)
                target_confidence = target_analysis.get('confidence', 0.0)
                
                # åŸºäºå†…å®¹åˆ†æç»“æœåˆ¤æ–­å­—æ®µç±»å‹
                if source_type == 'company_name' and target_type == 'company_name':
                    is_primary = True
                    match_type = 'unit_name'
                    threshold = self.primary_field_threshold
                    logger.info(f"ğŸ¯ å†…å®¹åˆ†æè¯†åˆ«ä¸»è¦å­—æ®µ: {source_field} -> {target_field}")
                    logger.info(f"   æºå­—æ®µç½®ä¿¡åº¦: {source_confidence:.2f}, ç›®æ ‡å­—æ®µç½®ä¿¡åº¦: {target_confidence:.2f}")
                    logger.info(f"   æƒé‡: {weight}, é˜ˆå€¼: {threshold:.1%}")
                    
                elif source_type == 'address' and target_type == 'address':
                    is_primary = False
                    match_type = 'address'
                    threshold = self.secondary_field_threshold
                    logger.info(f"ğŸ  å†…å®¹åˆ†æè¯†åˆ«æ¬¡è¦å­—æ®µ: {source_field} -> {target_field}")
                    logger.info(f"   æºå­—æ®µç½®ä¿¡åº¦: {source_confidence:.2f}, ç›®æ ‡å­—æ®µç½®ä¿¡åº¦: {target_confidence:.2f}")
                    logger.info(f"   æƒé‡: {weight}, é˜ˆå€¼: {threshold:.1%}")
                    
                elif source_type != target_type and source_type != 'unknown' and target_type != 'unknown':
                    logger.warning(f"âš ï¸  å­—æ®µç±»å‹ä¸åŒ¹é…: {source_field}({source_type}) -> {target_field}({target_type})")
                    logger.warning(f"   è¿™å¯èƒ½å¯¼è‡´åŒ¹é…æ•ˆæœä¸ä½³")
                    
                else:
                    logger.info(f"ğŸ” æ— æ³•ç¡®å®šå­—æ®µç±»å‹: {source_field} -> {target_field}")
                    logger.info(f"   æºå­—æ®µç±»å‹: {source_type}({source_confidence:.2f}), ç›®æ ‡å­—æ®µç±»å‹: {target_type}({target_confidence:.2f})")
                    
            else:
                # ã€é™çº§é€»è¾‘ã€‘å¦‚æœæ²¡æœ‰æ ·æœ¬æ•°æ®ï¼Œä»ç„¶ä½¿ç”¨å­—æ®µååˆ¤æ–­ï¼ˆä½†ä¼šè®°å½•è­¦å‘Šï¼‰
                logger.warning(f"âš ï¸  ç¼ºå°‘æ ·æœ¬æ•°æ®ï¼Œé™çº§ä½¿ç”¨å­—æ®µååˆ¤æ–­: {source_field} -> {target_field}")
                
                # å•ä½åç§°å­—æ®µ - ä¸»è¦å­—æ®µ
                if any(keyword in source_field.lower() for keyword in ['unit', 'name', 'dwmc', 'å•ä½', 'åç§°', 'company', 'jgmc']):
                    is_primary = True
                    match_type = 'unit_name'
                    threshold = self.primary_field_threshold
                    logger.info(f"ğŸ¯ å­—æ®µåè¯†åˆ«ä¸»è¦å­—æ®µ: {source_field} -> {target_field} (æƒé‡: {weight}, é˜ˆå€¼: {threshold:.1%})")
                
                # åœ°å€å­—æ®µ - æ¬¡è¦å­—æ®µ
                elif any(keyword in source_field.lower() for keyword in ['address', 'addr', 'dwdz', 'åœ°å€', 'ä½ç½®', 'dz']):
                    is_primary = False
                    match_type = 'address'
                    threshold = self.secondary_field_threshold
                    logger.info(f"ğŸ  å­—æ®µåè¯†åˆ«æ¬¡è¦å­—æ®µ: {source_field} -> {target_field} (æƒé‡: {weight}, é˜ˆå€¼: {threshold:.1%})")
            
            config = FieldValidationConfig(
                field_name=f"{source_field}->{target_field}",
                source_field=source_field,
                target_field=target_field,
                weight=weight,
                threshold=threshold,
                is_primary=is_primary,
                match_type=match_type
            )
            
            self.validation_configs.append(config)
        
        # éªŒè¯é…ç½®å®Œæ•´æ€§
        primary_fields = [c for c in self.validation_configs if c.is_primary]
        secondary_fields = [c for c in self.validation_configs if not c.is_primary]
        
        logger.info(f"âœ… å­—æ®µé…ç½®å®Œæˆ: {len(primary_fields)}ä¸ªä¸»è¦å­—æ®µ, {len(secondary_fields)}ä¸ªæ¬¡è¦å­—æ®µ")
    
    def validate_match(self, source_record: Dict[str, Any], target_record: Dict[str, Any]) -> DualValidationResult:
        """
        æ‰§è¡ŒåŒé‡éªŒè¯åŒ¹é…
        
        Args:
            source_record: æºè®°å½•
            target_record: ç›®æ ‡è®°å½•
            
        Returns:
            DualValidationResult: éªŒè¯ç»“æœ
        """
        # ã€åŠ å¼ºå®‰å…¨æ£€æŸ¥ã€‘ç¡®ä¿è®°å½•ä¸ä¸ºNone
        if source_record is None or target_record is None:
            error_msg = f"åŒé‡éªŒè¯åŒ¹é…å™¨è¾“å…¥éªŒè¯å¤±è´¥: source_record={source_record is not None}, target_record={target_record is not None}"
            logger.error(error_msg)
            return DualValidationResult(
                is_valid=False,
                final_score=0.0,
                primary_field_score=0.0,
                secondary_field_score=0.0,
                validation_details={},
                rejection_reason="è®°å½•ä¸ºç©º",
                passes_threshold=False
            )
        
        # ã€åŠ å¼ºç±»å‹æ£€æŸ¥ã€‘ç¡®ä¿è®°å½•æ˜¯å­—å…¸ç±»å‹
        if not isinstance(source_record, dict) or not isinstance(target_record, dict):
            error_msg = f"åŒé‡éªŒè¯åŒ¹é…å™¨ç±»å‹éªŒè¯å¤±è´¥: source_type={type(source_record)}, target_type={type(target_record)}"
            logger.error(error_msg)
            return DualValidationResult(
                is_valid=False,
                final_score=0.0,
                primary_field_score=0.0,
                secondary_field_score=0.0,
                validation_details={},
                rejection_reason="è®°å½•ç±»å‹é”™è¯¯",
                passes_threshold=False
            )
        start_time = time.time()
        
        # ç¬¬ä¸€æ­¥ï¼šéªŒè¯ä¸»è¦å­—æ®µ
        primary_validation = self._validate_primary_fields(source_record, target_record)
        
        if not primary_validation['is_valid']:
            return DualValidationResult(
                is_valid=False,
                final_score=0.0,
                primary_field_score=primary_validation['score'],
                secondary_field_score=0.0,
                validation_details={
                    'primary_validation': primary_validation,
                    'secondary_validation': None,
                    'processing_time': time.time() - start_time
                },
                rejection_reason=primary_validation['rejection_reason'],
                passes_threshold=False
            )
        
        # ç¬¬äºŒæ­¥ï¼šéªŒè¯æ¬¡è¦å­—æ®µ
        secondary_validation = self._validate_secondary_fields(source_record, target_record)
        
        if not secondary_validation['is_valid']:
            return DualValidationResult(
                is_valid=False,
                final_score=0.0,
                primary_field_score=primary_validation['score'],
                secondary_field_score=secondary_validation['score'],
                validation_details={
                    'primary_validation': primary_validation,
                    'secondary_validation': secondary_validation,
                    'processing_time': time.time() - start_time
                },
                rejection_reason=secondary_validation['rejection_reason'],
                passes_threshold=False
            )
        
        # ç¬¬ä¸‰æ­¥ï¼šè®¡ç®—æœ€ç»ˆå¾—åˆ†
        final_score = self._calculate_final_score(primary_validation, secondary_validation)
        
        # ç¬¬å››æ­¥ï¼šåº”ç”¨æœ€ç»ˆé˜ˆå€¼å’Œè¾¹ç•Œæƒ…å†µæ£€æŸ¥
        is_final_valid = final_score >= self.final_threshold
        rejection_reason = None
        
        if not is_final_valid:
            rejection_reason = f"æœ€ç»ˆå¾—åˆ†{final_score:.1%}ä½äºä¿ç•™é˜ˆå€¼{self.final_threshold:.1%}"
        else:
            # è¾¹ç•Œæƒ…å†µæ£€æŸ¥ï¼šé¿å…ä¿¡æ¯é‡è¿‡å°‘çš„åŒ¹é…
            boundary_check_result = self._check_boundary_conditions(
                source_record, target_record, primary_validation, secondary_validation
            )
            if not boundary_check_result['is_valid']:
                is_final_valid = False
                rejection_reason = boundary_check_result['reason']
        
        result = DualValidationResult(
            is_valid=is_final_valid,
            final_score=final_score,
            primary_field_score=primary_validation['score'],
            secondary_field_score=secondary_validation['score'],
            validation_details={
                'primary_validation': primary_validation,
                'secondary_validation': secondary_validation,
                'final_score_calculation': {
                    'primary_weighted': primary_validation['score'] * primary_validation['total_weight'],
                    'secondary_weighted': secondary_validation['score'] * secondary_validation['total_weight'],
                    'total_weight': primary_validation['total_weight'] + secondary_validation['total_weight']
                },
                'processing_time': time.time() - start_time
            },
            rejection_reason=rejection_reason,
            passes_threshold=is_final_valid
        )
        
        # è®°å½•éªŒè¯ç»“æœ
        if is_final_valid:
            logger.info(f"âœ… åŒé‡éªŒè¯é€šè¿‡: æœ€ç»ˆå¾—åˆ†{final_score:.1%} (ä¸»è¦:{primary_validation['score']:.1%}, æ¬¡è¦:{secondary_validation['score']:.1%})")
        else:
            logger.info(f"âŒ åŒé‡éªŒè¯å¤±è´¥: {rejection_reason}")
        
        return result
    
    def _validate_primary_fields(self, source_record: Dict[str, Any], target_record: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯ä¸»è¦å­—æ®µ"""
        primary_configs = [c for c in self.validation_configs if c.is_primary]
        
        if not primary_configs:
            return {
                'is_valid': True,
                'score': 1.0,
                'total_weight': 0.0,
                'field_scores': {},
                'rejection_reason': None
            }
        
        total_score = 0.0
        total_weight = 0.0
        field_scores = {}
        failed_fields = []
        
        for config in primary_configs:
            source_value = str((source_record or {}).get(config.source_field, '')).strip()
            target_value = str((target_record or {}).get(config.target_field, '')).strip()
            
            if not source_value or not target_value:
                failed_fields.append(f"{config.field_name}(ç©ºå€¼)")
                continue
            
            # è®¡ç®—å­—æ®µç›¸ä¼¼åº¦
            field_score = self._calculate_field_similarity(
                source_value, target_value, config.match_type
            )
            
            field_scores[config.field_name] = field_score
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°é˜ˆå€¼ï¼ˆè€ƒè™‘åŒä¹‰è¯æƒ…å†µï¼‰
            effective_threshold = config.threshold
            
            # å¦‚æœæ˜¯å•ä½åç§°å­—æ®µï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«åŒä¹‰è¯
            if config.match_type == 'unit_name':
                source_value = str((source_record or {}).get(config.source_field, '')).strip()
                target_value = str((target_record or {}).get(config.target_field, '')).strip()
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«åŒä¹‰è¯å¯¹
                synonym_pairs = [
                    ('å…»è€é™¢', 'æŠ¤ç†é™¢'),
                    ('è€å¹´æŠ¤ç†é™¢', 'å…»è€é™¢'),
                    ('æŠ¤ç†ä¸­å¿ƒ', 'å…»è€é™¢'),
                ]
                
                for syn1, syn2 in synonym_pairs:
                    if ((syn1 in source_value and syn2 in target_value) or 
                        (syn2 in source_value and syn1 in target_value)):
                        # å¯¹äºåŒä¹‰è¯æƒ…å†µï¼Œé™ä½é˜ˆå€¼è¦æ±‚
                        effective_threshold = max(0.15, config.threshold * 0.4)  # é™ä½åˆ°åŸé˜ˆå€¼çš„40%ï¼Œä½†ä¸ä½äº15%
                        logger.debug(f"ğŸ”„ æ£€æµ‹åˆ°åŒä¹‰è¯å¯¹ '{syn1}' <-> '{syn2}'ï¼Œé™ä½é˜ˆå€¼è‡³ {effective_threshold:.3f}")
                        break
            
            if field_score >= effective_threshold:
                total_score += field_score * config.weight
                total_weight += config.weight
                logger.debug(f"âœ… ä¸»è¦å­—æ®µé€šè¿‡: {config.field_name} = {field_score:.3f} >= {effective_threshold:.3f}")
            else:
                failed_fields.append(f"{config.field_name}({field_score:.1%}<{effective_threshold:.1%})")
                logger.debug(f"âŒ ä¸»è¦å­—æ®µå¤±è´¥: {config.field_name} = {field_score:.3f} < {effective_threshold:.3f}")
        
        # è®¡ç®—ä¸»è¦å­—æ®µå¹³å‡å¾—åˆ†
        avg_score = total_score / total_weight if total_weight > 0 else 0.0
        
        # ã€æ–°å¢ä¼˜åŒ–é€»è¾‘ã€‘å½“å…³é”®æ˜ å°„å­—æ®µæœ‰ä¸¤ä¸ªä»¥ä¸Šæ—¶ï¼Œæ‰€æœ‰å­—æ®µå¿…é¡»è¾¾åˆ°é…ç½®çš„é˜ˆå€¼ä»¥ä¸Š
        # ä»é…ç½®ä¸­è¯»å–å…³é”®å­—æ®µéªŒè¯å‚æ•°
        critical_validation_config = getattr(self, 'critical_validation_config', {
            'enabled': True,
            'minimum_threshold': 0.4,
            'minimum_field_count': 2
        })
        
        critical_field_threshold = critical_validation_config.get('minimum_threshold', 0.4)
        minimum_field_count = critical_validation_config.get('minimum_field_count', 2)
        validation_enabled = critical_validation_config.get('enabled', True)
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨å…³é”®å­—æ®µéªŒè¯ä¸”æ»¡è¶³æœ€å°‘å­—æ®µæ•°é‡è¦æ±‚
        if validation_enabled and len(primary_configs) >= minimum_field_count:
            # æ£€æŸ¥æ‰€æœ‰å…³é”®å­—æ®µæ˜¯å¦éƒ½è¾¾åˆ°é…ç½®çš„é˜ˆå€¼ä»¥ä¸Š
            low_score_fields = []
            for config in primary_configs:
                field_score = field_scores.get(config.field_name, 0.0)
                if field_score < critical_field_threshold:
                    low_score_fields.append(f"{config.field_name}({field_score:.3f}<{critical_field_threshold})")
            
            # å¦‚æœæœ‰å­—æ®µä½äºé˜ˆå€¼ï¼Œåˆ™æ•´ä½“åŒ¹é…å¤±è´¥
            if low_score_fields:
                is_valid = False
                rejection_reason = f"å…³é”®å­—æ®µè¯„åˆ†ä¸è¶³(éœ€â‰¥{critical_field_threshold}): {', '.join(low_score_fields)}"
                logger.info(f"ğŸš« å¤šå…³é”®å­—æ®µåŒ¹é…å¤±è´¥: {rejection_reason}")
            else:
                # æ‰€æœ‰å…³é”®å­—æ®µéƒ½è¾¾æ ‡ï¼Œå†æ£€æŸ¥åŸæœ‰çš„å¤±è´¥å­—æ®µé€»è¾‘
                is_valid = len(failed_fields) == 0 and avg_score > 0
                if failed_fields:
                    rejection_reason = f"ä¸»è¦å­—æ®µéªŒè¯å¤±è´¥: {', '.join(failed_fields)}"
                else:
                    logger.info(f"âœ… å¤šå…³é”®å­—æ®µåŒ¹é…æˆåŠŸ: æ‰€æœ‰{len(primary_configs)}ä¸ªå…³é”®å­—æ®µå‡â‰¥{critical_field_threshold}")
        else:
            # å•ä¸ªå…³é”®å­—æ®µæˆ–æœªå¯ç”¨éªŒè¯æ—¶ï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
            is_valid = len(failed_fields) == 0 and avg_score > 0
            if failed_fields:
                rejection_reason = f"ä¸»è¦å­—æ®µéªŒè¯å¤±è´¥: {', '.join(failed_fields)}"
        
        return {
            'is_valid': is_valid,
            'score': avg_score,
            'total_weight': total_weight,
            'field_scores': field_scores,
            'failed_fields': failed_fields,
            'rejection_reason': rejection_reason
        }
    
    def _validate_secondary_fields(self, source_record: Dict[str, Any], target_record: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯æ¬¡è¦å­—æ®µ"""
        secondary_configs = [c for c in self.validation_configs if not c.is_primary]
        
        if not secondary_configs:
            return {
                'is_valid': True,
                'score': 1.0,
                'total_weight': 0.0,
                'field_scores': {},
                'rejection_reason': None
            }
        
        total_score = 0.0
        total_weight = 0.0
        field_scores = {}
        failed_fields = []
        
        for config in secondary_configs:
            source_value = str((source_record or {}).get(config.source_field, '')).strip()
            target_value = str((target_record or {}).get(config.target_field, '')).strip()
            
            if not source_value or not target_value:
                failed_fields.append(f"{config.field_name}(ç©ºå€¼)")
                continue
            
            # è®¡ç®—å­—æ®µç›¸ä¼¼åº¦
            field_score = self._calculate_field_similarity(
                source_value, target_value, config.match_type
            )
            
            field_scores[config.field_name] = field_score
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°é˜ˆå€¼
            if field_score >= config.threshold:
                total_score += field_score * config.weight
                total_weight += config.weight
                logger.debug(f"âœ… æ¬¡è¦å­—æ®µé€šè¿‡: {config.field_name} = {field_score:.3f} >= {config.threshold:.3f}")
            else:
                failed_fields.append(f"{config.field_name}({field_score:.1%}<{config.threshold:.1%})")
                logger.debug(f"âŒ æ¬¡è¦å­—æ®µå¤±è´¥: {config.field_name} = {field_score:.3f} < {config.threshold:.3f}")
        
        # è®¡ç®—æ¬¡è¦å­—æ®µå¹³å‡å¾—åˆ†
        avg_score = total_score / total_weight if total_weight > 0 else 0.0
        is_valid = len(failed_fields) == 0 and avg_score > 0
        
        rejection_reason = None
        if failed_fields:
            rejection_reason = f"æ¬¡è¦å­—æ®µéªŒè¯å¤±è´¥: {', '.join(failed_fields)}"
        
        return {
            'is_valid': is_valid,
            'score': avg_score,
            'total_weight': total_weight,
            'field_scores': field_scores,
            'failed_fields': failed_fields,
            'rejection_reason': rejection_reason
        }
    
    def _calculate_field_similarity(self, value1: str, value2: str, match_type: str) -> float:
        """
        è®¡ç®—å­—æ®µç›¸ä¼¼åº¦
        
        Args:
            value1: å€¼1
            value2: å€¼2
            match_type: åŒ¹é…ç±»å‹ (string, address, unit_name)
            
        Returns:
            float: ç›¸ä¼¼åº¦ (0-1)
        """
        try:
            if match_type == 'unit_name':
                # ä½¿ç”¨æ™ºèƒ½å•ä½åç§°åŒ¹é…å™¨
                return self.unit_name_matcher.calculate_similarity(value1, value2)
            elif match_type == 'address':
                # ä½¿ç”¨ä¸“é—¨çš„åœ°å€ç›¸ä¼¼åº¦è®¡ç®—
                return self._calculate_address_similarity(value1, value2)
            else:
                # ä½¿ç”¨å¢å¼ºæ¨¡ç³ŠåŒ¹é…å™¨
                if self.enhanced_fuzzy_matcher:
                    return self.enhanced_fuzzy_matcher.calculate_similarity(value1, value2)
                else:
                    # ç®€å•çš„å­—ç¬¦ä¸²ç›¸ä¼¼åº¦è®¡ç®—
                    return self._simple_similarity(value1, value2)
        except Exception as e:
            logger.warning(f"è®¡ç®—å­—æ®µç›¸ä¼¼åº¦å¤±è´¥: {str(e)}")
            return 0.0
    
    def _calculate_final_score(self, primary_validation: Dict[str, Any], secondary_validation: Dict[str, Any]) -> float:
        """
        è®¡ç®—æœ€ç»ˆå¾—åˆ†
        
        Args:
            primary_validation: ä¸»è¦å­—æ®µéªŒè¯ç»“æœ
            secondary_validation: æ¬¡è¦å­—æ®µéªŒè¯ç»“æœ
            
        Returns:
            float: æœ€ç»ˆå¾—åˆ† (0-1)
        """
        primary_weighted = primary_validation['score'] * primary_validation['total_weight']
        secondary_weighted = secondary_validation['score'] * secondary_validation['total_weight']
        total_weight = primary_validation['total_weight'] + secondary_validation['total_weight']
        
        if total_weight == 0:
            return 0.0
        
        final_score = (primary_weighted + secondary_weighted) / total_weight
        
        logger.debug(f"ğŸ§® æœ€ç»ˆå¾—åˆ†è®¡ç®—: "
                    f"ä¸»è¦({primary_validation['score']:.3f}Ã—{primary_validation['total_weight']:.1f}) + "
                    f"æ¬¡è¦({secondary_validation['score']:.3f}Ã—{secondary_validation['total_weight']:.1f}) "
                    f"/ {total_weight:.1f} = {final_score:.3f}")
        
        return final_score

    def batch_validate(self, source_records: List[Dict[str, Any]], 
                      target_records: List[Dict[str, Any]]) -> List[Tuple[int, int, DualValidationResult]]:
        """
        æ‰¹é‡éªŒè¯åŒ¹é…
        
        Args:
            source_records: æºè®°å½•åˆ—è¡¨
            target_records: ç›®æ ‡è®°å½•åˆ—è¡¨
            
        Returns:
            List[Tuple[int, int, DualValidationResult]]: (æºç´¢å¼•, ç›®æ ‡ç´¢å¼•, éªŒè¯ç»“æœ)
        """
        results = []
        total_pairs = len(source_records) * len(target_records)
        processed = 0
        
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡éªŒè¯: {len(source_records)}æ¡æºè®°å½• Ã— {len(target_records)}æ¡ç›®æ ‡è®°å½• = {total_pairs}å¯¹")
        
        for i, source_record in enumerate(source_records):
            for j, target_record in enumerate(target_records):
                validation_result = self.validate_match(source_record, target_record)
                
                if validation_result.is_valid:
                    results.append((i, j, validation_result))
                
                processed += 1
                if processed % 1000 == 0:
                    logger.info(f"ğŸ“Š æ‰¹é‡éªŒè¯è¿›åº¦: {processed}/{total_pairs} ({processed/total_pairs:.1%})")
        
        logger.info(f"âœ… æ‰¹é‡éªŒè¯å®Œæˆ: {len(results)}ä¸ªæœ‰æ•ˆåŒ¹é… / {total_pairs}å¯¹ ({len(results)/total_pairs:.1%})")
        
        return results
    
    def _simple_similarity(self, value1: str, value2: str) -> float:
        """
        ç®€å•çš„å­—ç¬¦ä¸²ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆé™çº§æ–¹æ¡ˆï¼‰
        
        Args:
            value1: å­—ç¬¦ä¸²1
            value2: å­—ç¬¦ä¸²2
            
        Returns:
            float: ç›¸ä¼¼åº¦ (0-1)
        """
        if not value1 or not value2:
            return 0.0
        
        # è½¬æ¢ä¸ºå°å†™å¹¶å»é™¤ç©ºæ ¼
        v1 = value1.lower().replace(' ', '')
        v2 = value2.lower().replace(' ', '')
        
        if v1 == v2:
            return 1.0
        
        # è®¡ç®—æœ€é•¿å…¬å…±å­åºåˆ—é•¿åº¦
        def lcs_length(s1, s2):
            m, n = len(s1), len(s2)
            dp = [[0] * (n + 1) for _ in range(m + 1)]
            
            for i in range(1, m + 1):
                for j in range(1, n + 1):
                    if s1[i-1] == s2[j-1]:
                        dp[i][j] = dp[i-1][j-1] + 1
                    else:
                        dp[i][j] = max(dp[i-1][j], dp[i][j-1])
            
            return dp[m][n]
        
        # åŸºäºæœ€é•¿å…¬å…±å­åºåˆ—çš„ç›¸ä¼¼åº¦
        lcs_len = lcs_length(v1, v2)
        max_len = max(len(v1), len(v2))
        
        if max_len == 0:
            return 0.0
        
        return lcs_len / max_len
    
    def _calculate_address_similarity(self, addr1: str, addr2: str) -> float:
        """
        è®¡ç®—åœ°å€ç›¸ä¼¼åº¦ï¼ˆæ›´ä¸¥æ ¼çš„åœ°å€åŒ¹é…é€»è¾‘ï¼‰
        
        Args:
            addr1: åœ°å€1
            addr2: åœ°å€2
            
        Returns:
            float: ç›¸ä¼¼åº¦ (0-1)
        """
        if not addr1 or not addr2:
            return 0.0
        
        # æ ‡å‡†åŒ–åœ°å€
        def normalize_address(addr):
            # ç§»é™¤å¸¸è§çš„åœ°å€åç¼€
            suffixes = ['å·', 'å®¤', 'æ¥¼', 'å±‚', 'å•å…ƒ', 'æ ‹', 'å¹¢']
            normalized = addr.strip()
            for suffix in suffixes:
                if normalized.endswith(suffix):
                    normalized = normalized[:-len(suffix)]
            return normalized.lower().replace(' ', '')
        
        norm_addr1 = normalize_address(addr1)
        norm_addr2 = normalize_address(addr2)
        
        # å®Œå…¨åŒ¹é…
        if norm_addr1 == norm_addr2:
            return 1.0
        
        # æå–å…³é”®åœ°å€ç»„ä»¶
        def extract_address_components(addr):
            components = {
                'province': '',
                'city': '',
                'district': '',
                'street': '',
                'number': ''
            }
            
            # ç®€å•çš„åœ°å€ç»„ä»¶æå–
            import re
            
            # æå–çœä»½
            province_match = re.search(r'(.*?çœ)', addr)
            if province_match:
                components['province'] = province_match.group(1)
            
            # æå–å¸‚
            city_match = re.search(r'(.*?å¸‚)', addr)
            if city_match:
                components['city'] = city_match.group(1)
            
            # æå–åŒºå¿
            district_match = re.search(r'(.*?[åŒºå¿])', addr)
            if district_match:
                components['district'] = district_match.group(1)
            
            # æå–è¡—é“
            street_match = re.search(r'(.*?[è·¯è¡—é“å··å¼„])', addr)
            if street_match:
                components['street'] = street_match.group(1)
            
            # æå–é—¨ç‰Œå·
            number_match = re.search(r'(\d+å·?)', addr)
            if number_match:
                components['number'] = number_match.group(1)
            
            return components
        
        comp1 = extract_address_components(addr1)
        comp2 = extract_address_components(addr2)
        
        # è®¡ç®—å„ç»„ä»¶ç›¸ä¼¼åº¦
        component_scores = {}
        component_weights = {
            'province': 0.1,
            'city': 0.2,
            'district': 0.25,
            'street': 0.3,
            'number': 0.35  # é—¨ç‰Œå·æœ€é‡è¦
        }
        
        total_score = 0.0
        total_weight = 0.0
        
        for component, weight in component_weights.items():
            val1 = comp1.get(component, '')
            val2 = comp2.get(component, '')
            
            if val1 and val2:
                # è®¡ç®—ç»„ä»¶ç›¸ä¼¼åº¦
                if val1 == val2:
                    comp_sim = 1.0
                else:
                    comp_sim = self._simple_similarity(val1, val2)
                
                component_scores[component] = comp_sim
                total_score += comp_sim * weight
                total_weight += weight
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…çš„ç»„ä»¶ï¼Œä½¿ç”¨ç®€å•å­—ç¬¦ä¸²ç›¸ä¼¼åº¦
        if total_weight == 0:
            return self._simple_similarity(norm_addr1, norm_addr2)
        
        # è®¡ç®—åŠ æƒå¹³å‡ç›¸ä¼¼åº¦
        weighted_similarity = total_score / total_weight
        
        # åº”ç”¨ä¸¥æ ¼æ€§æƒ©ç½šï¼šå¦‚æœé—¨ç‰Œå·ä¸åŒ¹é…ï¼Œå¤§å¹…é™ä½ç›¸ä¼¼åº¦
        if comp1.get('number') and comp2.get('number'):
            if comp1['number'] != comp2['number']:
                # é—¨ç‰Œå·ä¸åŒ¹é…ï¼Œç›¸ä¼¼åº¦é™ä½50%
                weighted_similarity *= 0.5
                logger.debug(f"åœ°å€é—¨ç‰Œå·ä¸åŒ¹é…ï¼Œç›¸ä¼¼åº¦é™ä½: {comp1['number']} vs {comp2['number']}")
        
        # åº”ç”¨æœ€ç»ˆé˜ˆå€¼ï¼šåœ°å€ç›¸ä¼¼åº¦ä½äº60%è®¤ä¸ºä¸åŒ¹é…
        if weighted_similarity < 0.6:
            weighted_similarity *= 0.5  # è¿›ä¸€æ­¥é™ä½
        
        logger.debug(f"åœ°å€ç›¸ä¼¼åº¦è®¡ç®—: {addr1} <-> {addr2} = {weighted_similarity:.3f}")
        logger.debug(f"  ç»„ä»¶å¾—åˆ†: {component_scores}")
        
        return min(weighted_similarity, 1.0)
    
    def _check_boundary_conditions(self, source_record: Dict[str, Any], target_record: Dict[str, Any],
                                 primary_validation: Dict[str, Any], secondary_validation: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ£€æŸ¥è¾¹ç•Œæƒ…å†µï¼Œé¿å…ä¿¡æ¯é‡è¿‡å°‘æˆ–è´¨é‡è¿‡ä½çš„åŒ¹é…
        
        Args:
            source_record: æºè®°å½•
            target_record: ç›®æ ‡è®°å½•
            primary_validation: ä¸»è¦å­—æ®µéªŒè¯ç»“æœ
            secondary_validation: æ¬¡è¦å­—æ®µéªŒè¯ç»“æœ
            
        Returns:
            Dict[str, Any]: è¾¹ç•Œæ£€æŸ¥ç»“æœ
        """
        # è·å–ä¸»è¦å­—æ®µå’Œæ¬¡è¦å­—æ®µçš„å€¼
        primary_configs = [c for c in self.validation_configs if c.is_primary]
        secondary_configs = [c for c in self.validation_configs if not c.is_primary]
        
        # æ£€æŸ¥1ï¼šä¿¡æ¯é‡è¿‡å°‘ï¼ˆå­—æ®µå€¼å¤ªçŸ­ï¼‰
        for config in primary_configs:
            source_value = str((source_record or {}).get(config.source_field, '')).strip()
            target_value = str((target_record or {}).get(config.target_field, '')).strip()
            
            # æ”¾å®½æ¡ä»¶ï¼šåªæœ‰å½“å­—æ®µå€¼å°‘äº2ä¸ªå­—ç¬¦æ—¶æ‰è®¤ä¸ºä¿¡æ¯é‡ä¸è¶³
            if len(source_value) < 2 or len(target_value) < 2:
                return {
                    'is_valid': False,
                    'reason': f'ä¸»è¦å­—æ®µä¿¡æ¯é‡ä¸¥é‡ä¸è¶³: "{source_value}" vs "{target_value}" (é•¿åº¦<2)'
                }
        
        # æ£€æŸ¥2ï¼šå•ä½åç§°è¯­ä¹‰å†²çªæ£€æŸ¥
        for config in primary_configs:
            if config.match_type == 'unit_name':
                source_value = str((source_record or {}).get(config.source_field, '')).strip()
                target_value = str((target_record or {}).get(config.target_field, '')).strip()
                
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨è¯­ä¹‰å†²çªï¼ˆå¦‚ï¼šå…»è€é™¢ vs æŠ¤ç†é™¢ï¼‰
                conflict_result = self._check_unit_name_semantic_conflict(source_value, target_value)
                if conflict_result['has_conflict']:
                    # å¦‚æœå­˜åœ¨è¯­ä¹‰å†²çªä½†ç›¸ä¼¼åº¦å¾ˆé«˜ï¼Œå¯èƒ½æ˜¯åŒä¹‰è¯ï¼Œéœ€è¦æ›´ä¸¥æ ¼çš„éªŒè¯
                    field_scores = (primary_validation or {}).get('field_scores', {}) or {}
                    field_score = field_scores.get(config.field_name, 0.0)
                    if field_score < 0.5:  # æ”¾å®½è¯­ä¹‰å†²çªæ£€æŸ¥ï¼Œé™ä½åˆ°50%
                        return {
                            'is_valid': False,
                            'reason': f'å•ä½åç§°è¯­ä¹‰å†²çª: {conflict_result["reason"]} (ç›¸ä¼¼åº¦{field_score:.1%}<50%)'
                        }
        
        # æ£€æŸ¥3ï¼šåœ°å€ç²¾ç¡®åº¦æ£€æŸ¥
        for config in secondary_configs:
            if config.match_type == 'address':
                source_value = str((source_record or {}).get(config.source_field, '')).strip()
                target_value = str((target_record or {}).get(config.target_field, '')).strip()
                
                # æ£€æŸ¥åœ°å€ç²¾ç¡®åº¦
                precision_result = self._check_address_precision(source_value, target_value)
                if not precision_result['is_precise']:
                    return {
                        'is_valid': False,
                        'reason': f'åœ°å€ç²¾ç¡®åº¦ä¸è¶³: {precision_result["reason"]}'
                    }
        
        return {'is_valid': True, 'reason': None}
    
    def _check_unit_name_semantic_conflict(self, name1: str, name2: str) -> Dict[str, Any]:
        """
        æ£€æŸ¥å•ä½åç§°è¯­ä¹‰å†²çª
        
        Args:
            name1: å•ä½åç§°1
            name2: å•ä½åç§°2
            
        Returns:
            Dict[str, Any]: å†²çªæ£€æŸ¥ç»“æœ
        """
        # å®šä¹‰å¯èƒ½å†²çªçš„è¯æ±‡å¯¹
        conflict_pairs = [
            # ('å…»è€é™¢', 'æŠ¤ç†é™¢'),  # è¿™ä¸¤ä¸ªæ˜¯åŒä¹‰è¯ï¼Œä¸åº”è¯¥è§†ä¸ºå†²çª
            ('å…¬å¸', 'é™¢'),       # å…¬å¸ vs é™¢æ‰€ï¼Œå·®å¼‚è¾ƒå¤§
            ('é›†å›¢', 'åˆ†å…¬å¸'),   # é›†å›¢ vs åˆ†å…¬å¸ï¼Œå±‚çº§ä¸åŒ
            ('æ€»éƒ¨', 'åˆ†éƒ¨'),     # æ€»éƒ¨ vs åˆ†éƒ¨ï¼Œå±‚çº§ä¸åŒ
            ('åŒ»é™¢', 'è¯Šæ‰€'),     # åŒ»é™¢ vs è¯Šæ‰€ï¼Œè§„æ¨¡ä¸åŒ
        ]
        
        name1_lower = name1.lower()
        name2_lower = name2.lower()
        
        for word1, word2 in conflict_pairs:
            if (word1 in name1_lower and word2 in name2_lower) or (word2 in name1_lower and word1 in name2_lower):
                return {
                    'has_conflict': True,
                    'reason': f'æ£€æµ‹åˆ°è¯­ä¹‰å†²çªè¯æ±‡: "{word1}" vs "{word2}"'
                }
        
        return {'has_conflict': False, 'reason': None}
    
    def _check_address_precision(self, addr1: str, addr2: str) -> Dict[str, Any]:
        """
        æ£€æŸ¥åœ°å€ç²¾ç¡®åº¦
        
        Args:
            addr1: åœ°å€1
            addr2: åœ°å€2
            
        Returns:
            Dict[str, Any]: ç²¾ç¡®åº¦æ£€æŸ¥ç»“æœ
        """
        import re
        
        # æå–é—¨ç‰Œå·
        def extract_house_number(addr):
            match = re.search(r'(\d+)å·?', addr)
            return match.group(1) if match else None
        
        num1 = extract_house_number(addr1)
        num2 = extract_house_number(addr2)
        
        # å¦‚æœä¸¤ä¸ªåœ°å€éƒ½æœ‰é—¨ç‰Œå·ä½†ä¸ä¸€è‡´ï¼Œæ£€æŸ¥å·®å¼‚ç¨‹åº¦
        if num1 and num2 and num1 != num2:
            try:
                diff = abs(int(num1) - int(num2))
                # æ”¾å®½æ¡ä»¶ï¼šå¦‚æœé—¨ç‰Œå·å·®å¼‚è¶…è¿‡50ï¼Œè®¤ä¸ºæ˜¯ä¸åŒåœ°å€
                if diff > 50:
                    return {
                        'is_precise': False,
                        'reason': f'é—¨ç‰Œå·å·®å¼‚è¿‡å¤§: {num1}å· vs {num2}å· (å·®å¼‚{diff})'
                    }
            except ValueError:
                # é—¨ç‰Œå·ä¸æ˜¯çº¯æ•°å­—ï¼Œç›´æ¥æ¯”è¾ƒ
                if num1 != num2:
                    return {
                        'is_precise': False,
                        'reason': f'é—¨ç‰Œå·ä¸åŒ¹é…: {num1} vs {num2}'
                    }
        
        # æ£€æŸ¥è¡—é“åç§°
        def extract_street_name(addr):
            match = re.search(r'([^å¸‚åŒºå¿]*?[è·¯è¡—é“å··å¼„])', addr)
            return match.group(1) if match else None
        
        street1 = extract_street_name(addr1)
        street2 = extract_street_name(addr2)
        
        # å¦‚æœè¡—é“åç§°å®Œå…¨ä¸åŒï¼Œè®¤ä¸ºç²¾ç¡®åº¦ä¸è¶³
        if street1 and street2 and street1 != street2:
            # è®¡ç®—è¡—é“åç§°ç›¸ä¼¼åº¦
            street_sim = self._simple_similarity(street1, street2)
            if street_sim < 0.7:  # è¡—é“ç›¸ä¼¼åº¦ä½äº70%
                return {
                    'is_precise': False,
                    'reason': f'è¡—é“åç§°å·®å¼‚è¿‡å¤§: "{street1}" vs "{street2}" (ç›¸ä¼¼åº¦{street_sim:.1%})'
                }
        
        return {'is_precise': True, 'reason': None}
