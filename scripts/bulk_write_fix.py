#!/usr/bin/env python3
"""
æ‰¹é‡å†™å…¥æ“ä½œä¿®å¤è„šæœ¬
ä¿®å¤MongoDBæ‰¹é‡å†™å…¥æ“ä½œä¸­çš„æ•°æ®ç±»å‹å’Œæ ¼å¼é—®é¢˜
"""

import os
import sys
import time
import json
import yaml
from pathlib import Path
from datetime import datetime
from bson import ObjectId

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ æ‰¹é‡å†™å…¥æ“ä½œä¿®å¤å¼€å§‹...")
    
    try:
        from src.database.connection import DatabaseManager
        
        # åŠ è½½æ•°æ®åº“é…ç½®
        with open("config/database.yaml", "r", encoding="utf-8") as f:
            config = yaml.safe_load(f)
        
        db_manager = DatabaseManager(config)
        
        # è·å–æ­£ç¡®çš„é›†åˆ
        match_collection = db_manager.get_collection("unit_match_results")
        
        # ä¿®å¤æ•°æ®ç±»å‹é—®é¢˜çš„æ‰¹é‡å†™å…¥æ“ä½œ
        def safe_bulk_write(operations):
            """å®‰å…¨çš„æ‰¹é‡å†™å…¥æ“ä½œ"""
            try:
                # æ•°æ®ç±»å‹è½¬æ¢
                safe_operations = []
                
                for op in operations:
                    if 'replaceOne' in op:
                        replace_op = op['replaceOne']
                        
                        # ç¡®ä¿æ‰€æœ‰datetimeå¯¹è±¡éƒ½æ˜¯æ­£ç¡®çš„æ ¼å¼
                        replacement = replace_op['replacement']
                        
                        # è½¬æ¢datetimeå¯¹è±¡
                        for key, value in replacement.items():
                            if isinstance(value, datetime):
                                replacement[key] = value
                            elif key in ['created_time', 'updated_time', 'review_time'] and value is not None:
                                if isinstance(value, str):
                                    try:
                                        replacement[key] = datetime.fromisoformat(value.replace('Z', '+00:00'))
                                    except:
                                        replacement[key] = datetime.now()
                                else:
                                    replacement[key] = value
                        
                        # åˆ›å»ºå®‰å…¨çš„æ“ä½œ
                        safe_op = {
                            'replaceOne': {
                                'filter': replace_op['filter'],
                                'replacement': replacement,
                                'upsert': True
                            }
                        }
                        safe_operations.append(safe_op)
                
                # æ‰§è¡Œæ‰¹é‡æ“ä½œ
                if safe_operations:
                    result = match_collection.bulk_write(safe_operations)
                    return result
                else:
                    return None
                    
            except Exception as e:
                print(f"æ‰¹é‡å†™å…¥å¤±è´¥: {e}")
                return None
        
        # æµ‹è¯•æ‰¹é‡å†™å…¥
        test_operations = [
            {
                'replaceOne': {
                    'filter': {'source_record_id': 'test_fix_001'},
                    'replacement': {
                        'source_record_id': 'test_fix_001',
                        'source_system': 'supervision',
                        'match_type': 'none',
                        'match_status': 'unmatched',
                        'similarity_score': 0.0,
                        'match_confidence': 'none',
                        'created_time': datetime.now(),
                        'updated_time': datetime.now(),
                        'review_status': 'pending',
                        'review_time': None
                    },
                    'upsert': True
                }
            }
        ]
        
        # æ‰§è¡Œæµ‹è¯•
        result = safe_bulk_write(test_operations)
        
        if result:
            print(f"âœ… æ‰¹é‡å†™å…¥æµ‹è¯•æˆåŠŸ: æ’å…¥={result.upserted_count}, ä¿®æ”¹={result.modified_count}")
            
            # éªŒè¯æ•°æ®æ˜¯å¦å†™å…¥
            test_record = match_collection.find_one({'source_record_id': 'test_fix_001'})
            if test_record:
                print("âœ… æ•°æ®å†™å…¥éªŒè¯æˆåŠŸ")
                
                # æ¸…ç†æµ‹è¯•æ•°æ®
                match_collection.delete_one({'source_record_id': 'test_fix_001'})
                print("âœ… æµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")
            else:
                print("âŒ æ•°æ®å†™å…¥éªŒè¯å¤±è´¥")
        else:
            print("âŒ æ‰¹é‡å†™å…¥æµ‹è¯•å¤±è´¥")
        
        # ä¿®å¤ä¼˜åŒ–å¤„ç†å™¨ä¸­çš„æ‰¹é‡å†™å…¥æ–¹æ³•
        processor_file = project_root / "src" / "matching" / "optimized_match_processor.py"
        
        if processor_file.exists():
            with open(processor_file, 'r', encoding='utf-8') as f:
                code = f.read()
            
            # å¤‡ä»½
            with open(f"{processor_file}.bulk_fix_backup", 'w', encoding='utf-8') as f:
                f.write(code)
            
            # æŸ¥æ‰¾å¹¶æ›¿æ¢æ‰¹é‡å†™å…¥æ–¹æ³•
            old_method = '''    def _batch_save_optimized_results(self, results: List[Dict]) -> bool:
        """æ‰¹é‡ä¿å­˜ä¼˜åŒ–çš„åŒ¹é…ç»“æœ"""
        try:
            collection = self.db_manager.get_collection('unit_match_results')
            
            operations = []
            
            for result in results:
                if result.get('operation') == 'skipped':
                    continue
                
                source_id = result.get('source_record_id')
                if not source_id:
                    continue
                
                # ç§»é™¤æ“ä½œæ ‡è¯†ï¼Œä¸ä¿å­˜åˆ°æ•°æ®åº“
                result_to_save = {k: v for k, v in result.items() if k not in ['operation', 'previous_result_id']}
                
                # ä½¿ç”¨upsertæ“ä½œï¼ŒåŸºäºsource_record_idè¿›è¡Œå»é‡
                operations.append({
                    'replaceOne': {
                        'filter': {'source_record_id': source_id},
                        'replacement': result_to_save,
                        'upsert': True
                    }
                })
            
            if operations:
                # æ‰§è¡Œæ‰¹é‡æ“ä½œ
                bulk_result = collection.bulk_write(operations)
                
                logger.info(f"æ‰¹é‡ä¿å­˜ç»“æœ: åŒ¹é…={bulk_result.matched_count}, "
                          f"ä¿®æ”¹={bulk_result.modified_count}, æ’å…¥={bulk_result.upserted_count}")
                
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"æ‰¹é‡ä¿å­˜ä¼˜åŒ–åŒ¹é…ç»“æœå¤±è´¥: {str(e)}")
            return False'''
            
            new_method = '''    def _batch_save_optimized_results(self, results: List[Dict]) -> bool:
        """æ‰¹é‡ä¿å­˜ä¼˜åŒ–çš„åŒ¹é…ç»“æœ"""
        try:
            collection = self.db_manager.get_collection('unit_match_results')
            
            operations = []
            
            for result in results:
                if result.get('operation') == 'skipped':
                    continue
                
                source_id = result.get('source_record_id')
                if not source_id:
                    continue
                
                # ç§»é™¤æ“ä½œæ ‡è¯†ï¼Œä¸ä¿å­˜åˆ°æ•°æ®åº“
                result_to_save = {k: v for k, v in result.items() if k not in ['operation', 'previous_result_id']}
                
                # æ•°æ®ç±»å‹å®‰å…¨å¤„ç†
                for key, value in result_to_save.items():
                    if key in ['created_time', 'updated_time', 'review_time'] and value is not None:
                        if not isinstance(value, datetime):
                            try:
                                if isinstance(value, str):
                                    result_to_save[key] = datetime.fromisoformat(value.replace('Z', '+00:00'))
                                else:
                                    result_to_save[key] = datetime.now()
                            except:
                                result_to_save[key] = datetime.now()
                    elif key == 'similarity_score' and value is not None:
                        result_to_save[key] = float(value) if value != '' else 0.0
                
                # ä½¿ç”¨upsertæ“ä½œï¼ŒåŸºäºsource_record_idè¿›è¡Œå»é‡
                operations.append({
                    'replaceOne': {
                        'filter': {'source_record_id': source_id},
                        'replacement': result_to_save,
                        'upsert': True
                    }
                })
            
            if operations:
                # æ‰§è¡Œæ‰¹é‡æ“ä½œ
                bulk_result = collection.bulk_write(operations)
                
                logger.info(f"æ‰¹é‡ä¿å­˜ç»“æœ: åŒ¹é…={bulk_result.matched_count}, "
                          f"ä¿®æ”¹={bulk_result.modified_count}, æ’å…¥={bulk_result.upserted_count}")
                
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"æ‰¹é‡ä¿å­˜ä¼˜åŒ–åŒ¹é…ç»“æœå¤±è´¥: {str(e)}")
            return False'''
            
            if old_method in code:
                code = code.replace(old_method, new_method)
                
                with open(processor_file, 'w', encoding='utf-8') as f:
                    f.write(code)
                
                print("âœ… æ‰¹é‡å†™å…¥æ–¹æ³•å·²ä¿®å¤")
            else:
                print("âš ï¸ æ‰¹é‡å†™å…¥æ–¹æ³•æœªæ‰¾åˆ°ï¼Œå¯èƒ½å·²ç»ä¿®å¤")
        
        print("ğŸ‰ æ‰¹é‡å†™å…¥æ“ä½œä¿®å¤å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ ä¿®å¤å¤±è´¥: {e}")

if __name__ == "__main__":
    main() 