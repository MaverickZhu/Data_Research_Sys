"""
æ™ºèƒ½ç´¢å¼•ç®¡ç†å™¨
æ ¹æ®å­—æ®µæ˜ å°„è‡ªåŠ¨åˆ›å»ºå’Œä¼˜åŒ–æ•°æ®åº“ç´¢å¼•
"""

import logging
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import pymongo
from pymongo import ASCENDING, DESCENDING, TEXT, HASHED
import threading
import time

logger = logging.getLogger(__name__)


class SmartIndexManager:
    """æ™ºèƒ½ç´¢å¼•ç®¡ç†å™¨"""
    
    def __init__(self, db_manager):
        """
        åˆå§‹åŒ–æ™ºèƒ½ç´¢å¼•ç®¡ç†å™¨
        
        Args:
            db_manager: æ•°æ®åº“ç®¡ç†å™¨
        """
        self.db_manager = db_manager
        self.db = db_manager.mongo_client.get_database() if db_manager and db_manager.mongo_client else None
        self.index_cache = {}
        self.cache_lock = threading.Lock()
        
        # ç´¢å¼•é…ç½®
        self.index_config = {
            'text_search': {
                'default_language': 'none',  # å…³é—­è¯­è¨€ç‰¹å®šå¤„ç†ï¼Œé€‚åˆä¸­æ–‡
                'background': True,
                'sparse': True
            },
            'compound': {
                'background': True,
                'sparse': False
            },
            'single': {
                'background': True,
                'sparse': True
            },
            'performance': {
                'batch_size': 1000,
                'max_time_ms': 30000,  # 30ç§’è¶…æ—¶
                'enable_profiling': True
            }
        }
        
        logger.info("æ™ºèƒ½ç´¢å¼•ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _create_smart_text_index(self, collection, target_fields, existing_indexes, result, target_table):
        """
        æ™ºèƒ½æ–‡æœ¬ç´¢å¼•ç®¡ç† - è§£å†³MongoDBæ¯ä¸ªé›†åˆåªèƒ½æœ‰ä¸€ä¸ªæ–‡æœ¬ç´¢å¼•çš„é™åˆ¶
        """
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨æ–‡æœ¬ç´¢å¼•
            existing_text_indexes = []
            # è·å–è¯¦ç»†çš„ç´¢å¼•ä¿¡æ¯
            index_info_dict = collection.index_information()
            for index_name, index_info in index_info_dict.items():
                # å¤„ç†ä¸åŒæ ¼å¼çš„ç´¢å¼•ä¿¡æ¯
                if isinstance(index_info, dict):
                    key_info = index_info.get('key', {})
                    if isinstance(key_info, dict) and key_info.get('_fts') == 'text':
                        existing_text_indexes.append(index_name)
                elif isinstance(index_info, list):
                    # æŸäº›æƒ…å†µä¸‹ç´¢å¼•ä¿¡æ¯å¯èƒ½æ˜¯åˆ—è¡¨æ ¼å¼
                    for item in index_info:
                        if isinstance(item, dict) and item.get('_fts') == 'text':
                            existing_text_indexes.append(index_name)
                            break
            
            if existing_text_indexes:
                # å·²å­˜åœ¨æ–‡æœ¬ç´¢å¼•ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
                existing_index_name = existing_text_indexes[0]
                existing_index_info = index_info_dict[existing_index_name]
                # å®‰å…¨è·å–æƒé‡ä¿¡æ¯
                if isinstance(existing_index_info, dict):
                    existing_weights = existing_index_info.get('weights', {})
                else:
                    existing_weights = {}
                
                # æ£€æŸ¥å½“å‰å­—æ®µæ˜¯å¦éƒ½åœ¨ç°æœ‰æ–‡æœ¬ç´¢å¼•ä¸­
                missing_fields = [field for field in target_fields if field not in existing_weights]
                
                if missing_fields:
                    logger.info(f"ğŸ“ æ–‡æœ¬ç´¢å¼•éœ€è¦æ›´æ–°ï¼Œç¼ºå°‘å­—æ®µ: {missing_fields}")
                    
                    # åˆ é™¤æ—§çš„æ–‡æœ¬ç´¢å¼•
                    try:
                        collection.drop_index(existing_index_name)
                        logger.info(f"ğŸ—‘ï¸ åˆ é™¤æ—§æ–‡æœ¬ç´¢å¼•: {existing_index_name}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ åˆ é™¤æ—§æ–‡æœ¬ç´¢å¼•å¤±è´¥: {e}")
                    
                    # åˆ›å»ºåŒ…å«æ‰€æœ‰å­—æ®µçš„æ–°æ–‡æœ¬ç´¢å¼•
                    self._create_compound_text_index(collection, target_fields, result, target_table)
                else:
                    logger.info(f"âœ… æ–‡æœ¬ç´¢å¼•å·²åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ: {existing_index_name}")
                    result['skipped_count'] += 1
            else:
                # ä¸å­˜åœ¨æ–‡æœ¬ç´¢å¼•ï¼Œåˆ›å»ºæ–°çš„å¤åˆæ–‡æœ¬ç´¢å¼•
                self._create_compound_text_index(collection, target_fields, result, target_table)
                
        except Exception as e:
            result['error_count'] += 1
            logger.warning(f"âš ï¸ æ™ºèƒ½æ–‡æœ¬ç´¢å¼•ç®¡ç†å¤±è´¥: {e}")
    
    def _create_compound_text_index(self, collection, target_fields, result, target_table):
        """åˆ›å»ºå¤åˆæ–‡æœ¬ç´¢å¼•ï¼ˆç®€åŒ–ç‰ˆï¼Œè°ƒç”¨å‰å·²æ£€æŸ¥å†²çªï¼‰"""
        try:
            # ç›´æ¥åˆ›å»ºå¤åˆæ–‡æœ¬ç´¢å¼•
            text_fields = [(field, TEXT) for field in target_fields]
            text_weights = {field: 1 for field in target_fields}
            
            collection.create_index(
                text_fields,
                name="idx_compound_text",
                weights=text_weights,
                **self.index_config['text_search']
            )
            
            result['created_count'] += 1
            result['indexes'].append("idx_compound_text")
            logger.info(f"âœ… å¤åˆæ–‡æœ¬ç´¢å¼•åˆ›å»ºæˆåŠŸ: {target_table}.idx_compound_text (å­—æ®µ: {', '.join(target_fields)})")
            
        except Exception as e:
            result['error_count'] += 1
            logger.info(f"ğŸ“‹ å¤åˆæ–‡æœ¬ç´¢å¼•è·³è¿‡ï¼ˆç´¢å¼•å†²çªï¼‰: {target_table}.idx_compound_text - {e}")
    
    def create_mapping_optimized_indexes(self, mappings: List[Dict], source_table: str, 
                                       target_tables: List[str]) -> Dict[str, Any]:
        """
        æ ¹æ®å­—æ®µæ˜ å°„åˆ›å»ºä¼˜åŒ–ç´¢å¼•
        
        Args:
            mappings: å­—æ®µæ˜ å°„é…ç½®åˆ—è¡¨
            source_table: æºè¡¨å
            target_tables: ç›®æ ‡è¡¨ååˆ—è¡¨
            
        Returns:
            Dict: ç´¢å¼•åˆ›å»ºç»“æœæŠ¥å‘Š
        """
        if self.db is None:
            logger.error("æ•°æ®åº“è¿æ¥æœªåˆå§‹åŒ–")
            return {'success': False, 'error': 'æ•°æ®åº“è¿æ¥æœªåˆå§‹åŒ–'}
        
        start_time = time.time()
        results = {
            'success': True,
            'source_table_indexes': {},
            'target_table_indexes': {},
            'performance_indexes': {},
            'total_time': 0,
            'created_count': 0,
            'skipped_count': 0,
            'error_count': 0,
            'errors': []
        }
        
        try:
            logger.info(f"å¼€å§‹ä¸ºæ˜ å°„é…ç½®åˆ›å»ºä¼˜åŒ–ç´¢å¼•")
            logger.info(f"æºè¡¨: {source_table}, ç›®æ ‡è¡¨: {target_tables}")
            logger.info(f"å­—æ®µæ˜ å°„æ•°é‡: {len(mappings)}")
            
            # 1. ä¸ºæºè¡¨åˆ›å»ºç´¢å¼•
            source_result = self._create_source_table_indexes(source_table, mappings)
            results['source_table_indexes'] = source_result
            results['created_count'] += source_result.get('created_count', 0)
            results['skipped_count'] += source_result.get('skipped_count', 0)
            results['error_count'] += source_result.get('error_count', 0)
            
            # 2. ä¸ºç›®æ ‡è¡¨åˆ›å»ºç´¢å¼•
            for target_table in target_tables:
                target_result = self._create_target_table_indexes(target_table, mappings)
                results['target_table_indexes'][target_table] = target_result
                results['created_count'] += target_result.get('created_count', 0)
                results['skipped_count'] += target_result.get('skipped_count', 0)
                results['error_count'] += target_result.get('error_count', 0)
            
            # 3. åˆ›å»ºæ€§èƒ½ä¼˜åŒ–ç´¢å¼•
            perf_result = self._create_performance_indexes(source_table, target_tables, mappings)
            results['performance_indexes'] = perf_result
            results['created_count'] += perf_result.get('created_count', 0)
            results['skipped_count'] += perf_result.get('skipped_count', 0)
            results['error_count'] += perf_result.get('error_count', 0)
            
            # 4. åˆ›å»ºåŒ¹é…ç»“æœè¡¨ç´¢å¼•
            match_result = self._create_match_result_indexes(source_table, target_tables)
            results['match_result_indexes'] = match_result
            results['created_count'] += match_result.get('created_count', 0)
            results['skipped_count'] += match_result.get('skipped_count', 0)
            results['error_count'] += match_result.get('error_count', 0)
            
        except Exception as e:
            logger.error(f"åˆ›å»ºä¼˜åŒ–ç´¢å¼•å¤±è´¥: {str(e)}")
            results['success'] = False
            results['errors'].append(str(e))
        
        results['total_time'] = time.time() - start_time
        
        logger.info(f"ç´¢å¼•åˆ›å»ºå®Œæˆ - åˆ›å»º: {results['created_count']}, "
                   f"è·³è¿‡: {results['skipped_count']}, é”™è¯¯: {results['error_count']}, "
                   f"è€—æ—¶: {results['total_time']:.2f}ç§’")
        
        return results
    
    def _create_source_table_indexes(self, source_table: str, mappings: List[Dict]) -> Dict[str, Any]:
        """ä¸ºæºè¡¨åˆ›å»ºç´¢å¼•"""
        result = {'created_count': 0, 'skipped_count': 0, 'error_count': 0, 'indexes': []}
        
        try:
            collection = self.db[source_table]
            existing_indexes = set(collection.index_information().keys())
            
            # æå–æºå­—æ®µ
            source_fields = [mapping['source_field'] for mapping in mappings]
            
            # 1. å•å­—æ®µç´¢å¼•ï¼ˆç”¨äºå¿«é€ŸæŸ¥æ‰¾ï¼‰
            for field in source_fields:
                indexes_to_create = [
                    (f"idx_{field}_asc", [(field, ASCENDING)]),
                    (f"idx_{field}_text", [(field, TEXT)]),
                ]
                
                for index_name, index_spec in indexes_to_create:
                    if index_name not in existing_indexes:
                        try:
                            if index_spec[0][1] == TEXT:
                                collection.create_index(
                                    index_spec, 
                                    name=index_name,
                                    **self.index_config['text_search']
                                )
                            else:
                                collection.create_index(
                                    index_spec, 
                                    name=index_name,
                                    **self.index_config['single']
                                )
                            result['created_count'] += 1
                            result['indexes'].append(index_name)
                            logger.info(f"âœ… æºè¡¨ç´¢å¼•åˆ›å»º: {source_table}.{index_name}")
                        except Exception as e:
                            result['error_count'] += 1
                            logger.warning(f"âš ï¸ æºè¡¨ç´¢å¼•åˆ›å»ºå¤±è´¥: {index_name} - {str(e)}")
                    else:
                        result['skipped_count'] += 1
            
            # 2. å¤åˆç´¢å¼•ï¼ˆç”¨äºå¤šå­—æ®µæŸ¥è¯¢ä¼˜åŒ–ï¼‰
            if len(source_fields) > 1:
                # åˆ›å»ºå‰ä¸¤ä¸ªå­—æ®µçš„å¤åˆç´¢å¼•
                compound_fields = source_fields[:2]
                compound_name = f"idx_compound_{'_'.join(compound_fields)}"
                
                if compound_name not in existing_indexes:
                    try:
                        compound_spec = [(field, ASCENDING) for field in compound_fields]
                        collection.create_index(
                            compound_spec,
                            name=compound_name,
                            **self.index_config['compound']
                        )
                        result['created_count'] += 1
                        result['indexes'].append(compound_name)
                        logger.info(f"âœ… æºè¡¨å¤åˆç´¢å¼•åˆ›å»º: {source_table}.{compound_name}")
                    except Exception as e:
                        result['error_count'] += 1
                        logger.warning(f"âš ï¸ æºè¡¨å¤åˆç´¢å¼•åˆ›å»ºå¤±è´¥: {compound_name} - {str(e)}")
                else:
                    result['skipped_count'] += 1
            
            # 3. åŸºç¡€æ€§èƒ½ç´¢å¼•
            basic_indexes = [
                ("idx_id_asc", [("_id", ASCENDING)]),  # MongoDBé»˜è®¤æœ‰ï¼Œä½†ç¡®ä¿å­˜åœ¨
                ("idx_created_desc", [("created_at", DESCENDING)]),
                ("idx_updated_desc", [("updated_at", DESCENDING)]),
            ]
            
            for index_name, index_spec in basic_indexes:
                if index_name not in existing_indexes:
                    try:
                        collection.create_index(
                            index_spec,
                            name=index_name,
                            **self.index_config['single']
                        )
                        result['created_count'] += 1
                        result['indexes'].append(index_name)
                        logger.info(f"âœ… æºè¡¨åŸºç¡€ç´¢å¼•åˆ›å»º: {source_table}.{index_name}")
                    except Exception as e:
                        if "_id" not in index_name:  # _idç´¢å¼•é»˜è®¤å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯
                            result['error_count'] += 1
                            logger.warning(f"âš ï¸ æºè¡¨åŸºç¡€ç´¢å¼•åˆ›å»ºå¤±è´¥: {index_name} - {str(e)}")
                else:
                    result['skipped_count'] += 1
                    
        except Exception as e:
            logger.error(f"æºè¡¨ç´¢å¼•åˆ›å»ºè¿‡ç¨‹å¤±è´¥: {str(e)}")
            result['error_count'] += 1
        
        return result
    
    def _create_target_table_indexes(self, target_table: str, mappings: List[Dict]) -> Dict[str, Any]:
        """ä¸ºç›®æ ‡è¡¨åˆ›å»ºç´¢å¼•"""
        result = {'created_count': 0, 'skipped_count': 0, 'error_count': 0, 'indexes': []}
        
        try:
            collection = self.db[target_table]
            existing_indexes = set(collection.index_information().keys())
            
            # æå–ç›®æ ‡å­—æ®µ
            target_fields = [mapping['target_field'] for mapping in mappings 
                           if mapping['target_table'] == target_table]
            
            if not target_fields:
                return result
            
            # 1. å•å­—æ®µç´¢å¼•ï¼ˆä¸åŒ…å«æ–‡æœ¬ç´¢å¼•ï¼‰
            for field in target_fields:
                indexes_to_create = [
                    (f"idx_{field}_asc", [(field, ASCENDING)]),
                    (f"idx_{field}_hash", [(field, HASHED)]),  # ç”¨äºåˆ†ç‰‡å’Œå¿«é€Ÿç­‰å€¼æŸ¥è¯¢
                ]
                
                for index_name, index_spec in indexes_to_create:
                    if index_name not in existing_indexes:
                        try:
                            if index_spec[0][1] == HASHED:
                                collection.create_index(
                                    index_spec, 
                                    name=index_name,
                                    background=True
                                )
                            else:
                                collection.create_index(
                                    index_spec, 
                                    name=index_name,
                                    **self.index_config['single']
                                )
                            result['created_count'] += 1
                            result['indexes'].append(index_name)
                            logger.info(f"âœ… ç›®æ ‡è¡¨ç´¢å¼•åˆ›å»º: {target_table}.{index_name}")
                        except Exception as e:
                            result['error_count'] += 1
                            logger.warning(f"âš ï¸ ç›®æ ‡è¡¨ç´¢å¼•åˆ›å»ºå¤±è´¥: {index_name} - {str(e)}")
                    else:
                        result['skipped_count'] += 1
            
            # 2. æ™ºèƒ½æ–‡æœ¬ç´¢å¼•ç®¡ç†ï¼ˆè§£å†³MongoDBæ–‡æœ¬ç´¢å¼•å†²çªï¼‰
            # æ³¨æ„ï¼šåœ°å€åŒ¹é…åŠŸèƒ½ä¸ä¾èµ–æ–‡æœ¬ç´¢å¼•ï¼Œä½¿ç”¨åœ°å€å…³é”®è¯ç´¢å¼•å®ç°é«˜æ•ˆåŒ¹é…
            # æ–‡æœ¬ç´¢å¼•å†²çªè­¦å‘Šå¯ä»¥å¿½ç•¥ï¼Œä¸å½±å“åœ°å€åŒ¹é…åŠŸèƒ½
            self._create_smart_text_index(collection, target_fields, existing_indexes, result, target_table)
            
            # 2. å¤åˆç´¢å¼•
            if len(target_fields) > 1:
                compound_fields = target_fields[:2]
                compound_name = f"idx_compound_{'_'.join(compound_fields)}"
                
                if compound_name not in existing_indexes:
                    try:
                        compound_spec = [(field, ASCENDING) for field in compound_fields]
                        collection.create_index(
                            compound_spec,
                            name=compound_name,
                            **self.index_config['compound']
                        )
                        result['created_count'] += 1
                        result['indexes'].append(compound_name)
                        logger.info(f"âœ… ç›®æ ‡è¡¨å¤åˆç´¢å¼•åˆ›å»º: {target_table}.{compound_name}")
                    except Exception as e:
                        result['error_count'] += 1
                        logger.warning(f"âš ï¸ ç›®æ ‡è¡¨å¤åˆç´¢å¼•åˆ›å»ºå¤±è´¥: {compound_name} - {str(e)}")
                else:
                    result['skipped_count'] += 1
                    
        except Exception as e:
            logger.error(f"ç›®æ ‡è¡¨ç´¢å¼•åˆ›å»ºè¿‡ç¨‹å¤±è´¥: {str(e)}")
            result['error_count'] += 1
        
        return result
    
    def _create_performance_indexes(self, source_table: str, target_tables: List[str], 
                                  mappings: List[Dict]) -> Dict[str, Any]:
        """åˆ›å»ºæ€§èƒ½ä¼˜åŒ–ç´¢å¼•"""
        result = {'created_count': 0, 'skipped_count': 0, 'error_count': 0, 'indexes': []}
        
        try:
            # ä¸ºæ‰€æœ‰ç›¸å…³è¡¨åˆ›å»ºæ€§èƒ½ä¼˜åŒ–ç´¢å¼•
            all_tables = [source_table] + target_tables
            
            for table_name in all_tables:
                collection = self.db[table_name]
                existing_indexes = set(collection.index_information().keys())
                
                # æ€§èƒ½ä¼˜åŒ–ç´¢å¼•å®šä¹‰
                perf_indexes = [
                    # åŒ¹é…çŠ¶æ€ç´¢å¼•ï¼ˆç”¨äºå¿«é€Ÿç­›é€‰å·²åŒ¹é…/æœªåŒ¹é…è®°å½•ï¼‰
                    ("idx_is_matched", [("is_matched", ASCENDING)]),
                    ("idx_match_status", [("match_status", ASCENDING)]),
                    
                    # æ—¶é—´èŒƒå›´ç´¢å¼•ï¼ˆç”¨äºå¢é‡åŒ¹é…ï¼‰
                    ("idx_created_time_desc", [("created_at", DESCENDING)]),
                    ("idx_updated_time_desc", [("updated_at", DESCENDING)]),
                    
                    # å¤åˆæ€§èƒ½ç´¢å¼•
                    ("idx_match_time_compound", [("is_matched", ASCENDING), ("updated_at", DESCENDING)]),
                    ("idx_status_time_compound", [("match_status", ASCENDING), ("created_at", DESCENDING)]),
                ]
                
                for index_name, index_spec in perf_indexes:
                    full_index_name = f"{table_name}_{index_name}"
                    
                    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç›¸åŒå­—æ®µçš„ç´¢å¼•ï¼ˆé¿å…å†²çªï¼‰
                    index_exists = False
                    target_fields = [field[0] for field in index_spec]
                    
                    for existing_name, existing_info in collection.index_information().items():
                        if isinstance(existing_info, dict):
                            existing_key = existing_info.get('key', {})
                            if isinstance(existing_key, dict):
                                existing_fields = list(existing_key.keys())
                                if existing_fields == target_fields:
                                    index_exists = True
                                    logger.info(f"ğŸ“‹ è·³è¿‡æ€§èƒ½ç´¢å¼•åˆ›å»ºï¼ˆå·²å­˜åœ¨ç›¸åŒå­—æ®µç´¢å¼•ï¼‰: {table_name}.{existing_name} -> {target_fields}")
                                    break
                    
                    if not index_exists and index_name not in existing_indexes:
                        try:
                            collection.create_index(
                                index_spec,
                                name=index_name,
                                **self.index_config['single']
                            )
                            result['created_count'] += 1
                            result['indexes'].append(full_index_name)
                            logger.info(f"âœ… æ€§èƒ½ç´¢å¼•åˆ›å»º: {table_name}.{index_name}")
                        except Exception as e:
                            # å¦‚æœä»ç„¶å†²çªï¼Œè®°å½•è­¦å‘Šä½†ä¸å½±å“ç³»ç»Ÿè¿è¡Œ
                            result['error_count'] += 1
                            logger.info(f"ğŸ“‹ æ€§èƒ½ç´¢å¼•è·³è¿‡ï¼ˆç´¢å¼•å†²çªï¼‰: {full_index_name} - {str(e)}")
                    else:
                        result['skipped_count'] += 1
                        
        except Exception as e:
            logger.error(f"æ€§èƒ½ç´¢å¼•åˆ›å»ºè¿‡ç¨‹å¤±è´¥: {str(e)}")
            result['error_count'] += 1
        
        return result
    
    def _create_match_result_indexes(self, source_table: str, target_tables: List[str]) -> Dict[str, Any]:
        """ä¸ºåŒ¹é…ç»“æœè¡¨åˆ›å»ºç´¢å¼•"""
        result = {'created_count': 0, 'skipped_count': 0, 'error_count': 0, 'indexes': []}
        
        try:
            # åŒ¹é…ç»“æœé›†åˆåç§°
            result_collection_name = f'user_match_results_{source_table}'
            collection = self.db[result_collection_name]
            existing_indexes = set(collection.index_information().keys())
            
            # åŒ¹é…ç»“æœç´¢å¼•å®šä¹‰
            match_result_indexes = [
                # åŸºç¡€æŸ¥è¯¢ç´¢å¼•
                ("idx_source_id", [("source_id", ASCENDING)]),
                ("idx_target_id", [("target_id", ASCENDING)]),
                ("idx_source_table", [("source_table", ASCENDING)]),
                ("idx_target_table", [("target_table", ASCENDING)]),
                ("idx_task_id", [("task_id", ASCENDING)]),
                ("idx_config_id", [("config_id", ASCENDING)]),
                
                # ç›¸ä¼¼åº¦å’Œè´¨é‡ç´¢å¼•
                ("idx_similarity_desc", [("similarity_score", DESCENDING)]),
                ("idx_confidence", [("match_details.confidence_level", ASCENDING)]),
                ("idx_match_type", [("match_details.match_type", ASCENDING)]),
                
                # æ—¶é—´ç´¢å¼•
                ("idx_created_desc", [("created_at", DESCENDING)]),
                
                # å¤åˆæŸ¥è¯¢ç´¢å¼•
                ("idx_task_similarity", [("task_id", ASCENDING), ("similarity_score", DESCENDING)]),
                ("idx_source_target", [("source_table", ASCENDING), ("target_table", ASCENDING)]),
                ("idx_config_created", [("config_id", ASCENDING), ("created_at", DESCENDING)]),
                
                # ç»Ÿè®¡åˆ†æç´¢å¼•
                ("idx_similarity_confidence", [("similarity_score", DESCENDING), ("match_details.confidence_level", ASCENDING)]),
            ]
            
            for index_name, index_spec in match_result_indexes:
                if index_name not in existing_indexes:
                    try:
                        collection.create_index(
                            index_spec,
                            name=index_name,
                            **self.index_config['single']
                        )
                        result['created_count'] += 1
                        result['indexes'].append(f"{result_collection_name}.{index_name}")
                        logger.info(f"âœ… åŒ¹é…ç»“æœç´¢å¼•åˆ›å»º: {result_collection_name}.{index_name}")
                    except Exception as e:
                        result['error_count'] += 1
                        logger.warning(f"âš ï¸ åŒ¹é…ç»“æœç´¢å¼•åˆ›å»ºå¤±è´¥: {index_name} - {str(e)}")
                else:
                    result['skipped_count'] += 1
                    
        except Exception as e:
            logger.error(f"åŒ¹é…ç»“æœç´¢å¼•åˆ›å»ºè¿‡ç¨‹å¤±è´¥: {str(e)}")
            result['error_count'] += 1
        
        return result
    
    def get_index_statistics(self, table_names: List[str]) -> Dict[str, Any]:
        """è·å–ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯"""
        if not self.db:
            return {'error': 'æ•°æ®åº“è¿æ¥æœªåˆå§‹åŒ–'}
        
        stats = {}
        
        for table_name in table_names:
            try:
                collection = self.db[table_name]
                
                # è·å–ç´¢å¼•ä¿¡æ¯
                indexes = collection.index_information()
                
                # è·å–é›†åˆç»Ÿè®¡
                collection_stats = self.db.command("collStats", table_name)
                
                stats[table_name] = {
                    'index_count': len(indexes),
                    'index_names': list(indexes.keys()),
                    'total_index_size': collection_stats.get('totalIndexSize', 0),
                    'document_count': collection_stats.get('count', 0),
                    'avg_obj_size': collection_stats.get('avgObjSize', 0),
                    'storage_size': collection_stats.get('storageSize', 0)
                }
                
            except Exception as e:
                stats[table_name] = {'error': str(e)}
        
        return stats
    
    def optimize_existing_indexes(self, table_names: List[str]) -> Dict[str, Any]:
        """ä¼˜åŒ–ç°æœ‰ç´¢å¼•"""
        if not self.db:
            return {'error': 'æ•°æ®åº“è¿æ¥æœªåˆå§‹åŒ–'}
        
        results = {}
        
        for table_name in table_names:
            try:
                collection = self.db[table_name]
                
                # é‡å»ºç´¢å¼•ä»¥ä¼˜åŒ–æ€§èƒ½
                result = collection.reindex()
                
                results[table_name] = {
                    'success': True,
                    'reindex_result': result
                }
                
                logger.info(f"âœ… ç´¢å¼•ä¼˜åŒ–å®Œæˆ: {table_name}")
                
            except Exception as e:
                results[table_name] = {
                    'success': False,
                    'error': str(e)
                }
                logger.error(f"âŒ ç´¢å¼•ä¼˜åŒ–å¤±è´¥: {table_name} - {str(e)}")
        
        return results
