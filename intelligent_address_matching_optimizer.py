#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½åœ°å€åŒ¹é…ä¼˜åŒ–å™¨
è§£å†³å½“å‰0%åŒ¹é…ç‡çš„é—®é¢˜ï¼Œå®ç°åŠ¨æ€æƒé‡é…ç½®å’Œæ™ºèƒ½åŒ¹é…ç­–ç•¥
"""

import os
import sys
import logging
import json
import time
from datetime import datetime
from typing import Dict, List, Tuple, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.database.connection import DatabaseManager
from src.utils.config import ConfigManager
from src.matching.similarity_scorer import SimilarityCalculator
from src.matching.address_normalizer import normalize_address_for_matching

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class IntelligentAddressMatchingOptimizer:
    """æ™ºèƒ½åœ°å€åŒ¹é…ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ä¼˜åŒ–å™¨"""
        self.config_manager = ConfigManager()
        self.db_manager = DatabaseManager(config=self.config_manager.get_database_config())
        
        # å®šä¹‰æ™ºèƒ½åŒ¹é…ç­–ç•¥
        self.intelligent_strategies = {
            'flexible_hierarchical': {
                'name': 'çµæ´»å±‚çº§ç­–ç•¥',
                'description': 'å…è®¸è·¨åŒºåŒ¹é…ï¼Œé‡ç‚¹å…³æ³¨è¡—é“å’Œé—¨ç‰Œå·',
                'config': {
                    'similarity_threshold': 0.6,
                    'high_precision_threshold': 0.85,
                    'medium_precision_threshold': 0.6,
                    'enable_cross_district_matching': True,  # å…è®¸è·¨åŒºåŒ¹é…
                    'street_weight': 0.4,  # è¡—é“æƒé‡
                    'number_weight': 0.3,  # é—¨ç‰Œå·æƒé‡
                    'district_weight': 0.2,  # åŒºå¿æƒé‡ï¼ˆé™ä½ï¼‰
                    'building_weight': 0.1   # å»ºç­‘ç‰©æƒé‡
                }
            },
            'semantic_matching': {
                'name': 'è¯­ä¹‰åŒ¹é…ç­–ç•¥',
                'description': 'åŸºäºåœ°å€è¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œå¿½ç•¥è¡Œæ”¿åŒºåˆ’å·®å¼‚',
                'config': {
                    'similarity_threshold': 0.5,
                    'high_precision_threshold': 0.8,
                    'medium_precision_threshold': 0.5,
                    'enable_semantic_matching': True,  # å¯ç”¨è¯­ä¹‰åŒ¹é…
                    'ignore_district_mismatch': True,  # å¿½ç•¥åŒºå¿ä¸åŒ¹é…
                    'focus_on_location_keywords': True,  # å…³æ³¨ä½ç½®å…³é”®è¯
                    'keyword_weight': 0.5,  # å…³é”®è¯æƒé‡
                    'location_weight': 0.3,  # ä½ç½®æƒé‡
                    'administrative_weight': 0.2  # è¡Œæ”¿åŒºåˆ’æƒé‡ï¼ˆå¤§å¹…é™ä½ï¼‰
                }
            },
            'fuzzy_matching': {
                'name': 'æ¨¡ç³ŠåŒ¹é…ç­–ç•¥',
                'description': 'å¤§å¹…é™ä½æ‰€æœ‰é˜ˆå€¼ï¼Œæœ€å¤§åŒ–åŒ¹é…å¯èƒ½æ€§',
                'config': {
                    'similarity_threshold': 0.3,
                    'high_precision_threshold': 0.7,
                    'medium_precision_threshold': 0.3,
                    'province_threshold': 0.7,  # çœçº§é˜ˆå€¼é™ä½
                    'city_threshold': 0.6,     # å¸‚çº§é˜ˆå€¼é™ä½
                    'district_threshold': 0.4,  # åŒºå¿çº§é˜ˆå€¼å¤§å¹…é™ä½
                    'town_threshold': 0.4,     # é•‡è¡—çº§é˜ˆå€¼é™ä½
                    'community_threshold': 0.3, # å°åŒºçº§é˜ˆå€¼é™ä½
                    'street_threshold': 0.3,   # è·¯çº§é˜ˆå€¼é™ä½
                    'lane_threshold': 0.3,     # å¼„çº§é˜ˆå€¼é™ä½
                    'number_threshold': 0.3    # é—¨ç‰Œçº§é˜ˆå€¼é™ä½
                }
            }
        }
    
    def run_intelligent_optimization(self) -> Dict:
        """è¿è¡Œæ™ºèƒ½ä¼˜åŒ–æµ‹è¯•"""
        print("ğŸ§  æ™ºèƒ½åœ°å€åŒ¹é…ä¼˜åŒ–æµ‹è¯•")
        print("=" * 50)
        
        try:
            # 1. å‡†å¤‡æµ‹è¯•æ•°æ®
            test_data = self._prepare_test_data()
            if not test_data or not test_data.get('source_samples'):
                return {'error': 'æ— æ³•è·å–æµ‹è¯•æ•°æ®'}
            
            print(f"ğŸ“Š æµ‹è¯•æ•°æ®å‡†å¤‡å®Œæˆ:")
            print(f"  æºæ•°æ®: {len(test_data['source_samples'])} æ¡")
            print(f"  ç›®æ ‡æ•°æ®: {len(test_data['target_samples'])} æ¡")
            
            # 2. æ‰§è¡ŒåŸºå‡†æµ‹è¯•ï¼ˆå½“å‰é…ç½®ï¼‰
            print("\\nğŸ“ˆ æ‰§è¡ŒåŸºå‡†æµ‹è¯•...")
            baseline_result = self._test_baseline_matching(test_data)
            
            # 3. æµ‹è¯•æ™ºèƒ½ç­–ç•¥
            optimization_results = []
            for strategy_key, strategy in self.intelligent_strategies.items():
                print(f"\\nğŸ§ª æµ‹è¯• {strategy['name']}...")
                result = self._test_intelligent_strategy(strategy_key, strategy, test_data)
                result['improvement'] = self._calculate_improvement(baseline_result, result)
                optimization_results.append(result)
            
            # 4. é€‰æ‹©æœ€ä½³ç­–ç•¥
            best_strategy = self._select_best_strategy(optimization_results)
            
            # 5. ç”Ÿæˆä¼˜åŒ–å»ºè®®
            recommendations = self._generate_intelligent_recommendations(
                baseline_result, optimization_results, best_strategy
            )
            
            return {
                'test_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'baseline_performance': baseline_result,
                'optimization_results': optimization_results,
                'best_strategy': best_strategy,
                'recommendations': recommendations
            }
            
        except Exception as e:
            logger.error(f"æ™ºèƒ½ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {str(e)}")
            return {'error': str(e)}
    
    def _prepare_test_data(self) -> Dict:
        """å‡†å¤‡æµ‹è¯•æ•°æ®"""
        try:
            # è·å–æºè¡¨æ•°æ®ï¼ˆç«ç¾åœ°ç‚¹ï¼‰
            source_collection = self.db_manager.get_collection('hztj_hzxx')
            source_samples = list(source_collection.find(
                {'èµ·ç«åœ°ç‚¹': {'$exists': True, '$ne': '', '$ne': None}}
            ).limit(15))  # å‡å°‘åˆ°15æ¡ä»¥æé«˜æµ‹è¯•æ•ˆç‡
            
            # è·å–ç›®æ ‡è¡¨æ•°æ®ï¼ˆå…»è€æœºæ„åœ°å€ï¼‰
            target_collection = self.db_manager.get_collection('dwd_yljgxx')
            target_samples = list(target_collection.find(
                {'ZCDZ': {'$exists': True, '$ne': '', '$ne': None}}
            ).limit(25))  # å‡å°‘åˆ°25æ¡
            
            # æ ‡å‡†åŒ–å­—æ®µå
            for sample in source_samples:
                sample['address'] = sample.get('èµ·ç«åœ°ç‚¹', '')
            
            for sample in target_samples:
                sample['address'] = sample.get('ZCDZ', '')
            
            return {
                'source_samples': source_samples,
                'target_samples': target_samples,
                'source_field': 'èµ·ç«åœ°ç‚¹',
                'target_field': 'ZCDZ'
            }
            
        except Exception as e:
            logger.error(f"å‡†å¤‡æµ‹è¯•æ•°æ®å¤±è´¥: {str(e)}")
            return {}
    
    def _test_baseline_matching(self, test_data: Dict) -> Dict:
        """æµ‹è¯•åŸºå‡†åŒ¹é…æ€§èƒ½"""
        start_time = time.time()
        
        # ä½¿ç”¨å½“å‰é…ç½®
        similarity_calculator = SimilarityCalculator(self.config_manager.get_matching_config())
        
        results = {
            'strategy_name': 'å½“å‰é…ç½®ï¼ˆåŸºå‡†ï¼‰',
            'total_tests': len(test_data['source_samples']),
            'matches_found': 0,
            'high_precision_matches': 0,
            'medium_precision_matches': 0,
            'match_details': []
        }
        
        for i, source_record in enumerate(test_data['source_samples']):
            source_address = source_record.get('address', '')
            if not source_address:
                continue
            
            # æ ‡å‡†åŒ–æºåœ°å€
            normalized_source = normalize_address_for_matching(source_address)
            
            # å¯»æ‰¾æœ€ä½³åŒ¹é…
            best_similarity = 0.0
            best_match = None
            
            for target_record in test_data['target_samples']:
                target_address = target_record.get('address', '')
                if not target_address:
                    continue
                
                # æ ‡å‡†åŒ–ç›®æ ‡åœ°å€
                normalized_target = normalize_address_for_matching(target_address)
                
                # è®¡ç®—ç›¸ä¼¼åº¦
                similarity = similarity_calculator.calculate_address_similarity(
                    normalized_source, normalized_target
                )
                
                if similarity > best_similarity:
                    best_similarity = similarity
                    best_match = {
                        'target_address': target_address,
                        'similarity': similarity
                    }
            
            # åˆ†ç±»åŒ¹é…ç»“æœ
            if best_similarity >= 0.7:  # å½“å‰é˜ˆå€¼
                results['matches_found'] += 1
                if best_similarity >= 0.9:
                    results['high_precision_matches'] += 1
                elif best_similarity >= 0.7:
                    results['medium_precision_matches'] += 1
            
            # è®°å½•è¯¦ç»†ç»“æœï¼ˆå‰5æ¡ï¼‰
            if len(results['match_details']) < 5:
                results['match_details'].append({
                    'source_address': source_address,
                    'best_match_address': best_match['target_address'] if best_match else '',
                    'similarity_score': best_similarity,
                    'has_match': best_similarity >= 0.7
                })
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        total_time = time.time() - start_time
        results['processing_time'] = total_time
        results['tests_per_second'] = len(test_data['source_samples']) / total_time if total_time > 0 else 0
        results['match_rate'] = results['matches_found'] / results['total_tests'] * 100
        results['high_precision_rate'] = results['high_precision_matches'] / results['total_tests'] * 100
        
        return results
    
    def _test_intelligent_strategy(self, strategy_key: str, strategy: Dict, test_data: Dict) -> Dict:
        """æµ‹è¯•æ™ºèƒ½ç­–ç•¥"""
        start_time = time.time()
        
        strategy_config = strategy['config']
        
        results = {
            'strategy_key': strategy_key,
            'strategy_name': strategy['name'],
            'description': strategy['description'],
            'total_tests': len(test_data['source_samples']),
            'matches_found': 0,
            'high_precision_matches': 0,
            'medium_precision_matches': 0,
            'match_details': []
        }
        
        for i, source_record in enumerate(test_data['source_samples']):
            source_address = source_record.get('address', '')
            if not source_address:
                continue
            
            # æ ‡å‡†åŒ–æºåœ°å€
            normalized_source = normalize_address_for_matching(source_address)
            
            # å¯»æ‰¾æœ€ä½³åŒ¹é…
            best_similarity = 0.0
            best_match = None
            
            for target_record in test_data['target_samples']:
                target_address = target_record.get('address', '')
                if not target_address:
                    continue
                
                # æ ‡å‡†åŒ–ç›®æ ‡åœ°å€
                normalized_target = normalize_address_for_matching(target_address)
                
                # ä½¿ç”¨æ™ºèƒ½ç­–ç•¥è®¡ç®—ç›¸ä¼¼åº¦
                similarity = self._calculate_intelligent_similarity(
                    normalized_source, normalized_target, strategy_config
                )
                
                if similarity > best_similarity:
                    best_similarity = similarity
                    best_match = {
                        'target_address': target_address,
                        'similarity': similarity
                    }
            
            # åˆ†ç±»åŒ¹é…ç»“æœ
            similarity_threshold = strategy_config.get('similarity_threshold', 0.7)
            high_precision_threshold = strategy_config.get('high_precision_threshold', 0.9)
            medium_precision_threshold = strategy_config.get('medium_precision_threshold', 0.7)
            
            if best_similarity >= similarity_threshold:
                results['matches_found'] += 1
                if best_similarity >= high_precision_threshold:
                    results['high_precision_matches'] += 1
                elif best_similarity >= medium_precision_threshold:
                    results['medium_precision_matches'] += 1
            
            # è®°å½•è¯¦ç»†ç»“æœï¼ˆå‰5æ¡ï¼‰
            if len(results['match_details']) < 5:
                results['match_details'].append({
                    'source_address': source_address,
                    'best_match_address': best_match['target_address'] if best_match else '',
                    'similarity_score': best_similarity,
                    'has_match': best_similarity >= similarity_threshold
                })
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        total_time = time.time() - start_time
        results['processing_time'] = total_time
        results['tests_per_second'] = len(test_data['source_samples']) / total_time if total_time > 0 else 0
        results['match_rate'] = results['matches_found'] / results['total_tests'] * 100
        results['high_precision_rate'] = results['high_precision_matches'] / results['total_tests'] * 100
        
        return results
    
    def _calculate_intelligent_similarity(self, addr1: str, addr2: str, strategy_config: Dict) -> float:
        """ä½¿ç”¨æ™ºèƒ½ç­–ç•¥è®¡ç®—åœ°å€ç›¸ä¼¼åº¦"""
        
        # åŸºç¡€æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨ç®€å•çš„å…³é”®è¯åŒ¹é…ï¼‰
        def simple_text_similarity(text1: str, text2: str) -> float:
            # æå–å…³é”®è¯
            keywords1 = set([char for char in text1 if char.isalnum()])
            keywords2 = set([char for char in text2 if char.isalnum()])
            
            if not keywords1 or not keywords2:
                return 0.0
            
            # è®¡ç®—äº¤é›†æ¯”ä¾‹
            intersection = keywords1.intersection(keywords2)
            union = keywords1.union(keywords2)
            
            return len(intersection) / len(union) if union else 0.0
        
        # ç­–ç•¥1: çµæ´»å±‚çº§ç­–ç•¥
        if strategy_config.get('enable_cross_district_matching'):
            # æå–å…³é”®ä¿¡æ¯
            addr1_keywords = [word for word in ['è·¯', 'è¡—', 'å·', 'å¼„', 'æ‘', 'é•‡'] if word in addr1]
            addr2_keywords = [word for word in ['è·¯', 'è¡—', 'å·', 'å¼„', 'æ‘', 'é•‡'] if word in addr2]
            
            # å¦‚æœéƒ½åŒ…å«è·¯/è¡—ä¿¡æ¯ï¼Œé‡ç‚¹æ¯”è¾ƒ
            if any(kw in addr1 for kw in ['è·¯', 'è¡—']) and any(kw in addr2 for kw in ['è·¯', 'è¡—']):
                return simple_text_similarity(addr1, addr2) * 1.2  # åŠ æƒ
        
        # ç­–ç•¥2: è¯­ä¹‰åŒ¹é…ç­–ç•¥
        if strategy_config.get('enable_semantic_matching'):
            # å¿½ç•¥è¡Œæ”¿åŒºåˆ’ï¼Œé‡ç‚¹å…³æ³¨å…·ä½“ä½ç½®
            location_keywords = ['è·¯', 'è¡—', 'å·', 'å¼„', 'æ‘', 'é•‡', 'é™¢', 'ä¸­å¿ƒ', 'å¤§å¦', 'å¹¿åœº']
            
            # æå–ä½ç½®å…³é”®è¯
            addr1_locations = [kw for kw in location_keywords if kw in addr1]
            addr2_locations = [kw for kw in location_keywords if kw in addr2]
            
            if addr1_locations and addr2_locations:
                # åŸºäºä½ç½®å…³é”®è¯çš„ç›¸ä¼¼åº¦
                common_locations = set(addr1_locations).intersection(set(addr2_locations))
                total_locations = set(addr1_locations).union(set(addr2_locations))
                
                if total_locations:
                    location_similarity = len(common_locations) / len(total_locations)
                    text_similarity = simple_text_similarity(addr1, addr2)
                    
                    # ç»¼åˆç›¸ä¼¼åº¦
                    return location_similarity * 0.6 + text_similarity * 0.4
        
        # ç­–ç•¥3: æ¨¡ç³ŠåŒ¹é…ç­–ç•¥ï¼ˆé»˜è®¤ï¼‰
        return simple_text_similarity(addr1, addr2)
    
    def _calculate_improvement(self, baseline: Dict, candidate: Dict) -> Dict:
        """è®¡ç®—ç›¸å¯¹äºåŸºå‡†çš„æ”¹è¿›"""
        baseline_match_rate = baseline.get('match_rate', 0)
        candidate_match_rate = candidate.get('match_rate', 0)
        
        baseline_high_rate = baseline.get('high_precision_rate', 0)
        candidate_high_rate = candidate.get('high_precision_rate', 0)
        
        return {
            'match_rate_improvement': candidate_match_rate - baseline_match_rate,
            'high_precision_improvement': candidate_high_rate - baseline_high_rate,
            'speed_improvement': candidate.get('tests_per_second', 0) - baseline.get('tests_per_second', 0),
            'match_rate_change_percent': ((candidate_match_rate - baseline_match_rate) / baseline_match_rate * 100) if baseline_match_rate > 0 else float('inf') if candidate_match_rate > 0 else 0
        }
    
    def _select_best_strategy(self, results: List[Dict]) -> Dict:
        """é€‰æ‹©æœ€ä½³ç­–ç•¥"""
        if not results:
            return None
        
        # ç»¼åˆè¯„åˆ†ï¼šåŒ¹é…ç‡ * 0.7 + é«˜ç²¾åº¦ç‡ * 0.3
        best_strategy = None
        best_score = -1
        
        for result in results:
            match_rate = result.get('match_rate', 0)
            high_precision_rate = result.get('high_precision_rate', 0)
            
            composite_score = match_rate * 0.7 + high_precision_rate * 0.3
            
            if composite_score > best_score:
                best_score = composite_score
                best_strategy = result
        
        if best_strategy:
            best_strategy['composite_score'] = best_score
        
        return best_strategy
    
    def _generate_intelligent_recommendations(self, baseline: Dict, results: List[Dict], best_strategy: Dict) -> List[str]:
        """ç”Ÿæˆæ™ºèƒ½ä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        baseline_match_rate = baseline.get('match_rate', 0)
        
        # åˆ†æå½“å‰é—®é¢˜
        if baseline_match_rate == 0:
            recommendations.append("ğŸš¨ ä¸¥é‡é—®é¢˜ï¼šå½“å‰é…ç½®åŒ¹é…ç‡ä¸º0%ï¼Œå±‚çº§ç»ˆæ­¢éªŒè¯è¿‡äºä¸¥æ ¼")
            recommendations.append("ğŸ’¡ å»ºè®®ï¼šç«‹å³é‡‡ç”¨'æ¨¡ç³ŠåŒ¹é…ç­–ç•¥'ï¼Œå¤§å¹…é™ä½æ‰€æœ‰å±‚çº§é˜ˆå€¼")
        
        # åˆ†ææœ€ä½³ç­–ç•¥
        if best_strategy and best_strategy.get('match_rate', 0) > baseline_match_rate:
            improvement = best_strategy.get('match_rate', 0) - baseline_match_rate
            recommendations.append(
                f"ğŸ† æ¨èé‡‡ç”¨'{best_strategy['strategy_name']}'ï¼Œå¯å°†åŒ¹é…ç‡æå‡ {improvement:.1f}%"
            )
            recommendations.append(f"ğŸ“‹ ç­–ç•¥æè¿°ï¼š{best_strategy.get('description', '')}")
        
        # æŠ€æœ¯å»ºè®®
        recommendations.append("ğŸ”§ æŠ€æœ¯ä¼˜åŒ–å»ºè®®ï¼š")
        recommendations.append("  1. å®ç°è·¨åŒºåŒ¹é…æœºåˆ¶ï¼Œå…è®¸ä¸åŒåŒºå¿é—´çš„åœ°å€åŒ¹é…")
        recommendations.append("  2. å¢å¼ºè¯­ä¹‰åŒ¹é…èƒ½åŠ›ï¼Œé‡ç‚¹å…³æ³¨è¡—é“ã€é—¨ç‰Œå·ç­‰å…³é”®ä¿¡æ¯")
        recommendations.append("  3. ä¼˜åŒ–å±‚çº§ç»ˆæ­¢éªŒè¯ï¼Œé¿å…è¿‡æ—©ç»ˆæ­¢åŒ¹é…è¿‡ç¨‹")
        recommendations.append("  4. å¼•å…¥åœ°å€ç±»å‹è¯†åˆ«ï¼Œé’ˆå¯¹ä¸åŒç±»å‹é‡‡ç”¨ä¸åŒåŒ¹é…ç­–ç•¥")
        
        return recommendations

def main():
    """ä¸»å‡½æ•°"""
    try:
        optimizer = IntelligentAddressMatchingOptimizer()
        results = optimizer.run_intelligent_optimization()
        
        if 'error' in results:
            print(f"âŒ æ™ºèƒ½ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {results['error']}")
            return
        
        # æ˜¾ç¤ºåŸºå‡†æµ‹è¯•ç»“æœ
        baseline = results['baseline_performance']
        print(f"\\nğŸ“Š åŸºå‡†æµ‹è¯•ç»“æœ:")
        print(f"  æ€»æµ‹è¯•æ•°: {baseline['total_tests']}")
        print(f"  åŒ¹é…ç‡: {baseline['match_rate']:.1f}%")
        print(f"  é«˜ç²¾åº¦ç‡: {baseline['high_precision_rate']:.1f}%")
        print(f"  å¤„ç†é€Ÿåº¦: {baseline['tests_per_second']:.1f} æ¡/ç§’")
        
        # æ˜¾ç¤ºæ™ºèƒ½ç­–ç•¥ç»“æœ
        print(f"\\nğŸ§  æ™ºèƒ½ç­–ç•¥æµ‹è¯•ç»“æœ:")
        for result in results['optimization_results']:
            improvement = result['improvement']
            print(f"\\n  {result['strategy_name']}:")
            print(f"    åŒ¹é…ç‡: {result['match_rate']:.1f}% (æ”¹è¿›: {improvement['match_rate_improvement']:+.1f}%)")
            print(f"    é«˜ç²¾åº¦ç‡: {result['high_precision_rate']:.1f}% (æ”¹è¿›: {improvement['high_precision_improvement']:+.1f}%)")
            print(f"    å¤„ç†é€Ÿåº¦: {result['tests_per_second']:.1f} æ¡/ç§’")
            print(f"    ç­–ç•¥æè¿°: {result['description']}")
        
        # æ˜¾ç¤ºæœ€ä½³ç­–ç•¥
        best_strategy = results['best_strategy']
        if best_strategy:
            print(f"\\nğŸ† æ¨èæœ€ä½³ç­–ç•¥: {best_strategy['strategy_name']}")
            print(f"  ç»¼åˆè¯„åˆ†: {best_strategy['composite_score']:.1f}")
            print(f"  åŒ¹é…ç‡: {best_strategy['match_rate']:.1f}%")
            print(f"  é«˜ç²¾åº¦ç‡: {best_strategy['high_precision_rate']:.1f}%")
        
        # æ˜¾ç¤ºä¼˜åŒ–å»ºè®®
        print(f"\\nğŸ’¡ æ™ºèƒ½ä¼˜åŒ–å»ºè®®:")
        for i, rec in enumerate(results['recommendations'], 1):
            print(f"  {i}. {rec}")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_file = f"intelligent_optimization_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file}")
        
    except Exception as e:
        print(f"âŒ æ™ºèƒ½ä¼˜åŒ–æµ‹è¯•æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

