"""
ç›¸ä¼¼åº¦è®¡ç®—å™¨æ¨¡å—
å®ç°å¤šç§ç›¸ä¼¼åº¦è®¡ç®—ç®—æ³•
"""

import logging
import re
from typing import Dict, List, Optional, Tuple, Any
import jieba
import pypinyin
from fuzzywuzzy import fuzz
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
from src.utils.helpers import normalize_string, normalize_phone, safe_float_convert, calculate_percentage_diff

logger = logging.getLogger(__name__)


class SimilarityCalculator:
    """ç›¸ä¼¼åº¦è®¡ç®—å™¨"""
    
    def __init__(self, config: Dict):
        """
        åˆå§‹åŒ–ç›¸ä¼¼åº¦è®¡ç®—å™¨
        
        Args:
            config: é…ç½®å‚æ•°
        """
        self.config = config
        self.string_config = config.get('string_similarity', {})
        self.chinese_config = self.string_config.get('chinese_processing', {})
        self.numeric_config = config.get('numeric_similarity', {})
        self.phone_config = config.get('phone_similarity', {})
        self.address_config = config.get('address_similarity', {})
        
        # åˆå§‹åŒ–TF-IDFå‘é‡åŒ–å™¨
        self.tfidf_vectorizer = TfidfVectorizer(
            max_features=1000,
            stop_words=None,
            ngram_range=(1, 2)
        )
        
    def calculate_string_similarity(self, str1: str, str2: str) -> float:
        """
        è®¡ç®—å­—ç¬¦ä¸²ç›¸ä¼¼åº¦
        
        Args:
            str1: å­—ç¬¦ä¸²1
            str2: å­—ç¬¦ä¸²2
            
        Returns:
            float: ç›¸ä¼¼åº¦åˆ†æ•° (0-1)
        """
        if not str1 or not str2:
            return 0.0
            
        # æ ‡å‡†åŒ–å­—ç¬¦ä¸²
        str1 = normalize_string(str1)
        str2 = normalize_string(str2)
        
        if str1 == str2:
            return 1.0
            
        # è·å–ç®—æ³•é…ç½®
        algorithms = self.string_config.get('algorithms', [])
        if not algorithms:
            algorithms = [
                {'name': 'levenshtein', 'weight': 0.3},
                {'name': 'jaro_winkler', 'weight': 0.3},
                {'name': 'cosine', 'weight': 0.4}
            ]
        
        total_score = 0.0
        total_weight = 0.0
        
        for algorithm in algorithms:
            name = algorithm['name']
            weight = algorithm['weight']
            
            if name == 'levenshtein':
                score = self._levenshtein_similarity(str1, str2)
            elif name == 'jaro_winkler':
                score = self._jaro_winkler_similarity(str1, str2)
            elif name == 'cosine':
                score = self._cosine_similarity(str1, str2)
            else:
                continue
                
            total_score += score * weight
            total_weight += weight
        
        # ä¸­æ–‡å¤„ç†å¢å¼º
        if self.chinese_config.get('enable_pinyin', True):
            pinyin_score = self._pinyin_similarity(str1, str2)
            total_score += pinyin_score * 0.2
            total_weight += 0.2
        
        return total_score / total_weight if total_weight > 0 else 0.0
    
    def _levenshtein_similarity(self, str1: str, str2: str) -> float:
        """Levenshteinè·ç¦»ç›¸ä¼¼åº¦"""
        return fuzz.ratio(str1, str2) / 100.0
    
    def _jaro_winkler_similarity(self, str1: str, str2: str) -> float:
        """Jaro-Winklerç›¸ä¼¼åº¦"""
        return fuzz.token_sort_ratio(str1, str2) / 100.0
    
    def _cosine_similarity(self, str1: str, str2: str) -> float:
        """ä½™å¼¦ç›¸ä¼¼åº¦"""
        try:
            # ä½¿ç”¨TF-IDFå‘é‡åŒ–
            corpus = [str1, str2]
            tfidf_matrix = self.tfidf_vectorizer.fit_transform(corpus)
            similarity_matrix = cosine_similarity(tfidf_matrix)
            
            return similarity_matrix[0, 1]
        except Exception as e:
            logger.debug(f"ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {str(e)}")
            return 0.0
    
    def _pinyin_similarity(self, str1: str, str2: str) -> float:
        """æ‹¼éŸ³ç›¸ä¼¼åº¦"""
        try:
            # è½¬æ¢ä¸ºæ‹¼éŸ³
            pinyin1 = ''.join([item[0] for item in pypinyin.pinyin(str1, style=pypinyin.NORMAL)])
            pinyin2 = ''.join([item[0] for item in pypinyin.pinyin(str2, style=pypinyin.NORMAL)])
            
            if not pinyin1 or not pinyin2:
                return 0.0
            
            return fuzz.ratio(pinyin1, pinyin2) / 100.0
        except Exception as e:
            logger.debug(f"æ‹¼éŸ³ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {str(e)}")
            return 0.0
    
    def calculate_numeric_similarity(self, num1: Any, num2: Any, field_config: Dict) -> float:
        """
        è®¡ç®—æ•°å€¼ç›¸ä¼¼åº¦
        
        Args:
            num1: æ•°å€¼1
            num2: æ•°å€¼2
            field_config: å­—æ®µé…ç½®
            
        Returns:
            float: ç›¸ä¼¼åº¦åˆ†æ•° (0-1)
        """
        # è½¬æ¢ä¸ºæµ®ç‚¹æ•°
        val1 = safe_float_convert(num1)
        val2 = safe_float_convert(num2)
        
        if val1 == 0 and val2 == 0:
            return 1.0
        
        # è·å–å®¹å·®é…ç½®
        tolerance = field_config.get('tolerance', 0.1)
        
        # è®¡ç®—ç™¾åˆ†æ¯”å·®å¼‚
        diff = calculate_percentage_diff(val1, val2)
        
        # å¦‚æœå·®å¼‚åœ¨å®¹å·®èŒƒå›´å†…ï¼Œè¿”å›é«˜ç›¸ä¼¼åº¦
        if diff <= tolerance:
            return 1.0 - (diff / tolerance) * 0.2  # æœ€é«˜0.8-1.0
        else:
            # è¶…å‡ºå®¹å·®èŒƒå›´ï¼Œç›¸ä¼¼åº¦å¿«é€Ÿä¸‹é™
            return max(0.0, 1.0 - diff)
    
    def calculate_phone_similarity(self, phone1: str, phone2: str) -> float:
        """
        è®¡ç®—ç”µè¯å·ç ç›¸ä¼¼åº¦
        
        Args:
            phone1: ç”µè¯å·ç 1
            phone2: ç”µè¯å·ç 2
            
        Returns:
            float: ç›¸ä¼¼åº¦åˆ†æ•° (0-1)
        """
        if not phone1 or not phone2:
            return 0.0
        
        # æ ‡å‡†åŒ–ç”µè¯å·ç 
        norm_phone1 = normalize_phone(phone1)
        norm_phone2 = normalize_phone(phone2)
        
        if not norm_phone1 or not norm_phone2:
            return 0.0
        
        # å®Œå…¨åŒ¹é…
        if norm_phone1 == norm_phone2:
            return 1.0
        
        # éƒ¨åˆ†åŒ¹é…ï¼ˆå7ä½ï¼‰
        if len(norm_phone1) >= 7 and len(norm_phone2) >= 7:
            suffix1 = norm_phone1[-7:]
            suffix2 = norm_phone2[-7:]
            if suffix1 == suffix2:
                return 0.8
        
        # ä½¿ç”¨ç¼–è¾‘è·ç¦»
        return fuzz.ratio(norm_phone1, norm_phone2) / 100.0 * 0.6
    
    def calculate_address_similarity(self, addr1: str, addr2: str) -> float:
        """
        è®¡ç®—åœ°å€ç›¸ä¼¼åº¦ï¼ˆå¢å¼ºç‰ˆ - æ”¯æŒæ¨¡ç³Šåœ°å€ä¸æ ‡å‡†åœ°å€åŒ¹é…ï¼‰
        
        Args:
            addr1: åœ°å€1ï¼ˆå¯èƒ½æ˜¯æ¨¡ç³Šæè¿°åœ°å€ï¼‰
            addr2: åœ°å€2ï¼ˆå¯èƒ½æ˜¯æ ‡å‡†åœ°å€ï¼‰
            
        Returns:
            float: ç›¸ä¼¼åº¦åˆ†æ•° (0-1)
        """
        if not addr1 or not addr2:
            return 0.0
        
        # åœ°å€æ ‡å‡†åŒ–é¢„å¤„ç†
        # æ¢å¤åœ°å€æ ‡å‡†åŒ– - è¿™æ˜¯åœ°å€åŒ¹é…çš„æ ¸å¿ƒåŠŸèƒ½
        from .address_normalizer import normalize_address_for_matching
        normalized_addr1 = normalize_address_for_matching(addr1)
        normalized_addr2 = normalize_address_for_matching(addr2)
        
        logger.debug(f"åœ°å€æ ‡å‡†åŒ–: '{addr1}' -> '{normalized_addr1}'")
        logger.debug(f"åœ°å€æ ‡å‡†åŒ–: '{addr2}' -> '{normalized_addr2}'")
        
        # ã€è°ƒè¯•ã€‘è®°å½•æ ‡å‡†åŒ–æ•ˆæœ
        if addr1 != normalized_addr1 or addr2 != normalized_addr2:
            logger.info(f"ğŸ”§ åœ°å€æ ‡å‡†åŒ–ç”Ÿæ•ˆ: åŸå§‹1='{addr1}' æ ‡å‡†åŒ–1='{normalized_addr1}' | åŸå§‹2='{addr2}' æ ‡å‡†åŒ–2='{normalized_addr2}'")
        
        if normalized_addr1 == normalized_addr2:
            return 1.0
        
        # ä½¿ç”¨æ ‡å‡†åŒ–åçš„åœ°å€è¿›è¡Œè¯­ä¹‰åˆ†æ
        return self._enhanced_address_semantic_similarity(normalized_addr1, normalized_addr2)
    
    def _enhanced_address_semantic_similarity(self, addr1: str, addr2: str) -> float:
        """
        å¢å¼ºçš„åœ°å€è¯­ä¹‰ç›¸ä¼¼åº¦åˆ†æ
        ä¸“é—¨å¤„ç†æ¨¡ç³Šåœ°å€æè¿°ä¸æ ‡å‡†åœ°å€çš„åŒ¹é…
        
        Args:
            addr1: åœ°å€1
            addr2: åœ°å€2
            
        Returns:
            float: ç›¸ä¼¼åº¦åˆ†æ•° (0-1)
        """
        try:
            # 1. æå–åœ°å€æ ¸å¿ƒç»„ä»¶
            components1 = self._extract_enhanced_address_components(addr1)
            components2 = self._extract_enhanced_address_components(addr2)
            
            # 2. è®¡ç®—ç»„ä»¶æƒé‡åŒ–ç›¸ä¼¼åº¦
            return self._calculate_weighted_address_similarity(components1, components2)
            
        except Exception as e:
            logger.debug(f"å¢å¼ºåœ°å€è¯­ä¹‰åˆ†æå¤±è´¥ï¼Œå›é€€åˆ°åŸºç¡€æ–¹æ³•: {str(e)}")
            # å›é€€åˆ°åŸæœ‰çš„åˆ†æ®µåŒ¹é…
            if self.address_config.get('enable_segmentation', True):
                return self._segmented_address_similarity(addr1, addr2)
            else:
                return self.calculate_string_similarity(addr1, addr2)
    
    def _extract_enhanced_address_components(self, address: str) -> Dict[str, str]:
        """
        æå–å¢å¼ºçš„åœ°å€ç»„ä»¶
        æ”¯æŒæ›´å¤æ‚çš„åœ°å€è§£æï¼ŒåŒ…æ‹¬å»ºç­‘ç‰©åç§°ã€é—¨ç‰Œå·ç­‰
        
        ã€å…³é”®ä¿®å¤ã€‘ç¡®ä¿è¾“å…¥åœ°å€å·²ç»è¿‡æ ‡å‡†åŒ–å¤„ç†
        """
        components = {
            'province': '',    # 1çœçº§ï¼šçœã€è‡ªæ²»åŒºã€ç›´è¾–å¸‚
            'city': '',        # 2åœ°çº§ï¼šåœ°çº§å¸‚ã€åœ°åŒºã€è‡ªæ²»å·ã€ç›Ÿ
            'district': '',    # 3å¿çº§ï¼šå¿ã€å¿çº§å¸‚ã€åŒºã€æ——
            'town': '',        # 4ä¹¡çº§ï¼šè¡—é“ã€é•‡ã€ä¹¡
            'street': '',      # 5æ‘çº§ï¼šç¤¾åŒºã€è¡Œæ”¿æ‘ã€æ–°æ‘ã€é‡Œå¼„ã€é“è·¯
            'number': '',      # 6é—¨ç‰Œï¼šé—¨ç‰Œå·ã€æ¥¼å·ã€å•å…ƒå·ã€å®¤å·
            'building': '',    # å»ºç­‘ç‰©åç§°ï¼ˆä¸å‚ä¸6çº§åŒ¹é…ï¼‰
            'detail': ''       # å…¶ä»–è¯¦ç»†ä¿¡æ¯ï¼ˆä¸å‚ä¸6çº§åŒ¹é…ï¼‰
        }
        
        # ã€ä¿®å¤ã€‘ç¡®ä¿è¾“å…¥åœ°å€å·²æ ‡å‡†åŒ–ï¼ˆè°ƒç”¨æ–¹å·²å¤„ç†ï¼Œè¿™é‡ŒåšäºŒæ¬¡ç¡®è®¤ï¼‰
        # æ³¨æ„ï¼šæ­¤æ—¶addressåº”è¯¥å·²ç»æ˜¯æ ‡å‡†åŒ–åçš„åœ°å€
        logger.debug(f"æå–åœ°å€ç»„ä»¶ï¼Œè¾“å…¥åœ°å€: '{address}'")
        
        # ã€2025å¹´8æœˆ22æ—¥ä¿®å¤ã€‘6çº§åœ°å€ç»„ä»¶æå– - ä¸¥æ ¼æŒ‰ç…§6çº§å±‚çº§ç»“æ„
        # 1çœçº§ï¼šçœã€è‡ªæ²»åŒºã€ç›´è¾–å¸‚ï¼›2åœ°çº§ï¼šåœ°çº§å¸‚ã€åœ°åŒºã€è‡ªæ²»å·ã€ç›Ÿï¼›3å¿çº§ï¼šå¿ã€å¿çº§å¸‚ã€åŒºã€æ——ï¼›
        # 4ä¹¡çº§ï¼šè¡—é“ã€é•‡ã€ä¹¡ï¼›5æ‘çº§ï¼šç¤¾åŒºã€è¡Œæ”¿æ‘ã€æ–°æ‘ã€é‡Œå¼„ã€é“è·¯ï¼›6é—¨ç‰Œï¼šé—¨ç‰Œå·ã€æ¥¼å·ã€å•å…ƒå·ã€å®¤å·
        patterns = {
            'province': r'([^çœå¸‚åŒºå¿]{2,8}(?:çœ|å¸‚|è‡ªæ²»åŒº))',  # 1çœçº§
            'city': r'([^çœå¸‚åŒºå¿]{2,8}(?:å¸‚|å·|å¿))',          # 2åœ°çº§  
            'district': r'([^çœå¸‚åŒºå¿é•‡]{2,8}(?:åŒº|å¿|å¼€å‘åŒº|é«˜æ–°åŒº|ç»æµåŒº))',  # 3å¿çº§
            'town': r'([^çœå¸‚åŒºå¿]{2,8}(?:é•‡|ä¹¡|è¡—é“))',        # 4ä¹¡çº§ï¼šè¡—é“ã€é•‡ã€ä¹¡
            'street': r'([^è·¯è¡—é“å··å¼„é‡Œå·æ ‹å¹¢åº§æ¥¼å®¤å±‚]{1,20}(?:è·¯|è¡—|é“|å··|é‡Œ|å¤§è¡—|å¤§é“|è¡—é“|æ‘|é‚¨|ç¤¾åŒº|æ–°æ‘|å°åŒº|å…¬å¯“|èŠ±å›­|è‹‘|åº„|å®¶å›­|åŸ|å›­åŒº))',  # 5æ‘çº§ï¼šé“è·¯ã€æ‘ã€é‚¨ã€ç¤¾åŒºã€å°åŒºç­‰ï¼ˆç§»é™¤å¼„ï¼Œé¿å…ä¸é—¨ç‰Œå†²çªï¼‰
            'number': r'(\d+(?:å¼„\d*å·?|å·|æ ‹|å¹¢|åº§|æ¥¼|å®¤|å±‚))',  # 6é—¨ç‰Œï¼šé—¨ç‰Œå·ã€æ¥¼å·ã€å•å…ƒå·ã€å®¤å·
            'building': r'([^è·¯è¡—é“å··å¼„é‡Œå·æ ‹å¹¢åº§æ¥¼å®¤å±‚]{2,20}(?:å…»è€é™¢|æ•¬è€é™¢|è€å¹´å…¬å¯“|æŠ¤ç†é™¢|ç¦åˆ©é™¢|å…¬å¸|å‚|åº—|é¦†|æ‰€|ç«™|åœº|ç”Ÿæ€å›­|ç§‘æŠ€å›­|å·¥ä¸šå›­|äº§ä¸šå›­|å¹¿åœº|ä¸­å¿ƒ|å¤§å¦))'
        }
        
        # ã€ä¿®å¤ã€‘é¢„å¤„ç†å·²åœ¨æ ‡å‡†åŒ–é˜¶æ®µå®Œæˆï¼Œè¿™é‡Œç›´æ¥ä½¿ç”¨æ ‡å‡†åŒ–åçš„åœ°å€
        remaining_address = address
        
        # æŒ‰é¡ºåºæå–å„ç»„ä»¶
        for component, pattern in patterns.items():
            matches = re.findall(pattern, remaining_address)
            if matches:
                # å–æœ€é•¿çš„åŒ¹é…ï¼ˆé€šå¸¸æ›´å‡†ç¡®ï¼‰
                matched_component = max(matches, key=len)
                components[component] = matched_component
                # ä»å‰©ä½™åœ°å€ä¸­ç§»é™¤å·²åŒ¹é…çš„éƒ¨åˆ†
                remaining_address = remaining_address.replace(matched_component, '', 1)
                logger.debug(f"æå–åˆ°{component}: '{matched_component}'")
        
        # å‰©ä½™éƒ¨åˆ†ä½œä¸ºè¯¦ç»†ä¿¡æ¯
        components['detail'] = remaining_address.strip()
        
        logger.debug(f"åœ°å€ç»„ä»¶æå–ç»“æœ: {components}")
        return components
    
    def _calculate_weighted_address_similarity(self, comp1: Dict[str, str], comp2: Dict[str, str]) -> float:
        """
        ä¸¥æ ¼å±‚çº§ç»ˆæ­¢åœ°å€åŒ¹é…ç®—æ³•
        
        æ ¸å¿ƒåŸåˆ™ï¼ˆæŒ‰ç”¨æˆ·è¦æ±‚ï¼‰ï¼š
        1. æŒ‰ä»ä¸Šå¾€ä¸‹çš„å±‚çº§è¿›è¡ŒåŒ¹é…ï¼šçœâ†’å¸‚â†’åŒºâ†’é•‡â†’å°åŒº/è·¯â†’å¼„â†’é—¨ç‰Œå·
        2. å¦‚æœåŒä¸€çº§å‡ºç°ä¸åŒ¹é…åˆ™åº”è¯¥ç»ˆæ­¢åŒ¹é…ï¼Œå› ä¸ºä¸€å®šä¸æ˜¯åŒä¸€åœ°å€
        3. åªæœ‰å½“è¯¥çº§çš„åœ°å€ç›¸åŒã€é«˜åº¦ç›¸ä¼¼æˆ–æœ‰ç©ºå€¼æ—¶ï¼Œæ‰ç»§ç»­å‘ä¸‹ä¸€çº§è¿›è¡ŒåŒ¹é…
        """
        logger.debug(f"ğŸ›ï¸ å¼€å§‹ä¸¥æ ¼å±‚çº§ç»ˆæ­¢åœ°å€åŒ¹é…")
        logger.debug(f"åœ°å€1ç»„ä»¶: {comp1}")
        logger.debug(f"åœ°å€2ç»„ä»¶: {comp2}")
        
        # ã€æ ¸å¿ƒç®—æ³•ã€‘ä¸¥æ ¼6çº§åˆ†å±‚åŒ¹é… - æŒ‰ç”¨æˆ·2025å¹´8æœˆ21æ—¥è¦æ±‚å®ç°
        # 1çœçº§ï¼šçœã€è‡ªæ²»åŒºã€ç›´è¾–å¸‚ï¼›2åœ°çº§ï¼šåœ°çº§å¸‚ã€åœ°åŒºã€è‡ªæ²»å·ã€ç›Ÿï¼›3å¿çº§ï¼šå¿ã€å¿çº§å¸‚ã€åŒºã€æ——ï¼›
        # 4ä¹¡çº§ï¼šè¡—é“ã€é•‡ã€ä¹¡ï¼›5æ‘çº§ï¼šç¤¾åŒºã€è¡Œæ”¿æ‘ã€æ–°æ‘ã€é‡Œå¼„ã€é“è·¯ï¼›6é—¨ç‰Œï¼šé—¨ç‰Œå·ã€æ¥¼å·ã€å•å…ƒå·ã€å®¤å·
        hierarchy_levels = [
            ('province', '1çœçº§', 0.90),   # çœã€è‡ªæ²»åŒºã€ç›´è¾–å¸‚
            ('city', '2åœ°çº§', 0.90),       # åœ°çº§å¸‚ã€åœ°åŒºã€è‡ªæ²»å·ã€ç›Ÿ
            ('district', '3å¿çº§', 0.90),   # å¿ã€å¿çº§å¸‚ã€åŒºã€æ——
            ('town', '4ä¹¡çº§', 0.90),       # è¡—é“ã€é•‡ã€ä¹¡
            ('street', '5æ‘çº§', 0.90),     # ç¤¾åŒºã€è¡Œæ”¿æ‘ã€æ–°æ‘ã€é‡Œå¼„ã€é“è·¯
            ('number', '6é—¨ç‰Œ', 0.85),     # é—¨ç‰Œå·ã€æ¥¼å·ã€å•å…ƒå·ã€å®¤å·
        ]
        
        logger.debug(f"ğŸ” å¼€å§‹ä¸¥æ ¼6çº§åˆ†å±‚åŒ¹é…éªŒè¯ï¼ˆå…±{len(hierarchy_levels)}çº§ï¼‰")
        
        # ã€2025å¹´8æœˆ22æ—¥ä¿®å¤ã€‘å…ˆæ£€æŸ¥åœ°å€å®Œæ•´æ€§çº§åˆ«æ˜¯å¦åŒ¹é…
        def get_address_max_level(comp):
            """è·å–åœ°å€çš„æœ€é«˜çº§åˆ«"""
            for level_idx, (level, _, _) in enumerate(hierarchy_levels):
                if comp.get(level, '').strip():
                    max_level = level_idx + 1
            return max_level if 'max_level' in locals() else 0
        
        max_level1 = get_address_max_level(comp1)
        max_level2 = get_address_max_level(comp2)
        
        logger.debug(f"ğŸ“Š åœ°å€å®Œæ•´æ€§æ£€æŸ¥: åœ°å€1æœ€é«˜çº§åˆ«={max_level1}, åœ°å€2æœ€é«˜çº§åˆ«={max_level2}")
        
        # ã€2025å¹´8æœˆ22æ—¥ä¿®å¤ã€‘ç¬¬6çº§ï¼ˆé—¨ç‰Œï¼‰ä¸¥æ ¼åŒ¹é…æ£€æŸ¥
        # è·³ç©ºä»…å¯¹6çº§ä»¥å‰çš„ç”Ÿæ•ˆï¼Œç¬¬6çº§å¿…é¡»ä¸¥æ ¼åŒ¹é…
        val1_level6 = comp1.get('number', '').strip()  # ç¬¬6çº§ï¼šé—¨ç‰Œ
        val2_level6 = comp2.get('number', '').strip()
        
        # å¦‚æœä¸€ä¸ªæœ‰ç¬¬6çº§ï¼Œå¦ä¸€ä¸ªæ²¡æœ‰ç¬¬6çº§ â†’ åŒ¹é…å¤±è´¥
        if (val1_level6 and not val2_level6) or (not val1_level6 and val2_level6):
            logger.debug(f"âŒ ç¬¬6çº§ï¼ˆé—¨ç‰Œï¼‰ä¸å¯¹ç­‰: åœ°å€1='{val1_level6}', åœ°å€2='{val2_level6}'")
            logger.debug(f"   é€»è¾‘ä¾æ®: è·³ç©ºä»…å¯¹6çº§ä»¥å‰ç”Ÿæ•ˆï¼Œç¬¬6çº§å¿…é¡»ä¸¥æ ¼åŒ¹é…")
            return 0.0
        
        logger.debug(f"âœ… ç¬¬6çº§ï¼ˆé—¨ç‰Œï¼‰å¯¹ç­‰æ€§æ£€æŸ¥é€šè¿‡: åœ°å€1='{val1_level6}', åœ°å€2='{val2_level6}'")
        
        # ã€ä¸¥æ ¼6çº§åŒ¹é…ã€‘é€çº§éªŒè¯
        for level_idx, (level, level_name, threshold) in enumerate(hierarchy_levels):
            val1 = comp1.get(level, '').strip()
            val2 = comp2.get(level, '').strip()
            
            # ã€å…³é”®é€»è¾‘1ã€‘ä¸¤ä¸ªéƒ½æœ‰å€¼ â†’ å¿…é¡»åŒ¹é…ï¼Œå¦åˆ™ç«‹å³ç»ˆæ­¢
            if val1 and val2:
                level_similarity = self._calculate_component_similarity(val1, val2, level)
                logger.debug(f"ğŸ›ï¸ ç¬¬{level_idx+1}çº§ {level_name}éªŒè¯: '{val1}' vs '{val2}' = {level_similarity:.3f}")
                
                if level_similarity < threshold:
                    logger.debug(f"âŒ ç¬¬{level_idx+1}çº§ {level_name}ä¸åŒ¹é… â†’ ç«‹å³ç»ˆæ­¢åŒ¹é…")
                    logger.debug(f"   ç»ˆæ­¢åŸå› : {level_similarity:.3f} < {threshold:.2f}")
                    logger.debug(f"   é€»è¾‘ä¾æ®: åŒçº§åœ°å€ä¸åŒ¹é…ï¼Œä¸å¯èƒ½æ˜¯åŒä¸€åœ°å€")
                    return 0.0
                else:
                    logger.debug(f"âœ… ç¬¬{level_idx+1}çº§ {level_name}åŒ¹é…é€šè¿‡: {level_similarity:.3f} â‰¥ {threshold:.2f}")
            
            # ã€å…³é”®é€»è¾‘2ã€‘æœ‰ç©ºå€¼çš„å¤„ç† - 2025å¹´8æœˆ22æ—¥ä¿®å¤
            elif not val1 or not val2:
                current_level = level_idx + 1
                
                # æ£€æŸ¥æ˜¯å¦åœ¨æœ€é«˜çº§åˆ«èŒƒå›´å†…
                if current_level <= max(max_level1, max_level2):
                    logger.debug(f"ğŸ”„ ç¬¬{level_idx+1}çº§ {level_name}å­˜åœ¨ç©ºå€¼: '{val1}' vs '{val2}' â†’ ç»§ç»­ä¸‹çº§éªŒè¯")
                    continue
                else:
                    logger.debug(f"â¹ï¸ ç¬¬{level_idx+1}çº§ {level_name}è¶…å‡ºåœ°å€æœ€é«˜çº§åˆ« â†’ åœæ­¢éªŒè¯")
                    break
        
        logger.debug(f"ğŸ¯ ä¸¥æ ¼6çº§åˆ†å±‚åŒ¹é…éªŒè¯é€šè¿‡ï¼å¼€å§‹è®¡ç®—ç»¼åˆç›¸ä¼¼åº¦")
        
        # ã€æŒ‰ç”¨æˆ·è¦æ±‚ã€‘6çº§åŒ¹é…é€šè¿‡åï¼Œç›´æ¥è¿›è¡Œè¯„åˆ†ï¼Œä¸éœ€è¦é¢å¤–çš„å†²çªæ£€æµ‹
        
        # ã€ç¬¬äºŒé˜¶æ®µã€‘ä¸¥æ ¼6çº§æƒé‡é…ç½® - æŒ‰ç”¨æˆ·2025å¹´8æœˆ21æ—¥è¦æ±‚
        # 1çœçº§ï¼šçœã€è‡ªæ²»åŒºã€ç›´è¾–å¸‚ï¼›2åœ°çº§ï¼šåœ°çº§å¸‚ã€åœ°åŒºã€è‡ªæ²»å·ã€ç›Ÿï¼›3å¿çº§ï¼šå¿ã€å¿çº§å¸‚ã€åŒºã€æ——ï¼›
        # 4ä¹¡çº§ï¼šè¡—é“ã€é•‡ã€ä¹¡ï¼›5æ‘çº§ï¼šç¤¾åŒºã€è¡Œæ”¿æ‘ã€æ–°æ‘ã€é‡Œå¼„ã€é“è·¯ï¼›6é—¨ç‰Œï¼šé—¨ç‰Œå·ã€æ¥¼å·ã€å•å…ƒå·ã€å®¤å·
        weights = {
            'province': 0.10,    # 1çœçº§ï¼šçœã€è‡ªæ²»åŒºã€ç›´è¾–å¸‚
            'city': 0.15,        # 2åœ°çº§ï¼šåœ°çº§å¸‚ã€åœ°åŒºã€è‡ªæ²»å·ã€ç›Ÿ
            'district': 0.20,    # 3å¿çº§ï¼šå¿ã€å¿çº§å¸‚ã€åŒºã€æ——
            'town': 0.20,        # 4ä¹¡çº§ï¼šè¡—é“ã€é•‡ã€ä¹¡
            'street': 0.25,      # 5æ‘çº§ï¼šç¤¾åŒºã€è¡Œæ”¿æ‘ã€æ–°æ‘ã€é‡Œå¼„ã€é“è·¯
            'number': 0.30,      # 6é—¨ç‰Œï¼šé—¨ç‰Œå·ã€æ¥¼å·ã€å•å…ƒå·ã€å®¤å·
        }
        
        total_score = 0.0
        total_weight = 0.0
        matched_components = 0
        critical_matches = 0  # å…³é”®ç»„ä»¶åŒ¹é…æ•°
        
        for component, weight in weights.items():
            val1 = comp1.get(component, '').strip()
            val2 = comp2.get(component, '').strip()
            
            if val1 and val2:
                similarity = self._calculate_component_similarity(val1, val2, component)
                total_score += similarity * weight
                total_weight += weight
                matched_components += 1
                
                # ç»Ÿè®¡å…³é”®ç»„ä»¶åŒ¹é…ï¼ˆ6çº§ä¸­çš„å…³é”®çº§åˆ«ï¼‰
                if component in ['district', 'town', 'street', 'number']:  # 3å¿çº§ã€4ä¹¡çº§ã€5æ‘çº§ã€6é—¨ç‰Œ
                    critical_matches += 1
                
                logger.debug(f"ğŸ“Š ç»„ä»¶ '{component}': '{val1}' vs '{val2}' = {similarity:.3f} (æƒé‡: {weight})")
        
        # ã€ç¬¬ä¸‰é˜¶æ®µã€‘è®¡ç®—æœ€ç»ˆå¾—åˆ†
        if total_weight > 0 and matched_components >= 2:  # è‡³å°‘éœ€è¦2ä¸ªç»„ä»¶åŒ¹é…
            weighted_similarity = total_score / total_weight
            
            # ã€å¯ä¿¡åº¦è°ƒæ•´ã€‘æ ¹æ®å…³é”®ç»„ä»¶åŒ¹é…æ•°é‡è°ƒæ•´å¯ä¿¡åº¦
            # è‡³å°‘éœ€è¦2ä¸ªå…³é”®ç»„ä»¶åŒ¹é…æ‰èƒ½è·å¾—é«˜å¯ä¿¡åº¦
            if critical_matches >= 2:
                confidence_factor = 1.0
            elif critical_matches == 1:
                confidence_factor = 0.7  # åªæœ‰1ä¸ªå…³é”®ç»„ä»¶åŒ¹é…ï¼Œé™ä½å¯ä¿¡åº¦
            else:
                confidence_factor = 0.3  # æ²¡æœ‰å…³é”®ç»„ä»¶åŒ¹é…ï¼Œå¤§å¹…é™ä½å¯ä¿¡åº¦
            
            final_score = weighted_similarity * confidence_factor
            
            logger.debug(f"ğŸ¯ å±‚çº§é€’è¿›åŒ¹é…ç»“æœ: åŸºç¡€å¾—åˆ†={weighted_similarity:.3f}, å…³é”®ç»„ä»¶={critical_matches}, å¯ä¿¡åº¦={confidence_factor:.3f}, æœ€ç»ˆå¾—åˆ†={final_score:.3f}")
            return final_score
        
        logger.debug(f"âŒ åŒ¹é…ç»„ä»¶ä¸è¶³æˆ–æƒé‡ä¸º0ï¼Œè¿”å›0åˆ†")
        return 0.0
    
    def _calculate_component_similarity(self, val1: str, val2: str, component_type: str) -> float:
        """
        è®¡ç®—ç‰¹å®šç»„ä»¶çš„ç›¸ä¼¼åº¦
        æ ¹æ®ç»„ä»¶ç±»å‹ä½¿ç”¨ä¸åŒçš„åŒ¹é…ç­–ç•¥
        
        ã€2025å¹´8æœˆ21æ—¥æ–°å¢ã€‘å¢åŠ äººä¸ºè¾“å…¥æ•°æ®é”™è¯¯çš„å®¹é”™å¤„ç†
        å¤„ç†å¦‚ï¼šä¸Šæµ·è™¹å£å¤©å®è·¯881å· vs ä¸Šæµ·å¸‚è™¹å£åŒºå¤©å®è·¯881å·
        """
        if val1 == val2:
            return 1.0
        
        # ã€2025å¹´8æœˆ22æ—¥ä¿®å¤ã€‘å¯¹åœ°å€ç»„ä»¶è¿›è¡ŒäºŒæ¬¡æ ‡å‡†åŒ–ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§
        # å¯¹äºstreetç»„ä»¶ï¼ˆç¬¬5çº§æ‘çº§ï¼‰ï¼Œä¸ä½¿ç”¨ä¼šç§»é™¤å°åŒºæ‘åçš„æ ‡å‡†åŒ–
        if component_type == 'street':
            # å¯¹äºæ‘çº§ç»„ä»¶ï¼Œåªè¿›è¡ŒåŸºæœ¬æ ‡å‡†åŒ–ï¼Œä¸ç§»é™¤å°åŒºæ‘å
            normalized_val1 = val1.strip() if val1 else ""
            normalized_val2 = val2.strip() if val2 else ""
        else:
            # å¯¹äºå…¶ä»–ç»„ä»¶ï¼Œä½¿ç”¨å®Œæ•´çš„åœ°å€æ ‡å‡†åŒ–
            # æ¢å¤åœ°å€æ ‡å‡†åŒ– - è¿™æ˜¯åœ°å€åŒ¹é…çš„æ ¸å¿ƒåŠŸèƒ½
            from .address_normalizer import normalize_address_for_matching
            normalized_val1 = normalize_address_for_matching(val1) if val1 else ""
            normalized_val2 = normalize_address_for_matching(val2) if val2 else ""
        
        # æ ‡å‡†åŒ–åå†æ¬¡æ£€æŸ¥å®Œå…¨åŒ¹é…
        if normalized_val1 == normalized_val2:
            return 1.0
        
        # ã€æ–°å¢ã€‘äººä¸ºè¾“å…¥é”™è¯¯å®¹é”™å¤„ç†
        tolerance_score = self._calculate_tolerance_similarity(val1, val2, component_type)
        if tolerance_score > 0.0:
            return tolerance_score
        
        if component_type == 'number':
            # ã€2025å¹´8æœˆ22æ—¥ä¿®å¤ã€‘é—¨ç‰Œå·å¿…é¡»ç²¾ç¡®åŒ¹é…ï¼Œä¸å…è®¸æ¨¡ç³ŠåŒ¹é…
            # é—¨ç‰Œå·æ˜¯åœ°å€çš„å…³é”®æ ‡è¯†ï¼Œå¿…é¡»å®Œå…¨ä¸€è‡´æ‰èƒ½è®¤ä¸ºæ˜¯åŒä¸€åœ°å€
            
            # æå–æ‰€æœ‰æ•°å­—è¿›è¡Œå®Œæ•´æ¯”è¾ƒ
            num1 = re.findall(r'\d+', normalized_val1)
            num2 = re.findall(r'\d+', normalized_val2)
            
            # åªæœ‰å½“æ‰€æœ‰æ•°å­—å®Œå…¨åŒ¹é…æ—¶æ‰è®¤ä¸ºç›¸ä¼¼
            if num1 == num2 and len(num1) > 0:
                # æ•°å­—å®Œå…¨åŒ¹é…ï¼Œæ£€æŸ¥æ ¼å¼æ˜¯å¦ç›¸ä¼¼ï¼ˆå¦‚ï¼š27å· vs 27å®¤ï¼‰
                if normalized_val1 == normalized_val2:
                    return 1.0  # å®Œå…¨åŒ¹é…
                else:
                    return 0.95  # æ•°å­—ç›¸åŒä½†æ ¼å¼ç•¥æœ‰å·®å¼‚
            else:
                # æ•°å­—ä¸åŒ¹é…ï¼Œé—¨ç‰Œå·ä¸åŒï¼Œè¿”å›0ï¼ˆä¸¥æ ¼åŒ¹é…ï¼‰
                return 0.0
        
        elif component_type in ['street', 'building']:
            # è¡—é“å’Œå»ºç­‘ç‰©ï¼šä½¿ç”¨å¤šç§ç®—æ³•ç»¼åˆè¯„ä¼°ï¼ˆä½¿ç”¨æ ‡å‡†åŒ–æ•°æ®ï¼‰
            scores = [
                fuzz.ratio(normalized_val1, normalized_val2) / 100.0,
                fuzz.partial_ratio(normalized_val1, normalized_val2) / 100.0,
                fuzz.token_set_ratio(normalized_val1, normalized_val2) / 100.0
            ]
            return max(scores)  # å–æœ€é«˜åˆ†
        
        else:
            # å…¶ä»–ç»„ä»¶ï¼šä½¿ç”¨åœ°å€ä¸“ç”¨ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆè€Œéé€šç”¨å­—ç¬¦ä¸²ç›¸ä¼¼åº¦ï¼‰
            # ã€å…³é”®ä¿®å¤ã€‘ä½¿ç”¨æ ‡å‡†åŒ–åçš„æ•°æ®è¿›è¡Œfuzzè®¡ç®—ï¼Œè€Œä¸æ˜¯é€šç”¨å­—ç¬¦ä¸²ç›¸ä¼¼åº¦
            scores = [
                fuzz.ratio(normalized_val1, normalized_val2) / 100.0,
                fuzz.token_set_ratio(normalized_val1, normalized_val2) / 100.0
            ]
            return max(scores)
    
    def _apply_address_matching_bonus(self, base_score: float, comp1: Dict[str, str], comp2: Dict[str, str]) -> float:
        """
        åº”ç”¨åœ°å€åŒ¹é…å¥–åŠ±æœºåˆ¶
        å½“å¤šä¸ªå…³é”®ç»„ä»¶åŒ¹é…æ—¶ç»™äºˆé¢å¤–å¥–åŠ±
        """
        bonus = 0.0
        
        # å…³é”®ç»„ä»¶å®Œå…¨åŒ¹é…å¥–åŠ±
        key_components = ['number', 'street', 'district']
        matched_key_components = 0
        
        for component in key_components:
            val1 = comp1.get(component, '').strip()
            val2 = comp2.get(component, '').strip()
            if val1 and val2 and val1 == val2:
                matched_key_components += 1
        
        # æ ¹æ®åŒ¹é…çš„å…³é”®ç»„ä»¶æ•°é‡ç»™äºˆå¥–åŠ±
        if matched_key_components >= 2:
            bonus += 0.1  # ä¸¤ä¸ªæˆ–ä»¥ä¸Šå…³é”®ç»„ä»¶åŒ¹é…
        elif matched_key_components == 1:
            bonus += 0.05  # ä¸€ä¸ªå…³é”®ç»„ä»¶åŒ¹é…
        
        # å»ºç­‘ç‰©åç§°åŒ¹é…å¥–åŠ±
        building1 = comp1.get('building', '').strip()
        building2 = comp2.get('building', '').strip()
        if building1 and building2:
            building_sim = self.calculate_string_similarity(building1, building2)
            if building_sim > 0.8:
                bonus += 0.05
        
        return base_score + bonus
    
    def _segmented_address_similarity(self, addr1: str, addr2: str) -> float:
        """åˆ†æ®µåœ°å€ç›¸ä¼¼åº¦"""
        try:
            # æå–åœ°å€ç»„ä»¶
            components1 = self._extract_address_components(addr1)
            components2 = self._extract_address_components(addr2)
            
            # æƒé‡é…ç½®
            weights = {
                'province': self.address_config.get('province_weight', 0.2),
                'city': self.address_config.get('city_weight', 0.3),
                'district': self.address_config.get('district_weight', 0.3),
                'detail': self.address_config.get('detail_weight', 0.2)
            }
            
            total_score = 0.0
            total_weight = 0.0
            
            for component, weight in weights.items():
                comp1 = components1.get(component, '')
                comp2 = components2.get(component, '')
                
                if comp1 or comp2:
                    score = self.calculate_string_similarity(comp1, comp2)
                    total_score += score * weight
                    total_weight += weight
            
            return total_score / total_weight if total_weight > 0 else 0.0
            
        except Exception as e:
            logger.debug(f"åˆ†æ®µåœ°å€ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {str(e)}")
            return self.calculate_string_similarity(addr1, addr2)
    
    def _extract_address_components(self, address: str) -> Dict[str, str]:
        """æå–åœ°å€ç»„ä»¶"""
        components = {
            'province': '',    # 1çœçº§ï¼šçœã€è‡ªæ²»åŒºã€ç›´è¾–å¸‚
            'city': '',        # 2åœ°çº§ï¼šåœ°çº§å¸‚ã€åœ°åŒºã€è‡ªæ²»å·ã€ç›Ÿ
            'district': '',    # 3å¿çº§ï¼šå¿ã€å¿çº§å¸‚ã€åŒºã€æ——
            'town': '',        # 4ä¹¡çº§ï¼šè¡—é“ã€é•‡ã€ä¹¡
            'street': '',      # 5æ‘çº§ï¼šç¤¾åŒºã€è¡Œæ”¿æ‘ã€æ–°æ‘ã€é‡Œå¼„ã€é“è·¯
            'number': '',      # 6é—¨ç‰Œï¼šé—¨ç‰Œå·ã€æ¥¼å·ã€å•å…ƒå·ã€å®¤å·
            'building': '',    # å»ºç­‘ç‰©åç§°ï¼ˆä¸å‚ä¸6çº§åŒ¹é…ï¼‰
            'detail': ''       # å…¶ä»–è¯¦ç»†ä¿¡æ¯ï¼ˆä¸å‚ä¸6çº§åŒ¹é…ï¼‰
        }
        
        # é¢„å¤„ç†ï¼šç§»é™¤è¡Œæ”¿å±‚çº§è¯æ±‡
        remaining_address = address
        remaining_address = re.sub(r'å¸‚è¾–åŒº', '', remaining_address)  # ç§»é™¤"å¸‚è¾–åŒº"
        remaining_address = re.sub(r'å¿è¾–åŒº', '', remaining_address)  # ç§»é™¤"å¿è¾–åŒº"
        
        # ã€2025å¹´8æœˆ22æ—¥ä¿®å¤ã€‘6çº§åœ°å€ç»„ä»¶æå– - ä¸¥æ ¼æŒ‰ç…§6çº§å±‚çº§ç»“æ„
        # 1çœçº§ï¼šçœã€è‡ªæ²»åŒºã€ç›´è¾–å¸‚ï¼›2åœ°çº§ï¼šåœ°çº§å¸‚ã€åœ°åŒºã€è‡ªæ²»å·ã€ç›Ÿï¼›3å¿çº§ï¼šå¿ã€å¿çº§å¸‚ã€åŒºã€æ——ï¼›
        # 4ä¹¡çº§ï¼šè¡—é“ã€é•‡ã€ä¹¡ï¼›5æ‘çº§ï¼šç¤¾åŒºã€è¡Œæ”¿æ‘ã€æ–°æ‘ã€é‡Œå¼„ã€é“è·¯ï¼›6é—¨ç‰Œï¼šé—¨ç‰Œå·ã€æ¥¼å·ã€å•å…ƒå·ã€å®¤å·
        patterns = {
            'province': r'([^çœå¸‚åŒºå¿]{2,8}(?:çœ|å¸‚|è‡ªæ²»åŒº))',  # 1çœçº§
            'city': r'([^çœå¸‚åŒºå¿]{2,8}(?:å¸‚|å·|å¿))',          # 2åœ°çº§  
            'district': r'([^çœå¸‚åŒºå¿é•‡]{2,8}(?:åŒº|å¿|å¼€å‘åŒº|é«˜æ–°åŒº|ç»æµåŒº))',  # 3å¿çº§
            'town': r'([^çœå¸‚åŒºå¿]{2,8}(?:é•‡|ä¹¡|è¡—é“))',        # 4ä¹¡çº§ï¼šè¡—é“ã€é•‡ã€ä¹¡
            'street': r'([^è·¯è¡—é“å··å¼„é‡Œå·æ ‹å¹¢åº§æ¥¼å®¤å±‚]{1,20}(?:è·¯|è¡—|é“|å··|é‡Œ|å¤§è¡—|å¤§é“|è¡—é“|æ‘|é‚¨|ç¤¾åŒº|æ–°æ‘|å°åŒº|å…¬å¯“|èŠ±å›­|è‹‘|åº„|å®¶å›­|åŸ|å›­åŒº))',  # 5æ‘çº§ï¼šé“è·¯ã€æ‘ã€é‚¨ã€ç¤¾åŒºã€å°åŒºç­‰ï¼ˆç§»é™¤å¼„ï¼Œé¿å…ä¸é—¨ç‰Œå†²çªï¼‰
            'number': r'(\d+(?:å¼„\d*å·?|å·|æ ‹|å¹¢|åº§|æ¥¼|å®¤|å±‚))',  # 6é—¨ç‰Œï¼šé—¨ç‰Œå·ã€æ¥¼å·ã€å•å…ƒå·ã€å®¤å·
            'building': r'([^è·¯è¡—é“å··å¼„é‡Œå·æ ‹å¹¢åº§æ¥¼å®¤å±‚]{2,20}(?:å…»è€é™¢|æ•¬è€é™¢|è€å¹´å…¬å¯“|æŠ¤ç†é™¢|ç¦åˆ©é™¢|å…¬å¸|å‚|åº—|é¦†|æ‰€|ç«™|åœº|ç”Ÿæ€å›­|ç§‘æŠ€å›­|å·¥ä¸šå›­|äº§ä¸šå›­|å¹¿åœº|ä¸­å¿ƒ|å¤§å¦))'
        }
        
        # æŒ‰é¡ºåºæå–å„ç»„ä»¶
        for component, pattern in patterns.items():
            matches = re.findall(pattern, remaining_address)
            if matches:
                components[component] = matches[0]
                remaining_address = remaining_address.replace(matches[0], '', 1)
        
        # å‰©ä½™éƒ¨åˆ†ä½œä¸ºè¯¦ç»†åœ°å€
        components['detail'] = remaining_address.strip()
        
        return components
    
    def calculate_comprehensive_similarity(self, source_record: Dict, target_record: Dict, 
                                        field_configs: Dict) -> Tuple[float, Dict]:
        """
        è®¡ç®—ç»¼åˆç›¸ä¼¼åº¦
        
        Args:
            source_record: æºè®°å½•
            target_record: ç›®æ ‡è®°å½•
            field_configs: å­—æ®µé…ç½®
            
        Returns:
            Tuple[float, Dict]: (ç»¼åˆç›¸ä¼¼åº¦, å­—æ®µç›¸ä¼¼åº¦è¯¦æƒ…)
        """
        
        field_similarities = {}
        weighted_score = 0.0
        total_weight = 0.0
        
        for field_name, field_config in field_configs.items():
            source_field = field_config['source_field']
            target_field = field_config.get('target_field')
            weight = field_config['weight']
            match_type = field_config['match_type']
            
            # è·³è¿‡ç›®æ ‡å­—æ®µä¸ºç©ºçš„æƒ…å†µ
            if not target_field:
                continue
            
            source_value = source_record.get(source_field)
            target_value = target_record.get(target_field)
            
            # è®¡ç®—å­—æ®µç›¸ä¼¼åº¦
            if match_type == 'string':
                similarity = self.calculate_string_similarity(
                    str(source_value) if source_value else '',
                    str(target_value) if target_value else ''
                )
            elif match_type == 'numeric':
                similarity = self.calculate_numeric_similarity(
                    source_value, target_value, field_config
                )
            elif match_type == 'phone':
                similarity = self.calculate_phone_similarity(
                    str(source_value) if source_value else '',
                    str(target_value) if target_value else ''
                )
            elif match_type == 'address':
                similarity = self.calculate_address_similarity(
                    str(source_value) if source_value else '',
                    str(target_value) if target_value else ''
                )
            else:
                similarity = 0.0
            
            field_similarities[field_name] = {
                'similarity': similarity,
                'weight': weight,
                'source_value': source_value,
                'target_value': target_value
            }
            
            weighted_score += similarity * weight
            total_weight += weight
        
        # è®¡ç®—ç»¼åˆç›¸ä¼¼åº¦
        comprehensive_score = weighted_score / total_weight if total_weight > 0 else 0.0
        
        return comprehensive_score, field_similarities
    
    def _calculate_tolerance_similarity(self, val1: str, val2: str, component_type: str) -> float:
        """
        å¤„ç†äººä¸ºè¾“å…¥æ•°æ®é”™è¯¯çš„å®¹é”™åŒ¹é…
        
        å¸¸è§é”™è¯¯æ¨¡å¼ï¼š
        1. ç¼ºå°‘è¡Œæ”¿çº§åˆ«åç¼€ï¼šä¸Šæµ· vs ä¸Šæµ·å¸‚ï¼Œè™¹å£ vs è™¹å£åŒº
        2. æ ¼å¼ä¸ä¸€è‡´ï¼šå¤©å®è·¯881å· vs å¤©å®è·¯881å·
        3. ç®€å†™vså…¨ç§°ï¼šä¸Šæµ· vs ä¸Šæµ·å¸‚
        
        Args:
            val1, val2: å¾…æ¯”è¾ƒçš„åœ°å€ç»„ä»¶
            component_type: ç»„ä»¶ç±»å‹ï¼ˆprovince, city, district, town, street, numberï¼‰
            
        Returns:
            float: å®¹é”™ç›¸ä¼¼åº¦åˆ†æ•°ï¼Œ0.0è¡¨ç¤ºæ— æ³•å®¹é”™åŒ¹é…
        """
        if not val1 or not val2:
            return 0.0
        
        # ã€å®¹é”™ç­–ç•¥1ã€‘è¡Œæ”¿çº§åˆ«åç¼€å®¹é”™
        if component_type in ['province', 'city', 'district', 'town']:
            # å®šä¹‰å„çº§åˆ«çš„å¸¸è§åç¼€
            suffixes_map = {
                'province': ['çœ', 'å¸‚', 'è‡ªæ²»åŒº', 'ç‰¹åˆ«è¡Œæ”¿åŒº'],  # çœçº§åç¼€
                'city': ['å¸‚', 'åœ°åŒº', 'è‡ªæ²»å·', 'ç›Ÿ'],           # åœ°çº§åç¼€  
                'district': ['åŒº', 'å¿', 'å¿çº§å¸‚', 'æ——'],         # å¿çº§åç¼€
                'town': ['è¡—é“', 'é•‡', 'ä¹¡', 'åŠäº‹å¤„']            # ä¹¡çº§åç¼€
            }
            
            suffixes = suffixes_map.get(component_type, [])
            
            # å°è¯•ç§»é™¤åç¼€è¿›è¡ŒåŒ¹é…
            core1 = self._remove_admin_suffixes(val1, suffixes)
            core2 = self._remove_admin_suffixes(val2, suffixes)
            
            if core1 and core2 and core1 == core2:
                logger.debug(f"ğŸ”§ {component_type}çº§å®¹é”™åŒ¹é…æˆåŠŸ: '{val1}' vs '{val2}' â†’ æ ¸å¿ƒéƒ¨åˆ† '{core1}'")
                return 0.95  # é«˜åˆ†ä½†ç•¥ä½äºå®Œå…¨åŒ¹é…
        
        # ã€å®¹é”™ç­–ç•¥2ã€‘è¡—é“/é“è·¯åç§°å®¹é”™
        if component_type == 'street':
            # ç§»é™¤å¸¸è§é“è·¯åç¼€è¿›è¡ŒåŒ¹é…
            road_suffixes = ['è·¯', 'è¡—', 'é“', 'å¤§é“', 'å¤§è¡—', 'å··', 'å¼„', 'é‡Œ', 'æ‘']
            core1 = self._remove_road_suffixes(val1, road_suffixes)
            core2 = self._remove_road_suffixes(val2, road_suffixes)
            
            if core1 and core2 and core1 == core2:
                logger.debug(f"ğŸ”§ è¡—é“å®¹é”™åŒ¹é…æˆåŠŸ: '{val1}' vs '{val2}' â†’ æ ¸å¿ƒéƒ¨åˆ† '{core1}'")
                return 0.95
        
        # ã€å®¹é”™ç­–ç•¥3ã€‘é—¨ç‰Œå·æ ¼å¼å®¹é”™
        if component_type == 'number':
            # æå–æ•°å­—éƒ¨åˆ†è¿›è¡ŒåŒ¹é…
            import re
            nums1 = re.findall(r'\d+', val1)
            nums2 = re.findall(r'\d+', val2)
            
            if nums1 and nums2 and nums1 == nums2:
                logger.debug(f"ğŸ”§ é—¨ç‰Œå·å®¹é”™åŒ¹é…æˆåŠŸ: '{val1}' vs '{val2}' â†’ æ•°å­—éƒ¨åˆ† {nums1}")
                return 0.90  # æ•°å­—ç›¸åŒä½†æ ¼å¼å¯èƒ½ä¸åŒ
        
        # ã€å®¹é”™ç­–ç•¥4ã€‘æ¨¡ç³ŠåŒ¹é…å…œåº•
        # å¦‚æœæ ¸å¿ƒå†…å®¹é«˜åº¦ç›¸ä¼¼ï¼Œç»™äºˆä¸€å®šå®¹é”™åˆ†æ•°
        from fuzzywuzzy import fuzz
        fuzzy_score = fuzz.ratio(val1, val2) / 100.0
        
        if fuzzy_score >= 0.85:  # 85%ä»¥ä¸Šç›¸ä¼¼åº¦è®¤ä¸ºæ˜¯å®¹é”™åŒ¹é…
            logger.debug(f"ğŸ”§ æ¨¡ç³Šå®¹é”™åŒ¹é…: '{val1}' vs '{val2}' = {fuzzy_score:.3f}")
            return fuzzy_score * 0.9  # é™ä½ä¸€äº›åˆ†æ•°ä½œä¸ºå®¹é”™æƒ©ç½š
        
        return 0.0  # æ— æ³•å®¹é”™åŒ¹é…
    
    def _remove_admin_suffixes(self, text: str, suffixes: list) -> str:
        """ç§»é™¤è¡Œæ”¿çº§åˆ«åç¼€ï¼Œè¿”å›æ ¸å¿ƒåç§°"""
        if not text:
            return ""
        
        for suffix in suffixes:
            if text.endswith(suffix):
                core = text[:-len(suffix)].strip()
                if core:  # ç¡®ä¿ç§»é™¤åç¼€åè¿˜æœ‰å†…å®¹
                    return core
        
        return text  # æ²¡æœ‰åŒ¹é…çš„åç¼€ï¼Œè¿”å›åŸæ–‡
    
    def _remove_road_suffixes(self, text: str, suffixes: list) -> str:
        """ç§»é™¤é“è·¯åç¼€ï¼Œè¿”å›æ ¸å¿ƒåç§°"""
        if not text:
            return ""
        
        for suffix in suffixes:
            if text.endswith(suffix):
                core = text[:-len(suffix)].strip()
                if core:  # ç¡®ä¿ç§»é™¤åç¼€åè¿˜æœ‰å†…å®¹
                    return core
        
        return text  # æ²¡æœ‰åŒ¹é…çš„åç¼€ï¼Œè¿”å›åŸæ–‡ 